var searchDocuments = {"html/index.html":{"action-uuid":"5c364aa8-430f-41ac-84bf-888d84c959af","title":"HTML","content":"Sources"},"core/maven/index.html":{"path":"Core/Maven","action-uuid":"1fc7fac5-90ea-42c7-8622-d6db7bfcb894","title":"Maven","content":"Sources Javadoc"},"nsd-demo-cli/nsd/index.html":{"path":"Demo CLI/nsd","action-uuid":"49f1611b-9cdf-49d6-8d3a-e0d064414f08","title":"nsd","content":"Version: org.nasdanika.cli@2024.5.1 \r\nUsage: nsd [-hV] COMMAND\r\nNasdanika Command Line Interface\r\n  -h, --help      Show this help message and exit.\r\n  -V, --version   Print version information and exit.\r\nCommands:\r\n  launcher                Generates Java command line from directories of\r\n                            modules/jars\r\n  app                     HTML Application model commands\r\n  help                    Outputs usage for all registred commands\r\n  http-server             Serves HTTP routes\r\n  inspect-yaml            Demo of YAML inspection\r\n  java                    Commands related to Java\r\n  list-inspectable-rules  Lists available rules\r\n  list-rules              Lists available rules\r\n  module-graph            Generates module dependency graph\r\n  rules                   Rules commands"},"nsd-demo-cli/nsd/list-inspectable-rules/index.html":{"path":"Demo CLI/nsd/list-inspectable-rules","action-uuid":"90403acf-480b-4e0d-9231-13f4940d7665","title":"list-inspectable-rules","content":"Version: org.nasdanika.launcher.demo@2024.5.1 \r\nUsage: nsd list-inspectable-rules [-dhjV] [-o=&lt;output&gt;] [-p=&lt;progressOutput&gt;]\r\n                                  [--exclude-rule[=&lt;ruleExcludes&gt;...]]...\r\n                                  [--exclude-rule-set\r\n                                  [=&lt;ruleSetExcludes&gt;...]]... [--include-rule\r\n                                  [=&lt;ruleIncludes&gt;...]]... [--include-rule-set\r\n                                  [=&lt;ruleSetIncludes&gt;...]]...\r\nLists available rules\r\n  -d, --data              Output progress data\r\n      --exclude-rule[=&lt;ruleExcludes&gt;...]\r\n                          ID's of rules to exclude\r\n      --exclude-rule-set[=&lt;ruleSetExcludes&gt;...]\r\n                          ID's of rule sets to exclude\r\n  -h, --help              Show this help message and exit.\r\n      --include-rule[=&lt;ruleIncludes&gt;...]\r\n                          ID's of rules to include\r\n      --include-rule-set[=&lt;ruleSetIncludes&gt;...]\r\n                          ID's of rule sets to include\r\n  -j, --json              Output progress in JSON\r\n  -o, --output=&lt;output&gt;   Output file\r\n  -p, --progress=&lt;progressOutput&gt;\r\n                          Output file for progress monitor\r\n  -V, --version           Print version information and exit."},"core/diagram/index.html":{"path":"Core/Diagram","action-uuid":"b43e3ebf-decc-46f2-af83-5c158dc6ad17","title":"Diagram","content":"Sources Javadoc"},"nsd-cli/nsd/rules/action-model/index.html":{"path":"CLI/nsd/rules/action-model","action-uuid":"f5379e32-2418-4484-9805-11a5f37632b3","title":"action-model","content":"Usage: nsd rules action-model [-dfhjRV] [-p=&lt;progressOutput&gt;]\r\n                              [-c=&lt;String=String&gt;]... [-C=URL]...\r\n                              [-M=&lt;String=String&gt;]... &lt;model&gt; &lt;output&gt;\r\nGenerates rule set documentation action model\r\n      &lt;model&gt;         Model URI or file path, resolved relative\r\n                      to the current directory\r\n                      or looked up in registered rule sets\r\n                      if -R option is provided\r\n      &lt;output&gt;        Output file\r\n  -c, --context-entry=&lt;String=String&gt;\r\n                      Context entries.\r\n                      Shadow entries in contexts and mounts.\r\n  -C, --context=URL   Context resource URL relative to the current directory.\r\n                        YAML, JSON, or properties. In properties dots are\r\n                        treated as key path separators. Type is inferred from\r\n                        the content type header, if it is present, or\r\n                        extension. Contexts are composed in the order of\r\n                        definition, later context entries shadowing the former\r\n  -d, --data          Output progress data\r\n  -f, --file          Mdel parameter is a file path\r\n  -h, --help          Show this help message and exit.\r\n  -j, --json          Output progress in JSON\r\n  -M, --context-mount=&lt;String=String&gt;\r\n                      MappingContext resource URL relative to the current\r\n                        directory. YAML, JSON, or properties. In properties\r\n                        dots are treated as key path separators. Type is\r\n                        inferred from the content type header, if it is\r\n                        present, or extension. Mounts shadow context entries.\r\n  -p, --progress=&lt;progressOutput&gt;\r\n                      Output file for progress monitor\r\n  -R, --registered    Use registered rule set\r\n                      with provided URI\r\n  -V, --version       Print version information and exit."},"html/bootstrap/index.html":{"path":"HTML/Bootstrap","action-uuid":"7a3bbdda-0020-48b2-bd99-2461a36945f2","title":"Bootstrap","content":"Sources Javadoc"},"nsd-cli/nsd/app/index.html":{"path":"CLI/nsd/app","action-uuid":"9f8b7483-1038-4a09-8700-9173916cbd58","title":"app","content":"Version: org.nasdanika.html.model.app.gen.cli@2024.5.1 \r\nUsage: nsd app [-hV] [COMMAND]\r\nHTML Application model commands\r\n  -h, --help      Show this help message and exit.\r\n  -V, --version   Print version information and exit.\r\nCommands:\r\n  site  Generates HTML site"},"index.html":{"action-uuid":"14fabafc-f87f-4d02-ad27-9ccaace4c1ea","title":"Nasdanika","content":" Common Resources Persistence Ncore Diagram Graph Drawio EMF Exec Maven Capability CLI HTTP Core HTML HTML Bootstrap App Models JsTree Bootstrap EMF HTML GitLab Family Architecture Git Excel ECharts Nature Bank PDF Party Coverage Source Engineering Java Maven Enterprise Function Flow Rules Azure Decision Analysis Capability Flow Ecore Jira Models Data Sources Loader Store Key Extractor Query Engine Requestor Generator Responder Retrieval Augmented Generation (RAG) Analysis, Visualization &amp; Generation Java Analysis, Visualization &amp; Generation JUnit Tests Generation Practices Beyond Diagrams Java Analysis, Visualization, and Generation Books CLI Medium Publication Demo CLI Common Resources Persistence Ncore Diagram Graph Drawio EMF Exec Maven Capability CLI HTTP Core HTML HTML Bootstrap App Models JsTree Bootstrap EMF HTML GitLab Family Architecture Git Excel ECharts Nature Bank PDF Party Coverage Source Engineering Java Maven Enterprise Function Flow Rules Azure Decision Analysis Capability Flow Ecore Jira Models Data Sources Loader Store Key Extractor Query Engine Requestor Generator Responder Retrieval Augmented Generation (RAG) Analysis, Visualization &amp; Generation Java Analysis, Visualization &amp; Generation JUnit Tests Generation Practices Beyond Diagrams Java Analysis, Visualization, and Generation Books CLI Medium Publication Demo CLI"},"nsd-cli/nsd/app/site/index.html":{"path":"CLI/nsd/app/site","action-uuid":"006de3ad-3939-4414-9817-5fbf5eee4e46","title":"site","content":"Version: org.nasdanika.html.model.app.gen.cli@2024.5.1 \r\nUsage: nsd app site [-dhjlV] [-b=&lt;baseDir&gt;] [-m=&lt;domian&gt;] [-p=&lt;progressOutput&gt;]\r\n                    [-P=&lt;parallelism&gt;] [-r=&lt;pageErrors&gt;] [-t=&lt;timeout&gt;]\r\n                    [-T=&lt;pageTemplate&gt;] [-w=&lt;workDir&gt;] [-c=&lt;String=String&gt;]...\r\n                    [-C=URL]... [-M=&lt;String=String&gt;]... [-e[=&lt;excludes&gt;...]]...\r\n                    [-i[=&lt;includes&gt;...]]... &lt;model&gt; &lt;output&gt;\r\nGenerates HTML site\r\n      &lt;model&gt;                Model URI, resolved relative\r\n                             to the current directory\r\n      &lt;output&gt;               Output directory\r\n  -b, --base-dir=&lt;baseDir&gt;   Base directory\r\n  -c, --context-entry=&lt;String=String&gt;\r\n                             Context entries.\r\n                             Shadow entries in contexts and mounts.\r\n  -C, --context=URL          Context resource URL relative to the current\r\n                               directory. YAML, JSON, or properties. In\r\n                               properties dots are treated as key path\r\n                               separators. Type is inferred from the content\r\n                               type header, if it is present, or extension.\r\n                               Contexts are composed in the order of\r\n                               definition, later context entries shadowing the\r\n                               former\r\n  -d, --data                 Output progress data\r\n  -e, --exclude[=&lt;excludes&gt;...]\r\n                             Output directory clean excludes\r\n                             Ant pattern\r\n  -h, --help                 Show this help message and exit.\r\n  -i, --include[=&lt;includes&gt;...]\r\n                             Output directory clean includes\r\n                             Ant pattern\r\n  -j, --json                 Output progress in JSON\r\n  -l, --[no-]clean           Clean working directory\r\n                             defaults to true\r\n  -m, --domain=&lt;domian&gt;      Sitemap domain\r\n  -M, --context-mount=&lt;String=String&gt;\r\n                             MappingContext resource URL relative to the\r\n                               current directory. YAML, JSON, or properties. In\r\n                               properties dots are treated as key path\r\n                               separators. Type is inferred from the content\r\n                               type header, if it is present, or extension.\r\n                               Mounts shadow context entries.\r\n  -p, --progress=&lt;progressOutput&gt;\r\n                             Output file for progress monitor\r\n  -P, --parallelism=&lt;parallelism&gt;\r\n                             If the value greater than one then an executor\r\n                               service is created and injected into the context\r\n                               to allow concurrent execution.\r\n  -r, --errors=&lt;pageErrors&gt;  Expected number of page errors\r\n  -t, --timeout=&lt;timeout&gt;    If parallelism is greater than one this option\r\n                               specifies timout in seconds awaiting completion\r\n                               of execution. Default value is 60.\r\n  -T, --page-template=&lt;pageTemplate&gt;\r\n                             Page template URI relative\r\n                             to the current directory\r\n  -V, --version              Print version information and exit.\r\n  -w, --work-dir=&lt;workDir&gt;   Working directory\r\nExit codes:\r\n  Non-negative number   Delegate result\r\n  -1                    Unhandled exception during execution\r\n  -2                    Invalid input\r\n  -3                    Diagnostic failed\r\n  -4                    Execution failed or was cancelled, successful rollback\r\n  -5                    Execution failed or was cancelled, rollback failed\r\n  -6                    Executor service termination timed out"},"core/common/index.html":{"path":"Core/Common","action-uuid":"08b0b091-27b2-4186-bd20-964af74ebbc2","title":"Common","content":"Sources Javadoc"},"practices/junit/index.html":{"path":"Practices/JUnit Tests Generation","action-uuid":"52d2ef54-956f-47ee-b121-18511817ac73","title":"JUnit Tests Generation","content":"This practice is a specialization of the Java Analysis, Visualization &amp; Generation Practice for generation of JUnit tests. In particular: Generation of tests for methods or classes with low test coverage Leveraging Gen AI such as OpenAI ChatGPT or Azure OpenAI Service for test generation The above diagram shows Java development activities and artifacts. Black arrows show the typical process, blue arrows show the test generation loop. The developer produces source artifacts which may include non-java artifacts used to generate Java code (e.g. Ecore models), &ldquo;main&rdquo; Java sources and test Java sources. Java sources are compiled into bytecode (class files). Here it is important to note that matching of bytecode classes and methods to source code classes and methods might be non-trivial because of: Lambdas Anonymous and method-scope classes Annotation processors like Lombok JUnit tests are compiled and executed. If code coverage, such as jacoco, is configured then test execution produces coverage data. Jacoco stores coverage data in jacoco.exec file. This file is used to generate a coverage report and upload coverage information to systems like SonarQube. In this practice it is also used to select which methods to generate tests for based on coverage data. This diagram provides an insight into the test generation activity: Coverage data and bytecode are used as input to load the Coverage model. Source files, the coverage model, and bytecode (optional) are used to load the Java model of source code. The generator traverses the model and generates unit tests for method with low coverage using a combination of programmatic (traditional) generation and Gen AI. Tests are generated as a Java model as well and then are delivered to the developer for review, modification, and inclusion into the unit test suite. The following section provides an overview of two &ldquo;local loop&rdquo; reference implementations (a.k.a. designs/embodiments) - all-in-one and componentized. There are many possible designs leveraging different alternatives at multiple variation points. The sections after the reference implementations section provide an overview of variation points, alternatives, and factors to take into consideration during alternative selection. Command line Reference Implementations All-in-one Componentized Repository scan/crawl Variation points and alternatives Stakeholders &amp; Activities Developer Build machine Test generator GenAI Messages Channels Developer -&gt; Build Machine/Test Generation : Source code Build Machine -&gt; Test Generator : Coverage results, possibly with bytecode Test Generation -&gt; Developer : Generated tests Test Generation - GenAI : Prompt Command line Nasdanika CLI features JUnit command which generates JUnit tests as explained above. Reference Implementations This section explains reference implementations All-in-one All-in-one generations is implemented as a JUnit test is available in TestGenerator. An example of tests generated by this generator - PetControllerTests. As the name implies, all steps of source analysis and generation are implemented in a single class and are executed in one go. Componentized Componentized test generation which is also executed in one go is implemented in these classes: TestJavaAnalyzers - loads sources, coverage, and inspectors, passes the sources to the inspectors, aggregates and saves results. Coverage Inspector - generates tests for methods with low coverage leveraging TestGenerator capability provided by OpenAITestGenerator. Repository scan/crawl TestGitLab demonstrates how to scan a source repository (GitLab) using REST API, inspect code, generate unit tests, commit them to the server (also over the REST API) and create a merge request. This implementation does not use coverage information, its purpose is to demonstrate operation over the REST API without having to clone a repository, which might be an expensive operation. The implementation uses GitLab Model to communicate with the repository. It uses Java model to load sources and StringBuilder to build test cases. Variation points and alternatives As you have seen above, you can have an AI-powered JUnit test generator in about 230 lines of code, and maybe it would all you need. However, there are many variation points (design dimensions), alternatives at each point and, as such, possible permutations of thereof (designs). This section provides a high level overview of variation points and alternatives. How to assemble a solution from those alternative is specific to your context and there might be different solutions for different contexts and multiple solutions complementing each other. As you proceed with assembling a solution, or a portfolio of solutions, you may identify more variation points and alternatives. To manage the complexity you may use: Enterprise Model for general guidance, Capability framework or Capability model to create a catalog of variation points and alternatives and compute solutions (designs) from them Decision Analysis to select from the computed list of designs Flow to map your development process AS-IS and then augment it with test generation activities at different points. In this section we&rsquo;ll use the below diagram and the concept of an Enterprise with Stakeholders performing activities and exchanging Messages over Channels. The mission of our enterprise is to deliver quality Java code. The loss function to minimize is loss function = cost * risk / business value. For our purposes we&rsquo;ll define risk as inversely proportional to tests coverage risk = missed lines / total lines - that&rsquo;s all we can measure in this simple model. The cost includes resources costs - salary, usage fees for OpenAI. Below is a summary of our enterprise: Stakeholders &amp; Activities: Developer - writes code Build machine - compiles code and executes tests Test generator - generates unit tests GenAI - leveraged by the Test Generator Messages: Source code Bytecode Coverage results Prompt to generate a test Generated tests Channels Developer -&gt; Build Machine : Source code Developer -&gt; Test Generation : Source code Build Machine -&gt; Test Generator : Coverage results, possibly with bytecode Test Generation -&gt; Developer : Generated tests Test Generation - GenAI : Prompt The below sections outline variation points and alternatives for the list items above Stakeholders &amp; Activities Developer A developer writes code - both &ldquo;business&rdquo; and test. They use some kind of an editor, likely an IDE - Eclipse, IntelliJ, VS Code. Different IDE&rsquo;s come with different sets of plug-ins, including AI assistants. Forcing a developer to switch from their IDE of preference to another IDE is likely to cause considerable productivity drop, at least for some period of time, even if the new IDE is considered superior to the old IDE. So, if you want to switch to another IDE just because it has some plug-in which you like - think twice. Build machine A build machine compiles code and executes tests. Technically, compilation and test execution may be separated in two individual activities. We are not doing it for this analysis because it doesn&rsquo;t carry much relevance to test generation. You can do it for yours. Test generator Test generator generates tests by &ldquo;looking&rdquo; at the source code, bytecode, and code coverage results. Because the source code is a model element representing piece of code (method, constructor, &hellip;), the generator may traverse the model to &ldquo;understand&rdquo; the context. E.g. it may take a look at the method&rsquo;s class, other classes in the module. If the sources are loaded from a version control system, it may take a look at the commits. And if the source model is part of an organization model, it may look at &ldquo;sibling&rdquo; modules and other resources. By analyzing source and bytecode the generator would know methods a given method calls, objects it creates, and also it would know methods calling the method. It will also &ldquo;know&rdquo; branch conditions, e.g. switch cases. Using this information the generator may: Generate comments to help the developer Generate mocks, including constructor and static methods mocks Generate tests for different branches Build a variety of prompts for GenAI The test generator may do the following code generated by GenAI: Add to generated test methods commented out - as it is done in the reference implementations &ldquo;Massage&rdquo; - remove backticks, parse, add imports - generated and implied. In addition to code generation the generator may ask GenAI to explain code and generate recommendations - it will help the developer to understand the source method and possibly improve it along the way. It may also generate dependency graphs and sequence diagrams. GenAI There may GenAI models out there - cloud, self hosted. Which one to use heavily depends on the context. For example, if you have a large codebase with considerable amount of technical debt having an on-prem model may be a good choice because: You may fine-tune it. Even if you don&rsquo;t have tons of GPU power and your model is relatively slow you can crawl you code base, generate tests and deliver them to developers for review and inclusion into test suites. In this scenario your cost is on-prem infrastructure and power. Your savings are not having to pay for GenAI in the cloud and developer productivity if your fined tuned model turns out to be more efficient than a &ldquo;vanilla&rdquo; LLM. There are many other considerations, of course! Messages In this section we&rsquo;ll take a look just at bytecode and coverage results delivered to the test generator. The generator operates on models. As such, bytecode and coverage results can be delivered in a &ldquo;raw&rdquo; format to be loaded to a model by the generator, or pre-loaded to a model and saved to a file. The second option results in fewer files to pass to the test generator. The model file can be in XMI format or in compressed binary. The XMI format is human-readable, the binary format takes less space on disk. Channels Developer -&gt; Build Machine/Test Generation : Source code For local development the build machine is the same machine where developer creates sources. The test generator is also executed on the developer&rsquo;s workstation. As such, the delivery channels is the file system. In the case of CI/CD pipeline/build server such as Jenkins or GitHub Actions, a version control systems is the delivery channel. Build Machine -&gt; Test Generator : Coverage results, possibly with bytecode The test generator needs coverage results. If the coverage results are delivered in the raw form, it also needs bytecode (class files) to make sense of the results. Coverage results can be delivered to the test generator using the following channels: Filesystem Jenkins workspace made available to the test generator over HTTP(S) Binary repository. For example, coverage results might be published to the Maven repository as an assembly along with sources, jar file, and javadoc. They can be published in a raw format or as a model. In this modality the tests generator can get everything it needs from a Maven repository. You can use Maven model or Maven Artifact Resolver API to work with Maven repositories. See also Apache Maven Artifact Resolver. Additional value of storing coverage data in a binary repository is that it can serve as an evidence of code quality stored with the compiled code, not in some other system. Source repository. Traditionally storing derived artifacts in a source repository is frowned upon. However, storage is cheap, GitHub Pages use this approach - so, whatever floats your boat! SonarQube - it doesn&rsquo;t store method level coverage, so the solution would have to operate on the class level and generate test methods for all methods in a class with low coverage. You may have a specialized application/model repository/database and store coverage information there, possibly aligned to your organization structure. Test Generation -&gt; Developer : Generated tests The goal is to deliver generated tests to the developer, make the developer aware that they are available, and possibly track progress of incorporating the generated tests into the test suite. With this in mind, there are the following alternatives/options: Filesystem - for the local loop Source control system - commit, create a merge/pull request. When using this channels you can check if there is already a generated test and whether it needs to be re-generated. If, say, the source method hasn&rsquo;t changed (the same SHA digest), and the generator version and configuration hasn&rsquo;t changed - do not re-generate, it will only consume resources and create &ldquo;noise&rdquo; - the LLM may return a different response, developers will have to spend time understanding what has changed. You may fork a repository instead of creating a branch. This way all work on tests will be done in the forked repository and the source repository will receive pull requests with fully functional tests. Tests can be generated to a separate directory and then copied to the source directory, or they can be generated directly to the source directory. Tests may be generated with @Disabled annotation so they are clearly visible in the test execution tree, and with @Generated annotation to track changes and merge generated and hand-crafted code. Issue tracking system - either attach generated tests to issues, or create a merge request and reference it from the generated issues. In systems like Jira you may create a hierarchy of issues (epic/story), assign components, labels, fix versions, assignees, etc. You may assign different generated tests to different developers based on size and complexity of the source method. E.g. tests for short methods with low complexity can be assigned to junior developers. This alone may give your team a productivity boost! E-mail or other messaging system. Issue trackers and messaging systems may be used to deliver generated documentation while source control will deliver generated tests. Developers will use the generated documentation such as graphs, sequence diagrams and GenAI explanations/recommendations in conjunction with the generated test code. This channel may implement some sort of backpressure by saying &ldquo;it is enough for now&rdquo;, as a human developer would by crying &ldquo;Enough is enough, I have other stories to work on in this sprint!&rdquo;. Generating just enough tests is beneficial in the following ways: Does not overwhelm developers Does not result in a stale generated code waiting to be taken a look at Does not waste resources and time to generate code which nobody would look at in the near future Uses the latest (and hopefully the greatest) generator version With backpressure a question of prioritization/sorting arises - what to work on first? Source methods can be sorted according to: Size/complexity Dependency. E.g. method b (caller) calls method a (callee) One strategy might be to work on callee methods first (method a) to provide a solid foundation. Another is to work on caller methods first because callee methods might be tested along the way. These strategies might be combined - some developers (say junior) may work on callee tests and senior developers may be assigned to test (complex) caller (top level) methods. Also, the top-down approach (callers first) might be better for addressing technical debt accrued over time, while bottom-up (callees first) for new development. Test Generation - GenAI : Prompt GenAI is neither free not blazing fast. As such, this channel may implement: Billing Rate limiting (throttling) Budgeting - so many calls per time period Caching Java Sources Source Artifacts Bytecode Coverage Data Developer JUnit Tests Gen AI Code Generation Compilation Test Execution JUnit Test Generation Coverage Report Java Sources Bytecode Coverage Data Developer Gen AI Coverage Model Source Code Model Tests Model Generator JUnit Test Generation Writing Code Compilation Testing Test Generation Gen AI"},"nsd-cli/index.html":{"action-uuid":"d67adec7-740d-4e86-a9b2-fa9bd9d2e351","title":"CLI","content":"Nasdanika Command Line Interface (CLI) is a suite of Nasdanika capabilities packaged as command line tools. Sources Prerequisites To run Nasdanika CLI you&rsquo;d need Java 17+. To build from sources you&rsquo;d also need Maven. Installation Download installation archive from the releases page. On Linux make nsd executable: chmod a+x nsd. Building from sources Download sources as a zip file or clone the repository Run mvn clean verify After the build completes the distribuion will be available in target/dist directory Adding to PATH The distribution is portable and local - it can be put to any directory, but it can only be executed from that directory. To create an installation which can be used from any directory you will need to create launcher files with absolute paths. Windows nsd.bat launcher -f options-global -o nsd-global.bat -s -m org.nasdanika.launcher -c org.nasdanika.launcher.Launcher -M modules -j &quot;@java&quot;\n Add the installation to the PATH environment variable. You may delete/rename nsd.bat and rename nsd-global.bat to nsd.bat. Linux ./nsd launcher -o nsd-global -s -m org.nasdanika.launcher -c org.nasdanika.launcher.Launcher -M modules\n Open nsd-global in a text editor and add #!/bin/bash line before the java command line. Make the file executable and add the installation directory to the path. You may remove/rename nsd and rename nsd-global to nsd. If you get java.lang.module.FindException: Module &lt;module name&gt; not found error, open the file in a text editor, locate the problematic module and remove it from the --add-modules list."},"core/drawio/index.html":{"path":"Core/Drawio","action-uuid":"33bb1a41-dfc6-42ec-aae9-15461acb5acf","title":"Drawio","content":"Nasdankia provides two Maven modules for working with Drawio diagrams - API and Model. The modules require Java 17 or above. API Drawio module provides Java API for reading and manipulating Drawio diagrams. It is built on top of Graph. The module provides the following interfaces representing elements of a diagram file: Document - the root object of the API representing a file/resource which contains one or more pages. Page - a page containing a diagram (Model). Model - a diagram model containing the diagram root. Root - the root of the model containing layers. Layer - a diagram may have one or more layers. Layers contain Nodes and Connections. Node - a node can be connected to other nodes with connections. A node may contain other nodes and connections. Connection - a connection between two nodes. The below diagram shows relationships between the above interfaces including their super-interfaces: Util provides utility methods such as layout() and methods to navigate and query documents and their elements. Sources Model Drawio Model module provides an EMF Ecore model for diagrams. A model instance can be obtained from the API document by calling Document.toModelDocument() method. The model makes it more convenient to work with the diagram elements by: Making a reference between pages and model elements bi-directional. Introducing Tag class as opposed to a string in the API. Tag is contained by Page and has bi-directional reference with tagged elements. Sources Document The root object of the API representing a file/resource which contains one or more pages Page A page containing a diagram (Model) Model A diagram model containing the diagram root Root The root of the model containing layers Layer A diagram may have one or more layers. Layers contain Nodes and Connections. Link [0..1] Layer Element Element Model Element Node A node can be connected to other nodes with connections. A node may contain other nodes and connections. Connection A connection between two nodes * source 0..1 outgoingConnections * 1 1 1..* * target 0..1 incomingConnections * Tag * * *"},"nsd-cli/nsd/java/junit/index.html":{"path":"CLI/nsd/java/junit","action-uuid":"92493f3c-3cac-4fbf-bd0c-4aa6ca357903","title":"junit","content":"Version: org.nasdanika.models.java.cli@2024.5.1 \r\nUsage: nsd java junit [-dhjVw] [--[no-]ai] [--[no-]comment-response]\r\n                      [--disabled] [--api-endpoint=&lt;apiEndpoint&gt;]\r\n                      [-c=&lt;classes&gt;] [--class-suffix=&lt;classSuffix&gt;]\r\n                      [-J=&lt;jacoco&gt;] [-k=&lt;apiKey&gt;] [-l=&lt;limit&gt;]\r\n                      [-m=&lt;deploymentOrModelName&gt;] [-p=&lt;progressOutput&gt;]\r\n                      [--package-suffix=&lt;packageSuffix&gt;] [-r=&lt;prompt&gt;]\r\n                      [-s=&lt;sources&gt;] [-t=&lt;coverageType&gt;]\r\n                      [-v=&lt;apiKeyEnvironmentVariable&gt;] [-e[=&lt;excludes&gt;...]]...\r\n                      [-i[=&lt;includes&gt;...]]... &lt;projectDir&gt; &lt;coverageThreshold&gt;\r\n                      &lt;output&gt;\r\nGenerates JUnit tests\r\n      &lt;projectDir&gt;          Project directory\r\n      &lt;coverageThreshold&gt;   Coverage threshold\r\n      &lt;output&gt;              Output directory\r\n                            relative to the project directory\r\n      --[no-]ai             Use AI, defaults to true\r\n      --api-endpoint=&lt;apiEndpoint&gt;\r\n                            OpenAPI endpoint, defaults to\r\n                            https://api.openai.com/v1/chat/completions\r\n  -c, --classes=&lt;classes&gt;   Classes directory path relative\r\n                            to the project directory,\r\n                            defaults to target/classes\r\n      --class-suffix=&lt;classSuffix&gt;\r\n                            Test class suffix\r\n                            defaults to Tests\r\n      --[no-]comment-response\r\n                            Comment AI responses\r\n                            defaults to true\r\n  -d, --data                Output progress data\r\n      --disabled            Generate disabled tests\r\n  -e, --exclude[=&lt;excludes&gt;...]\r\n                            Source excludes\r\n                            Ant pattern\r\n  -h, --help                Show this help message and exit.\r\n  -i, --include[=&lt;includes&gt;...]\r\n                            Source includes\r\n                            Ant pattern\r\n  -j, --json                Output progress in JSON\r\n  -J, --jacoco=&lt;jacoco&gt;     jacoco.exec file path relative\r\n                            to the project directory,\r\n                            defaults to target/jacoco.exec\r\n  -k, --api-key=&lt;apiKey&gt;    OpenAPI key\r\n  -l, --limit=&lt;limit&gt;       Maximum number of test classes\r\n                            to generate\r\n  -m, --model=&lt;deploymentOrModelName&gt;\r\n                            OpenAPI deployment or model\r\n                            defaults to gpt-4\r\n  -p, --progress=&lt;progressOutput&gt;\r\n                            Output file for progress monitor\r\n      --package-suffix=&lt;packageSuffix&gt;\r\n                            Test package suffix\r\n                            defaults to .tests\r\n  -r, --prompt=&lt;prompt&gt;     Propmt\r\n                            defaults to 'Generate a JUnit 5 test method\r\n                              leveraging Mockito for the following Java method'\r\n  -s, --sources=&lt;sources&gt;   Sources directory path relative\r\n                            to the project directory,\r\n                            defaults to src/main/java\r\n  -t, --coverage-type=&lt;coverageType&gt;\r\n                            Coverage type\r\n                            Valid values: complexity, instruction, branch, line\r\n                            defaults to line\r\n  -v, --api-key-variable=&lt;apiKeyEnvironmentVariable&gt;\r\n                            OpenAPI key environment variable\r\n                            defaults to OPENAI_API_KEY\r\n  -V, --version             Print version information and exit.\r\n  -w, --overwrite           Overwrite existing tests"},"practices/java/index.html":{"path":"Practices/Java Analysis, Visualization &amp; Generation","action-uuid":"95c15996-c84c-42c7-8ee9-84a2c10f805e","title":"Java Analysis, Visualization &amp; Generation","content":"This practice is a specialization of the Analysis, Visualization &amp; Generation Practice for using the Java model as a source model, target model, or both. This page provides a high level reference and the book goes into details. So what is possible to do with the Java model/language in addition to generic analysis, visualization and generation? Analysis Java model can be loaded from sources and bytecode. Tests coverage can be loaded from jacoco.exec and class files and associated with model elements. Bytecode information can be used to establish bi-directional references between model elements - field access, method calls. Bytecode can be instrumented to collect runtime cross-referencing such as reflective method calls and field access. Visualization Module, package, class, method dependency graphs. The graphs may reflect coverage data so they can be used for prioritization of addressing technical debt. For example, many well-covered microservices may use a shared library with low coverage. Sequence diagrams Generation Documentation Documentation similar to documentation generated from Ecore models such as Java model above, Family model, or Enterprise model with: * Visualizations mentioned above\n* Documentation produced by GenAI - explainations and recommendations.\n Such documentation may be useful in modernization efforts where there is a need to understand a legacy codebase. It may also be useful in onboarding of new team members and it might help provide deeper insights into the codebase for all team members. Source code Source code with @Generated annotations or @generated Javadoc tags to allow detection of changes in the generated code and re-generation only if there changes in the generator inputs, and the output was not modified since the last generation. It allows concurrent evolution of the generator, generator inputs, and manual modifications. For more details see Solution instantiation. RAG/Chat RAG/Chat on top of the Java model may use bytecode and runtime introspection information in addition to just source code. For example &ldquo;This method is overridden by &hellip; and is called by &hellip;&rdquo;. RAG may be contextual - chat with a class, a method, a package, a module or an application (group of modules) if the model elements are &ldquo;mounted&rdquo; under higher level constructs such as products and segments."},"core/capability/index.html":{"path":"Core/Capability","action-uuid":"95b87d70-5557-4f5c-b808-7fdaa07ebfac","title":"Capability","content":"Nasdanika Capability framework1 allows to discover/load capabilities which meet a requirement. Capabilities are provided by CapabilityFactory create() method. Capability factories may request other capabilities they need. As such, capabilities can be chained. Factories create CapabilityLoaders which provide Flux reactive streams of capabilities. It allows to have an infinite stream of capabilities which are consumed (and produced) as needed. Capability providers may furnish additional information about capabilities. This information can be used for filtering or sorting providers. A non-technical example of requirement/capability chain graph is a food chain/graph. Food is a requirement. Or &ldquo;I want to eat&rdquo; is a requirement. Bread and, say fried eggs are two capabilities meeting/addressing the requirement. Bread requires &ldquo;wheat&rdquo;, &ldquo;water&rdquo;, and &ldquo;bake&rdquo; capabilities. Fried eggs require &ldquo;egg&rdquo;, &ldquo;oil&rdquo;, and &ldquo;fry&rdquo; capabilities. Bread capability provider may implement Vegan marker interface which can be used for filtering. All food capabilities may implement NutritionalInformation interface - it can be used for filtering or sorting. A more technical example is Java ServiceLoader with service type being a requirement and an instance of the service class being a capability. Nasdanika capability framework can operate on top of ServiceLoader and may be thought of as a generalization of service loading. In essence, the capability framework is a backward chaining engine as shown in one of the example below. Sources Client code - requesting a capability Service capabilities Providing a capability EMF Requesting a ResourceSet With all packages and factories Selecting contributors Providing ResourceSet instance Contributing EPackages Resource factories URI handlers Applications Services Solutions for architectures Backward chaining Stream processing AI model training/fine-tuning Client code - requesting a capability Capabilities are loaded by CapabilityLoader. Capability loader can take an iterable of capability factories in its constructor, or it can load them using ServiceLoader as shown in the below code snippet: CapabilityLoader capabilityLoader = new CapabilityLoader();\ncapabilityLoader.getFactories().add(new TestServiceFactory&lt;Object&gt;());\nProgressMonitor progressMonitor = new PrintStreamProgressMonitor();\n\t\t\nfor (CapabilityProvider&lt;?&gt; cp: capabilityLoader.load(new TestCapabilityFactory.Requirement(&quot;Hello World&quot;), progressMonitor)) {\n\tSystem.out.println(cp);\n\tFlux&lt;?&gt; publisher = cp.getPublisher();\n\t\t\t\n\tpublisher.subscribe(System.out::println);\n}\n Factories can also be added post-construction with getFactories().add(factory). Service capabilities Service requirements and capabilities provide functionality similar to ServiceLoader - requesting instances of specific type, but extend it with ability to provide additional service requirement. This functionality is provided by ServiceCapabilityFactory and ServiceCapabilityFactory.Requirement. CapabilityLoader capabilityLoader = new CapabilityLoader();\ncapabilityLoader.getFactories().add(new TestServiceFactory&lt;Object&gt;());\nProgressMonitor progressMonitor = new PrintStreamProgressMonitor();\n\t\t\n@SuppressWarnings({ &quot;unchecked&quot;, &quot;rawtypes&quot; })\nServiceCapabilityFactory.Requirement&lt;List&lt;Double&gt;, Double&gt; requirement = (ServiceCapabilityFactory.Requirement) ServiceCapabilityFactory.createRequirement(List.class, null,  33.0);\nfor (CapabilityProvider&lt;?&gt; cp: capabilityLoader.load(requirement, progressMonitor)) {\n\tSystem.out.println(cp);\n\tFlux&lt;?&gt; publisher = cp.getPublisher();\n\t\t\t\n\tpublisher.subscribe(System.out::println);\n}\n It is also possible to load services from ServiceLoader using subclasses of Service. You&rsquo;d need to subclass ServiceFactory in a module which uses a particular service and override stream(Class&lt;S&gt; service) method as shown below: @Override\nprotected Stream&lt;Provider&lt;S&gt;&gt; stream(Class&lt;S&gt; service) {\n\treturn ServiceLoader.load(service).stream();\n}\n Then you&rsquo;d need to add the factory to the loader: capabilityLoader.getFactories().add(new TestServiceFactory&lt;Object&gt;());\n Providing a capability As it was mentioned above, capability factories can be explicitly added to CapabilityLoader or loaded using ServiceLoader. Below is an example of a capability factory: public class TestCapabilityFactory implements CapabilityFactory&lt;TestCapabilityFactory.Requirement, Integer&gt; {\n\t\n\tpublic record Requirement(String value){};\n\t\n\t@Override\n\tpublic boolean canHandle(Object requirement) {\n\t\treturn requirement instanceof Requirement;\n\t}\n\n\t@Override\n\tpublic CompletionStage&lt;Iterable&lt;CapabilityProvider&lt;Integer&gt;&gt;&gt; create(\n\t\t\tRequirement requirement,\n\t\t\tBiFunction&lt;Object, ProgressMonitor, CompletionStage&lt;Iterable&lt;CapabilityProvider&lt;Object&gt;&gt;&gt;&gt; resolver,\n\t\t\tProgressMonitor progressMonitor) {\n\t\t\n\t\treturn resolver.apply(MyService.class, progressMonitor).thenApply(cp -&gt; {;\n\t\t\t@SuppressWarnings({ &quot;unchecked&quot;, &quot;rawtypes&quot; })\n\t\t\tFlux&lt;MyService&gt; myServiceCapabilityPublisher = (Flux) cp.iterator().next().getPublisher();\n\t\t\t\n\t\t\treturn Collections.singleton(new CapabilityProvider&lt;Integer&gt;() {\n\t\n\t\t\t\t@Override\n\t\t\t\tpublic Flux&lt;Integer&gt; getPublisher() {\n\t\t\t\t\tFunction&lt;MyService, Integer&gt; mapper = ms -&gt; ms.count(((Requirement) requirement).value());\n\t\t\t\t\treturn myServiceCapabilityPublisher.map(mapper);\n\t\t\t\t}\n\t\t\t\t\n\t\t\t});\n\t\t});\n\t}\n\n}\n There is a number of implementations of CapabilityFactory is different Nasdanika modules, most of them extending ServiceCapability. In Eclipse or other IDE open CapabilityFactory type hierarchy to discover available implementations. EMF Most of Nasdanika capabilities are based on Eclipse Modeling Framework (EMF)2, Ecore3 models in particular. One of key objects in EMF Ecore is a ResourceSet. Resource set has a package registry, resource factory registry, and URI converter. org.nasdanika.capability.emf packages provides capability factories for contributing to resource set. It allows to request resource set from a capability loader and the returned resource set would be configured with registered EPackages, resource factories, adapter factories and URIHandlers. Requesting a ResourceSet With all packages and factories CapabilityLoader capabilityLoader = new CapabilityLoader();\nProgressMonitor progressMonitor = new PrintStreamProgressMonitor();\nRequirement&lt;ResourceSetRequirement, ResourceSet&gt; requirement = ServiceCapabilityFactory.createRequirement(ResourceSet.class);\t\t\nfor (CapabilityProvider&lt;?&gt; capabilityProvider: capabilityLoader.load(requirement, progressMonitor)) {\n\tResourceSet resourceSet = (ResourceSet) capabilityProvider.getPublisher().blockFirst();\n}\n Selecting contributors CapabilityLoader capabilityLoader = new CapabilityLoader();\nProgressMonitor progressMonitor = new PrintStreamProgressMonitor();\n\nPredicate&lt;ResourceSetContributor&gt; contributorPredicate = ...;\nResourceSetRequirement serviceRequirement = new ResourceSetRequirement(null, contributorPredicate);\n\t\t\nRequirement&lt;ResourceSetRequirement, ResourceSet&gt; requirement = ServiceCapabilityFactory.createRequirement(ResourceSet.class, null, serviceRequirement);\t\t\n\nfor (CapabilityProvider&lt;?&gt; capabilityProvider: capabilityLoader.load(requirement, progressMonitor)) {\n\tResourceSet resourceSet = (ResourceSet) capabilityProvider.getPublisher().blockFirst();\n}\n Providing ResourceSet instance You may provide an instance of ResourceSet to configure in the requirement. Contributing EPackages Create a class extending EPackageCapabilityFactory: public class NcoreEPackageResourceSetCapabilityFactory extends EPackageCapabilityFactory {\n\n\t@Override\n\tprotected EPackage getEPackage() {\n\t\treturn NcorePackage.eINSTANCE;\n\t}\n\n\t@Override\n\tprotected URI getDocumentationURI() {\n\t\treturn URI.createURI(&quot;https://ncore.models.nasdanika.org/&quot;);\n\t}\n\n}\n and add it to module-info.java provides: provides CapabilityFactory with NcoreEPackageResourceSetCapabilityFactory;\n Resource factories Create a class extending ResourceFactoryCapabilityFactory: public class XMIResourceFactoryCapabilityFactory extends ResourceFactoryCapabilityFactory {\n\n\t@Override\n\tprotected Factory getResourceFactory() {\n\t\treturn new XMIResourceFactoryImpl();\n\t}\n\t\n\t@Override\n\tprotected String getExtension() {\n\t\treturn Resource.Factory.Registry.DEFAULT_EXTENSION;\n\t}\n\n}\n and add it to module-info.java provides CapabilityFactory. URI handlers Create a class extending URIConverterContributorCapabilityFactory: public class ClassPathURIHandlerResourceSetCapabilityFactory extends URIConverterContributorCapabilityFactory {\n\n\t@Override\n\tprotected void contribute(URIConverter uriConverter, ProgressMonitor progressMonitor) {\t\n\t\turiConverter.getURIHandlers().add(0, new URIHandlerImpl() {\n\n\t\t\t@Override\n\t\t\tpublic boolean canHandle(URI uri) {\n\t\t\t\treturn uri != null &amp;&amp; Util.CLASSPATH_SCHEME.equals(uri.scheme());\n\t\t\t}\n\n\t\t\t@Override\n\t\t\tpublic InputStream createInputStream(URI uri, Map&lt;?, ?&gt; options) throws IOException {\n\t\t\t\treturn DefaultConverter.INSTANCE.toInputStream(uri);\n\t\t\t}\n\t\t\t\n\t\t});\n\t\t\n\t}\n\t\n}\n and add it to module-info.java provides CapabilityFactory. Applications Services Service capabilities explained above a used by Graph and Function Flow for loading node processors and connection processors for a specific requirement using NodeProcessorFactory and ConnectionProcessorFactory respectively. For example, code generation, execution, simulation. Solutions for architectures One of future application of the capability framework is creation a list of solution alternatives for an architecture/pattern. For example, there might be multiple RAG embodiments with different key types, key extractors, stores, &hellip; Some of &ldquo;design dimensions&rdquo; are listed below: Key type: Bag of words. Multiple options - just words, words with frequency, tokenized words, word stems. Embedding vector - different embedding models, different dimensions. Store - multiple stores for multiple key types. Multiple indexing and retrieval methods. Chunk size, chunk overlap, chunking algorithm. Generator - multiple models and prompts As you can see a number of potential combinations can easily go into thousands or even be infinite. Reactive approach with filtering and sorting may be helpful in selecting a solution which is a good fit for a particular use case - number and type of data sources etc. For example, if the total size of data is under a few gigabytes an in-memory store may be a better choice than, say, an external (vector) database. Also an old good bag of words might be better than embeddings. E.g. it might be cheaper. Solution alternatives may include temporal aspect or monetary aspects. For example, version X of Y is available at time Z. Z might be absolute or relative. Say, Z days after project kick-off or license fee payment. Identified solutions meeting requirements can have different quality attributes - costs (to build, to run), timeline, etc. These quality attributes can be used for solution analysis. E.g. one solution can be selected as a transition architecture and another as the target architecture. Backward chaining Family reasoning demonstrates application of the capability framework as a backward chaining engine. Family relationships such as grandfather and cousin are constructed by requiring and combining relationships such as child and sibling. Stream processing This possible application is similar to backward reasoning. Imagine an algorithmic trading strategy which uses several technical indicators, such as moving averages, to make trading decisions. Such a strategy would submit requirements for technical indicators which would include symbol, indicator configuration, time frame size. Technical indicators in turn would submit a requirement for raw trading data. A technical indicator such as moving average would start publishing its events once it receives enough trading data frames to compute its average. A trading engine would submit a requirement for strategies. A strategy factory may produce multiple strategies with different configurations. The trading engine would perform &ldquo;paper&rdquo; trades, select well-performing strategies and discard ones which perform poorly. This can be an ongoing process - if a strategy deteriorates then it is discarded and a new strategy is requested from strategy publishers - this process can be infinite. AI model training/fine-tuning This application is similar to stream processing and may be combined with backward reasoning. Let&rsquo;s say we want to train a model to answer questions about family relationships for a specific family. For example, &ldquo;Who is Alan&rsquo;s great grandmother?&rdquo; A single relationship in the model can be expressed in multiple ways in natural language. And multiple relationships can be expressed in a single sentence. For example: Elias is a person Elias is a man Elias is a male Elias is a parent of Fiona Fiona is a child of Elias Elias is a father of Fiona Fiona is a daughter of Elias Paul and Isa are parents of Lea and Elias &hellip; So, on top of a model there might be a collection of text generators. Output of those generators can be fed to a model: Supervised - question and answer &ldquo;How many sisters does Bryan have?&rdquo; - &ldquo;Two&rdquo; &ldquo;Who are Bryan&rsquo;s sisters?&rdquo; - &ldquo;Clara and Fiona&rdquo; Unsupervised - factual statements A similar approach can be applied to other models - customer/accounts, organization or architecture model, etc. For example, from the Internet Banking System we can generate something like &ldquo;Accounts Summary Controller uses Mainframe Banking System Facade to make API calls to the Mainframe Banking System over XML/HTTPS&rdquo;. &ldquo;make API calls&rdquo; may also be generated as &ldquo;connect&rdquo; or &ldquo;make requests&rdquo;. In a similar fashion a number of questions/answers can be generated. Javadoc ↩ See Eclipse Modeling Framework (EMF) - Tutorial and EMF Eclipse Modeling Framework book for more details. ↩ See EMF Ecore chapter in Beyond Diagrams book for a high-level overview of EMF Ecore. ↩"},"core/graph/index.html":{"path":"Core/Graph","action-uuid":"aa105ef7-f97f-430e-a6a0-1fa69d70885d","title":"Graph","content":"Nasdanika Graph module provides classes for visiting and processing graphs with two types of relationships between graph elements: Containment - one element is contained by another Connection - one element (node) connecting to another node via a connection. On the diagram below containment relationships are shown in bold black and connections in blue Examples of such graphs: A file systems with directories containing files and other directories. Connections may take multiple forms such as symbolic links or files, e.g. HTML files, referencing other files. Organizational structure with a hierarchy of organizational units and connections between them. For example, one unit may pass work product to another unit, or a unit may provide services to other units. Country, state, county, city, street, house, people living in that house; family relationships between people and ownership relationships between people and houses. Diagrams, such as Drawio diagrams with a diagram file (resource) containing a ${javadoc/org.nasdanika.drawio.Document document} which contains ${javadoc/org.nasdanika.drawio.Page pages}, pages containing ${javadoc/org.nasdanika.drawio.Layer layers}, and layers containing ${javadoc/org.nasdanika.drawio.Node nodes} and ${javadoc/org.nasdanika.drawio.Connection connections}. Nodes may be nested. Nasdanika Drawio is a module for working with Drawio diagrams. It is built on top of this module. Processes/(work)flows - processes consist of activities and nested processes. Activities are connected by transitions. Nasdanika Flow is an example of such process/flow. Distributed systems, such as cloud solutions - availability zones, data centers, clusters, nodes, pods, containers, processes inside containers. All of them communicating to each other via network connections. Work hierarchy and dependencies - in issue trackers issues may be organized into a hierarchy (e.g. Initiative, Epic, Story, Sub-Task in Jira) and have different types of dependencies. In Java a jar contains packages containing sub-packages and classes. Classes contain fields and methods. Fields reference their types, methods call methods of other classes, &hellip; EMF Ecore models contain packages. Packages contain sub-packages and classifiers including classes. Classes contain references to other classes. References may be configured as containment (composition) or non-containment. Sources Javadoc Graph API Processing Dispatching Processors and processor factories Reflective EMF PropertySourceEObjectFactory Conifguration properties child-injectors child-reference child-references incoming-injector incoming-reference outgoing-injector outgoing-reference parent-injector parent-reference registry-injectors registry-references semantic-uri source-injector source-reference spec ResourceSetPropertySourceEObjectFactory spec-format spec-uri target-reference target-injector Graph API The graph API has 3 interfaces: ${javadoc/org.nasdanika.graph.Element Element} - super-interface for Connection and Node below. Elements may contain other elements. Containment is implemented with &lt;T&gt; T accept(BiFunction&lt;? super Element, Map&lt;? extends Element, T&gt;, T&gt; visitor), which can be thought of as a hierarchical bottom-up reduce - the visitor function is invoked with an element being visited as its first argument and a map of element&rsquo;s children to results returned by the visitor as the second argument. For leaf elements the second argument may be either an empty map or null. Depending on the map type used by implementations they may also need to implement equals() and hashCode(). ${javadoc/org.nasdanika.graph.Node Node} extends Element and may have incoming and outgoing connections. ${javadoc/org.nasdanika.graph.Connection Connection} extends Element and has source and target nodes. Processing Graph processing means associating some behavior with graph elements. That behavior (code execution) may modify the graph or perform other actions. Examples of graph processing: Generate code from a diagram. Nasdanika Application Model Drawio module generates HTML sites from Drawio diagrams. Demos: Actions Flow Mind Map Update a diagram with information from external source. For example, there might be a diagram of a (software) system. Diagram elements can be updated as follows: During development - colors may reflect completion status. Say, in progress elements in blue, completed elements in green, elements with issues in red or amber. In production - color elements based on their monitoring status. Offline - grey, good - green, overloaded - amber, broken - red. The above two examples may be combined - a documentation site might be generated from a system diagram. The diagram may be updated with statuses as part of the generation process and embedded to the home page. A click on a diagram element would navigate to an element documentation page, which may contain detailed status information pulled from tracking/monitoring systems during generation. Dispatching One form of graph processing is dispatching of graph elements to Java methods annotated with ${javadoc/org.nasdanika.graph.Handler Handler} annotation. The annotation takes a Spring boolean expression. Graph elements are passed to methods for which the expression is blank or evaluates to true. Below is a code snippet from AliceBobHandlers class: @Handler(&quot;getProperty('my-property') == 'xyz'&quot;)\npublic String bob(Node bob) {\n\tSystem.out.println(bob.getLabel());\n\treturn bob.getLabel();\n}\n Below is a test method from TestDrawio.testDispatch() test method which dispatches to the above handler method: Document document = Document.load(getClass().getResource(&quot;alice-bob.drawio&quot;));\n\t\t\nAliceBobHandlers aliceBobHandlers = new AliceBobHandlers();\t\t\nObject result = document.dispatch(aliceBobHandlers);\nSystem.out.println(result);\n Dispatching is suitable for processing where processing logic for different graph elements does not need to access processing logic of other elements. An example of such logic would be updating diagram elements based on statuses retrieved from tracking/monitoring systems - each element is updated individually. Processors and processor factories ${javadoc/org.nasdanika.graph.processor} package provides means for creating graph element processors and wiring them together so they can interact. One area of where such functionality would be needed is executable diagrams. For example, a flow processor/simulator. Activity processors would need to pass control to connected activities via connection processors. Activity processors may also need to access facilities of their parent processors. The below diagram shows interaction of two nodes via a connection. Connections are bi-directional - source processor may interact with the target processor and vice versa. Some connections may be &ldquo;pass-through&rdquo; - just passing interactions without doing any processing. A pass-through connection is depicted below. Graph element processors are wired together with handlers and endpoints: A handler is a java object created by the client code and receiving invocations from other processors or client code via endpoints. An endpoint is a java object provided to the client code for interacting with other processors. An endpoint may be of the same type as a handler or a handler may be used as an endpoint. This might be the case if processing is performed sequentially in a single JVM. Alternatively, an endpoint may be of different type than the handler it passes invocations to. For example: Endpoint methods may return ${javadoc/java.util.concurrent.Future Futures} or ${javadoc/java.util.concurrent.CompletableFuture Completable Futures} of counterpart handler methods - when an endpoint method is invoked it would invoke handler&rsquo;s method asynchronously. Endpoint methods may take different parameters. E.g. an endpoint method can take ${javadoc/java.io.InputStream InputStream}, save it to some storage and pass a URL to the handler method. Processors can also interact by looking up other processors in the processor registry as explained below. Processors, handlers, and endpoints are created and wired by implementations of ${javadoc/org.nasdanika.graph.processor.ProcessorFactory ProcessorFactory} which should implement the following methods: createEndpoint() - creates an endpoint for a given connection, handler and handler type. ${javadoc/org.nasdanika.graph.processor.NopEndpointProcessorFactory NopEndpointProcessorFactory} provides a default implementation of this method which simply returns the handler. createProcessor() method. This method has a default implementation which does nothing - it simply returns ${javadoc/org.nasdanika.graph.processor.ProcessorInfo ProcessorInfo} with null processor. The purpose of this default implementation is to provide access to graph element&rsquo;s ${javadoc/org.nasdanika.graph.processor.ProcessorConfig ProcessorConfig} (or its subtypes ${javadoc/org.nasdanika.graph.processor.ConnectionProcessorConfig ConnectionProcessorConfig} or ${javadoc/org.nasdanika.graph.processor.NodeProcessorConfig NodeProcessorConfig} depending on the element type) to the client code. The client code can use the config to wire handlers and to call endpoints. It is similar to a printed circuit board with a CPU socket - the board provides wiring and the user inserts a CPU into the socket. parentProcessorInfoCallbackConsumer parameters provides a mechanism to get notified when element&rsquo;s parent processor is created. Processors are created bottom-up and child processors are created before parent processors. registryCallbackConsumer provides a mechanism to get notified when all processors have been created. isPassThrough() returns true by default meaning that connections do not perform any processing - they just connect nodes. Client code creates processors by calling one of createProcessors methods. These methods return a registry - Map&lt;Element,ProcessorInfo&lt;P&gt;&gt;. The registry allows the client code to interact with the handler/endpoint/processor wiring created from the graph. TestDrawio.testProcessor() method provides an example of using an anonymous implementation of NopEndpointProcessorFactory for graph processing. Reflective A good deal of graph processing is matching graph elements to code to be invoked for processing of that elements. It may be quite tedious for large graphs. ${javadoc/org.nasdanika.graph.processor.ReflectiveProcessorFactory ReflectiveProcessorFactory} uses annotations with Spring expressions to create processors and handlers and inject endpoints as explained below. ${javadoc/org.nasdanika.graph.processor.NopEndpointReflectiveProcessorFactory NopEndpointReflectiveProcessorFactory} extends ReflectiveProcessorFactory and implements NopEndpointProcessorFactory providing default implementations for createEndpoint() method. ReflectiveProcessorFactory constructor takes an vararg array of targets - objects with methods and fields annotated with: ${javadoc/org.nasdanika.graph.processor.Processor Processor} - annotation for a method creating an instance of processor which is then introspected to create handlers and inject/wire endpoints, parent, and registry. ${javadoc/org.nasdanika.graph.processor.Factory Factory} - field, method, or type annotation. Allows to cascade/group targets ${javadoc/org.nasdanika.graph.processor.Factories Factories} - field or method annotation which also allows to cascade/group targets Below is an example of a method annotated with Processor annotation: @Processor(&quot;label == 'Bob'&quot;)\npublic BobProcessor createBobProcessor(NodeProcessorConfig&lt;Object, Function&lt;String,String&gt;, Function&lt;String,String&gt;&gt; config) {\n\treturn new BobProcessor();\n}\n Objects returned from methods annotated with Processor are introspected for the following annotations: All processors: ${javadoc/org.nasdanika.graph.processor.ChildProcessor ChildProcessor} - field a method to inject processor or config of element&rsquo;s child matching the selector expression. ${javadoc/org.nasdanika.graph.processor.ChildProcessors ChildProcessors} - field or method to inject a map of children elements to their processor info. ${javadoc/org.nasdanika.graph.processor.ParentProcessor ParentProcessor} - field or method to inject processor or config of element&rsquo;s parent. ${javadoc/org.nasdanika.graph.processor.ProcessorElement ProcessorElement} - field or method to inject the graph element. ${javadoc/org.nasdanika.graph.processor.Registry Registry} - field or method to inject the registry - a map of graph elements to their info. ${javadoc/org.nasdanika.graph.processor.RegistryEntry RegistryEntry} - field or method to inject a matching registry entry. Node processors: ${javadoc/org.nasdanika.graph.processor.IncomingEndpoint IncomingEndpoint} - field or method to inject a matching incoming endpoint. ${javadoc/org.nasdanika.graph.processor.IncomingEndpoints IncomingEndpoints} - field or method to inject a map of incoming connections to their endpoints completion stages. ${javadoc/org.nasdanika.graph.processor.IncomingHandler IncomingHandler} - field or method to obtain a handler for an incoming connection. ${javadoc/org.nasdanika.graph.processor.IncomingHandlerConsumers IncomingHandlerConsumers} - field or method to inject a map of incoming connections to ${javadoc/java.util.function.Consumer consumers} of handlers. ${javadoc/org.nasdanika.graph.processor.OutgoingEndpoint OutgoingEndpoint} - field or method to inject a matching outgoing endpoint. ${javadoc/org.nasdanika.graph.processor.OutgoingEndpoints OutgoingEndpoints} - field or method to inject a map of outgoing connections to their endpoints completion stages. ${javadoc/org.nasdanika.graph.processor.OutgoingHandler OutgoingHandler} - field or method to obtain a handler for an outgoing connection. ${javadoc/org.nasdanika.graph.processor.OutgoingHandlerConsumers OutgoingHandlerConsumers} - field or method to inject a map of outgoing connections to consumers of handlers. Connection processors: ${javadoc/org.nasdanika.graph.processor.SourceEndpoint SourceEndpoint} - field or method into which a connection source endpoint is injected. Source endpoint allows the connection processor to interact with the connection source handler. ${javadoc/org.nasdanika.graph.processor.SourceHandler SourceHandler} - field or method from which the connection source handler is obtained. ${javadoc/org.nasdanika.graph.processor.TargetEndpoint TargetEndpoint} - field or method into which a connection target endpoint is injected. Target endpoint allows the connection processor to interact with the connection target handler. ${javadoc/org.nasdanika.graph.processor.TargetHandler TargetHandler} - Field or method from which the connection target handler is obtained. Below is an example of a node processor: public class AliceProcessor extends BobHouseProcessor {\n\t\n\t@ProcessorElement\n\tprivate Node aliceNode;\n\t\n\t@OutgoingHandler(&quot;target.label == 'Bob'&quot;)\n\tprivate Function&lt;String,String&gt; replyToBob = request -&gt; {\n\t\treturn request + System.lineSeparator() + &quot;[&quot; + aliceNode.getLabel() + &quot;] My name is &quot; + aliceNode.getLabel() + &quot;.&quot;;\n\t};\n\t\n\t@OutgoingEndpoint(&quot;target.label == 'Bob'&quot;)\n\tprivate Function&lt;String,String&gt; bobEndpoint;\n\t\n\tpublic String talkToBob(String str) {\n\t\treturn bobEndpoint.apply(&quot;[&quot; + aliceNode.getLabel() + &quot;] Hello!&quot;);\n\t}\t\n\n}\n Below is an example of a connection processor: public class AliceBobConnectionProcessor {\n\t\n\t@SourceEndpoint\n\tFunction&lt;String,String&gt; sourceEndpoint;\n\t\n\t@TargetEndpoint\n\tFunction&lt;String,String&gt; targetEndpoint;\n\t\n\t@SourceHandler\n\tFunction&lt;String,String&gt; sourceHandler = request -&gt; &quot;&gt;&gt; &quot; + targetEndpoint.apply(request);\n\t\n\t@TargetHandler\n\tFunction&lt;String,String&gt; targetHandler = response -&gt; &quot;&lt;&lt; &quot; + sourceEndpoint.apply(response);\t\n\t\n}\n EMF ${javadoc/org.nasdanika.graph.processor.emf.GraphProcessorResource GraphProcessorResource} is a base class for mapping graph elements to EMF Ecore model elements. Nasdanika Application Model Drawio is an example of such semantic mapping - it maps elements of Drawio diagrams to actions of Nasdanika Application Model which allows to generate HTML sites from diagrams. ${javadoc/org.nasdanika.graph.processor.emf.AbstractEObjectFactory} is a base class for mapping of graph elements to ${javadoc/org.eclipse.emf.ecore.EObject}&rsquo;s. Concrete implementations of this class can be used in combination with concrete implementations of GraphProcessorResource. ${javadoc/org.nasdanika.drawio.emf.DrawioEObjectFactory} is a specialization of AbstractEObjectFactory for Drawio diagrams, see Drawio for more details. ${javadoc/org.nasdanika.drawio.emf.ResourceSetDrawioEObjectFactory} is a further specialization of DrawioEObjectFactory. ${javadoc/org.nasdanika.drawio.emf.ResourceSetDrawioResourceFactory} leverages ResourceSetDrawioEObjectFactory for loading models from Drawio diagrams. There might be multiple processors and semantic models for the same graph, e.g. a diagram. It can be thought of as &ldquo;semantic inversion&rdquo; - in UML and tools like Sirius there is a model and multiple representations/views of the model. Visual (representation) elements are mapped to model elements, to it is a one-to-many relationship between a semantic element and its repreentations. In the case of graph processing and semantic mapping the relationship is many-to-many. Semantic elements are mapped to visual elements and there might be multiple semantic elements in different models mapping to the same visual element. At the same time, multiple visual elements may map to the same semantic element. An example of such mapping might be a map of United States with a a hierarchy of states and counties. Map elements can be mapped to different semantic models - weather, population, election results. Another example is a diagram of a software system where diagram elements can be mapped to: Action model (see above) to generate documentation. Issues in an issue tracker like Jira to visually depict progress in constructing the system. Diagram elements can be mapped to code generators so parts of the system can be generated. This can be used in software product lines where multiple similar solutions are created following the same pattern. The pattern can be captured and documented using diagrams. Once the system is build diagram elements can be mapped to build/deployment processes - execution of the diagram would result in deploying a solution. The diagram may be updated with deployment details, e.g. ARN&rsquo;s for AWS solutions. Once the system is built diagram elements can be mapped to monitoring models to show how the system operates. At this step deployment details injected into the diagram can be used to pull runtime information. With semantic mapping a diagram does not have to comply to a specific notation as it is the case with UML or Sirius diagrams. Meaning is assigned to diagram elements by semantic mapping, i.e. the notation may be created after the diagram. It can be beneficial when there is no notation for the problem domain at hand, the notation is too complex or people authoring diagrams are not familiar with the notation, but they know how to express what they know or need as a diagram. A practical example is mapping of existing diagrams in an organization to a semantic model or models. The semantic model may have to be elicited gradually from the diagrams and diagram elements would be mapped to the model in multiple stages. This can be thought of as a two-dimensional effort. One dimension is the depth/richness of the semantic model. It can be called the &ldquo;Exploration&rdquo; dimension - how well the problem domain is articulated. The other is the breadth - the number of diagram elements mapped to the model. It can be called &ldquo;Exploitation&rdquo; - how much the capability of understanding and expressing of the problem domain is utilized to achieve organizational goals. To put it slightly differently, semantic mapping approach can be used to elicit and codify organizational tribal knowledge - the &ldquo;secret sauce&rdquo; of an organization. An organization may start with pre-existing diagrams and map them to actions to generate documentation sites. Diagrams similar to this one can be used to document software systems. Flow diagrams can be used to document processes. The diagrams can be interrelated. For example, documentation of some software component may contain flow diagrams instructing how to perform operations on the component, e.g. deployment. The organization may also map diagrams to different models. E.g. to the Nasdanika Flow model for processes. Or the organization may create an Ecore model of the organization and map diagrams and other data sources to the model. Such a model can be documented using Nasdanika HTML Ecore. The documentation may include instructions how to map diagram elements to model elements. PropertySourceEObjectFactory ${javadoc/org.nasdanika.drawio.emf.PropertySourceEObjectFactory} is a specialization of ${javadoc/org.nasdanika.graph.processor.emf.AbstractEObjectFactory} for Drawio diagrams. It loads semantic information from properties of elements which implement ${javadoc/org.nasdanika.common.PropertySource} as explained below. This class is abstract. It does not dictate semantic specification format - subclasses shall implement T load(String spec, URI specBase, ProcessorConfig&lt;T&gt; config, ProgressMonitor progressMonitor) method. Conifguration properties child-injectors The value of this property shall be a Spring expression which injects children into the semantic element. Expression value is not used. To inject multiple children you may use linine list expression { &lt;expr&gt;[, &lt;expr&gt;] } The expression is evaluated in the context of the semantic element with the following variables: children - a map of children with child diagram elements as keys and their ${javadoc/org.nasdanika.graph.processor.ProcessorInfo}s as values config - semantic element config of type ${javadoc/org.nasdanika.graph.processor.ProcessorConfig} element - diagram element child-reference Reference name of the semantic parent to inject this semantic element into. child-references A YAML map of reference names to selectors - Spring boolean expressions. Children matching the selector expression are injected into the respective reference of the semantic element. Expressions are evaluated in the context of a child semantic element to be matched with the following variables: config - context (child) semantic element ProcessorConfig. element - child diagram element. parent - semantic element. parentConfig - semantic element ProcessorConfig. parentElement - diagram element. incoming-injector Connection property - a spring expression to inject this connection&rsquo;s semantic element (or source semantic element for pass-through connections) into its target&rsquo;s semantic element. Evaluated in the context of the target semantic element with the following variables: element - diagram element config - processor config connection - incoming connection incoming - incoming semantic element incomingConfig - incoming processor config incoming-reference Connection property specifying reference name of the connection&rsquo;s target semantic element to inject this connection semantic element or connection&rsquo;s source semantic element if the connection doesn&rsquo;t have its own semantic element (pass-through connection). outgoing-injector Connection property - a spring expression to inject this connection&rsquo;s semantic element (or target semantic element for pass-through connections) into its source&rsquo;s semantic element. Evaluated in the context of the source semantic element with the following variables: element - diagram element config - processor config connection - incoming connection outgoing - outgoing semantic element outgoingConfig - outgoing processor config outgoing-reference Connection property specifying reference name of the connection&rsquo;s source semantic element to inject this connection semantic element or connection&rsquo;s target semantic element if the connection doesn&rsquo;t have its own semantic element (pass-through connection). parent-injector Spring expression to inject parent into this semantic element. Evaluated in the context of the semantic element with the following variables: config - this semantic element processor config element - this diagram element parent - parent semantic element parentConfig - parent processor config parent-reference Reference name of this semantic element to inject the parent semantic element into. registry-injectors Spring expression to inject registry entries into this semantic element. Evaluated expression value is not used. The expression is evaluated in the context of the semantic element with the following variables: config - this semantic element processor config element - this diagram element registry - a map of diagram elements to their registry info&rsquo;s registry-references A YAML map of reference names to selectors - Spring boolean expressions. Registry entries matching the selector expression are injected into the respective reference of the semantic element. Expressions are evaluated in the context of a registry semantic element to be matched with the following variables: config - context (child) semantic element ProcessorConfig. element - child diagram element. registryElement - registry diagram element. registryConfig - processor config of the registry element. semanticElement - semantic element. semantic-uri URI of the semantic element definition. The difference between semantic-uri and spec-uri is that the spec is loaded as a string, interpolated, and then used to load the semantic element. spec-uri supports YAML and JSON definitions, whereas semantic-uri can point to definitions in multiple formats - XMI, Drawio, YAML, Json, MS Excel, &hellip; source-injector Connection property - a spring expression to inject this connection source semantic element into this connection semantic element. Evaluated in the context of the connection semantic element with the following variables: element - diagram element (connection) config - processor config source - source semantic element sourceConfig - source processor config source-reference Name of a reference to inject this connection source semantic element into this connection semantic element. spec Specification of the semantic element. YAML or JSON. Example: ncore-temporal: \n  offset: ${diagram-element/expr/outgoingConnections[0].label}\n  description: ${diagram-element/label}\n ResourceSetPropertySourceEObjectFactory ${javadoc/org.nasdanika.graph.emf.ResourceSetPropertySourceEObjectFactory} is a specialization of ${javadoc/org.nasdanika.graph.emf.PropertySourceEObjectFactory}. It is used by ${javadoc/org.nasdanika.graph.emf.ResourceSetPropertySourceResource} and ${javadoc/org.nasdanika.graph.emf.ResourceSetPropertySourceResourceFactory}. In ResourceSetPropertySourceEObjectFactory specification is interpolated with the following tokens: expression - spring expression evaluated in the context of the element with the following variables: context - ${javadoc/org.nasdanika.common.Context} providing access to additional information. config - processor config diagram-element/properties/&lt;property name&gt; - element property value for elements implementing ${javadoc/org.nasdanika.common.PropertySource}. Additional tokens may be provided by sub-classing ResourceSetPropertySourceEObjectFactory or ResourceSetPropertySourceResourceFactory and overriding getContext() method. spec-format Specification format - yaml or json. The format is inferred if not explicitly specified - specifications starting with { and ending with } are assumed to be JSON, YAML otherwise. spec-uri URI of the specification resolved relative to the document URI. Specification is loaded from the specification URI, interpolated, and then a semantic element is loaded from it. target-reference Name of a reference to inject this connection target semantic element into this connection semantic element. target-injector Connection property - a spring expression to inject this connection target semantic element into this connection semantic element. Evaluated in the context of the connection semantic element with the following variables: element - diagram element (connection) config - processor config target - target semantic element targetConfig - target processor config Root A B A1 A2 B1 Node Processor Node Processor source -&gt; target processor target -&gt; source processor Node Processor Node Processor"},"nsd-demo-cli/nsd/list-rules/index.html":{"path":"Demo CLI/nsd/list-rules","action-uuid":"379d8c39-b4f3-4c75-9b50-95eaacf4b5a2","title":"list-rules","content":"Version: org.nasdanika.launcher.demo@2024.5.1 \r\nUsage: nsd list-rules [-hV] [-o=&lt;output&gt;] [--exclude-rule\r\n                      [=&lt;ruleExcludes&gt;...]]... [--exclude-rule-set\r\n                      [=&lt;ruleSetExcludes&gt;...]]... [--include-rule\r\n                      [=&lt;ruleIncludes&gt;...]]... [--include-rule-set\r\n                      [=&lt;ruleSetIncludes&gt;...]]...\r\nLists available rules\r\n      --exclude-rule[=&lt;ruleExcludes&gt;...]\r\n                          ID's of rules to exclude\r\n      --exclude-rule-set[=&lt;ruleSetExcludes&gt;...]\r\n                          ID's of rule sets to exclude\r\n  -h, --help              Show this help message and exit.\r\n      --include-rule[=&lt;ruleIncludes&gt;...]\r\n                          ID's of rules to include\r\n      --include-rule-set[=&lt;ruleSetIncludes&gt;...]\r\n                          ID's of rule sets to include\r\n  -o, --output=&lt;output&gt;   Output file\r\n  -V, --version           Print version information and exit."},"nsd-demo-cli/nsd/rules/index.html":{"path":"Demo CLI/nsd/rules","action-uuid":"44599e33-d5cb-41eb-bfd7-4aa1da6529da","title":"rules","content":"Usage: nsd rules [-hV] [COMMAND]\r\nRules commands\r\n  -h, --help      Show this help message and exit.\r\n  -V, --version   Print version information and exit.\r\nCommands:\r\n  action-model  Generates rule set documentation action model\r\n  list          Lists available rule sets and rules\r\n  site          Generates rule set documentation site"},"nsd-cli/nsd/rules/list/index.html":{"path":"CLI/nsd/rules/list","action-uuid":"0293c4fa-788e-4ab7-89ae-49dd45271f82","title":"list","content":"Usage: nsd rules list [-dhjrV] [-o=&lt;output&gt;] [-p=&lt;progressOutput&gt;]\r\n                      [--exclude-rule[=&lt;ruleExcludes&gt;...]]...\r\n                      [--exclude-rule-set[=&lt;ruleSetExcludes&gt;...]]...\r\n                      [--include-rule[=&lt;ruleIncludes&gt;...]]...\r\n                      [--include-rule-set[=&lt;ruleSetIncludes&gt;...]]...\r\nLists available rule sets and rules\r\n  -d, --data              Output progress data\r\n      --exclude-rule[=&lt;ruleExcludes&gt;...]\r\n                          ID's of rules to exclude\r\n      --exclude-rule-set[=&lt;ruleSetExcludes&gt;...]\r\n                          ID's of rule sets to exclude\r\n  -h, --help              Show this help message and exit.\r\n      --include-rule[=&lt;ruleIncludes&gt;...]\r\n                          ID's of rules to include\r\n      --include-rule-set[=&lt;ruleSetIncludes&gt;...]\r\n                          ID's of rule sets to include\r\n  -j, --json              Output progress in JSON\r\n  -o, --output=&lt;output&gt;   Output file\r\n  -p, --progress=&lt;progressOutput&gt;\r\n                          Output file for progress monitor\r\n  -r, --[no-]rules        Output rules\r\n  -V, --version           Print version information and exit."},"nsd-cli/nsd/http-server/index.html":{"path":"CLI/nsd/http-server","action-uuid":"0387bc21-ffab-4c5d-9dde-9a6bdfd0bc24","title":"http-server","content":"Usage: nsd http-server [-hV] [--http-host=&lt;httpHost&gt;] [--http-port=&lt;httpPort&gt;]\r\n                       [--http-server-shutdown-timeout=&lt;timeout&gt;]\r\nServes HTTP routes\r\n  -h, --help      Show this help message and exit.\r\n      --http-host=&lt;httpHost&gt;\r\n                  HTTP host (network interface) to bind to\r\n      --http-port=&lt;httpPort&gt;\r\n                  HTTP port. If a port is not specified,\r\n                  an ephemeral port is used\r\n      --http-server-shutdown-timeout=&lt;timeout&gt;\r\n                  Timeout in seconds,\r\n                  defaults to 3 seconds\r\n  -V, --version   Print version information and exit."},"nsd-demo-cli/index.html":{"action-uuid":"9fb5bddc-d2f1-4a00-aba0-5eae48f700db","title":"Demo CLI","content":"Nasdanika Demo (CLI) is an extension of the Nasdanika CLI. It demonstrates how to build CLI suites on top of other suites. It also contains commands demonstrating some Nasdanika capabilities, but not useful AS-IS. For example, YAML inspection command shows how to implement inspection of YAML, but it performs only basic validations. Sources"},"nsd-demo-cli/nsd/http-server/index.html":{"path":"Demo CLI/nsd/http-server","action-uuid":"e3b295f5-b9cb-4aa8-803c-fc6f1207a3ce","title":"http-server","content":"Usage: nsd http-server [-hV] [--http-host=&lt;httpHost&gt;] [--http-port=&lt;httpPort&gt;]\r\n                       [--http-server-shutdown-timeout=&lt;timeout&gt;]\r\nServes HTTP routes\r\n  -h, --help      Show this help message and exit.\r\n      --http-host=&lt;httpHost&gt;\r\n                  HTTP host (network interface) to bind to\r\n      --http-port=&lt;httpPort&gt;\r\n                  HTTP port. If a port is not specified,\r\n                  an ephemeral port is used\r\n      --http-server-shutdown-timeout=&lt;timeout&gt;\r\n                  Timeout in seconds,\r\n                  defaults to 3 seconds\r\n  -V, --version   Print version information and exit."},"html/models/app/index.html":{"path":"HTML/Models/App","action-uuid":"0a4d2646-adb9-4f68-af29-73c6735a255d","title":"App","content":"TODO"},"nsd-cli/nsd/launcher/index.html":{"path":"CLI/nsd/launcher","action-uuid":"2682d1d7-2f7c-410b-9e03-7a98891595f2","title":"launcher","content":"Version: org.nasdanika.cli@2024.5.1 \r\nUsage: nsd launcher [-hstvV] [-a=&lt;args&gt;] [-b=&lt;base&gt;] [-c=&lt;className&gt;]\r\n                    [-C=&lt;classPathModules&gt;] [-f=&lt;optionsFile&gt;]\r\n                    [-j=&lt;javaCommand&gt;] [-m=&lt;moduleName&gt;] [-M=&lt;modulesFile&gt;]\r\n                    [-o=&lt;output&gt;] [-p=&lt;pathSeparator&gt;] [-P=&lt;prefix&gt;]\r\n                    [-r=&lt;rootModules&gt;] [&lt;repositories&gt;...]\r\nGenerates Java command line from directories of modules/jars\r\n      [&lt;repositories&gt;...]    Directories to scan for modules,\r\n                             defaults to lib\r\n  -a, --args=&lt;args&gt;          Arguments,\r\n                             defaults to %*\r\n  -b, --base=&lt;base&gt;          Base repositories directory\r\n  -c, --class=&lt;className&gt;    Application class,\r\n                             defaults to org.nasdanika.cli.Application\r\n  -C, --claspath-modules=&lt;classPathModules&gt;\r\n                             Comma-separated list of classpath modules\r\n  -f, --options-file=&lt;optionsFile&gt;\r\n                             File to output options to\r\n  -h, --help                 Show this help message and exit.\r\n  -j, --java=&lt;javaCommand&gt;   Java command,\r\n                             defaults to java\r\n  -m, --module=&lt;moduleName&gt;  Application module,\r\n                             defaults to org.nasdanika.cli\r\n  -M, --modules=&lt;modulesFile&gt;\r\n                             Modules to add to the module path\r\n  -o, --output=&lt;output&gt;      Output file\r\n  -p, --path-separator=&lt;pathSeparator&gt;\r\n                             Path separator,\r\n                             defaults to the system path separator\r\n  -P, --prefix=&lt;prefix&gt;      Module path prefix\r\n  -r, --root-modules=&lt;rootModules&gt;\r\n                             Comma-separated list of root modules\r\n                             Supports .* and .** patterns\r\n  -s, --absolute             Use absolute paths\r\n  -t, --options              Output only options\r\n  -v, --verbose              Output debug invformation\r\n  -V, --version              Print version information and exit."},"nsd-cli/nsd/rules/site/index.html":{"path":"CLI/nsd/rules/site","action-uuid":"fc9daf4f-a047-4873-ae4c-ac044f01d755","title":"site","content":"Usage: nsd rules site [-dfhjlRV] [-b=&lt;baseDir&gt;] [-m=&lt;domian&gt;]\r\n                      [-p=&lt;progressOutput&gt;] [-P=&lt;parallelism&gt;]\r\n                      [-r=&lt;pageErrors&gt;] [--root-action-icon=&lt;rootActionIcon&gt;]\r\n                      [--root-action-location=&lt;rootActionLocation&gt;]\r\n                      [--root-action-text=&lt;rootActionText&gt;] [-t=&lt;timeout&gt;]\r\n                      [-T=&lt;pageTemplate&gt;] [-w=&lt;workDir&gt;]\r\n                      [-c=&lt;String=String&gt;]... [-C=URL]...\r\n                      [-M=&lt;String=String&gt;]... [-e[=&lt;excludes&gt;...]]... [-i\r\n                      [=&lt;includes&gt;...]]... &lt;model&gt; &lt;output&gt;\r\nGenerates rule set documentation site\r\n      &lt;model&gt;                Model URI, resolved relative\r\n                             to the current directory\r\n                             or looked up in registered rule sets\r\n                             if -R option is provided\r\n      &lt;output&gt;               Output directory\r\n  -b, --base-dir=&lt;baseDir&gt;   Base directory\r\n  -c, --context-entry=&lt;String=String&gt;\r\n                             Context entries.\r\n                             Shadow entries in contexts and mounts.\r\n  -C, --context=URL          Context resource URL relative to the current\r\n                               directory. YAML, JSON, or properties. In\r\n                               properties dots are treated as key path\r\n                               separators. Type is inferred from the content\r\n                               type header, if it is present, or extension.\r\n                               Contexts are composed in the order of\r\n                               definition, later context entries shadowing the\r\n                               former\r\n  -d, --data                 Output progress data\r\n  -e, --exclude[=&lt;excludes&gt;...]\r\n                             Output directory clean excludes\r\n                             Ant pattern\r\n  -f, --file                 Mdel parameter is a file path\r\n  -h, --help                 Show this help message and exit.\r\n  -i, --include[=&lt;includes&gt;...]\r\n                             Output directory clean includes\r\n                             Ant pattern\r\n  -j, --json                 Output progress in JSON\r\n  -l, --[no-]clean           Clean working directory\r\n                             defaults to true\r\n  -m, --domain=&lt;domian&gt;      Sitemap domain\r\n  -M, --context-mount=&lt;String=String&gt;\r\n                             MappingContext resource URL relative to the\r\n                               current directory. YAML, JSON, or properties. In\r\n                               properties dots are treated as key path\r\n                               separators. Type is inferred from the content\r\n                               type header, if it is present, or extension.\r\n                               Mounts shadow context entries.\r\n  -p, --progress=&lt;progressOutput&gt;\r\n                             Output file for progress monitor\r\n  -P, --parallelism=&lt;parallelism&gt;\r\n                             If the value greater than one then an executor\r\n                               service is created and injected into the context\r\n                               to allow concurrent execution.\r\n  -r, --errors=&lt;pageErrors&gt;  Expected number of page errors\r\n  -R, --registered           Use registered rule set\r\n                             with provided URI\r\n      --root-action-icon=&lt;rootActionIcon&gt;\r\n                             Root action icon\r\n      --root-action-location=&lt;rootActionLocation&gt;\r\n                             Root action location\r\n      --root-action-text=&lt;rootActionText&gt;\r\n                             Root action text\r\n  -t, --timeout=&lt;timeout&gt;    If parallelism is greater than one this option\r\n                               specifies timout in seconds awaiting completion\r\n                               of execution. Default value is 60.\r\n  -T, --page-template=&lt;pageTemplate&gt;\r\n                             Page template URI relative\r\n                             to the current directory\r\n  -V, --version              Print version information and exit.\r\n  -w, --work-dir=&lt;workDir&gt;   Working directory\r\nExit codes:\r\n  Non-negative number   Delegate result\r\n  -1                    Unhandled exception during execution\r\n  -2                    Invalid input\r\n  -3                    Diagnostic failed\r\n  -4                    Execution failed or was cancelled, successful rollback\r\n  -5                    Execution failed or was cancelled, rollback failed\r\n  -6                    Executor service termination timed out"},"nsd-demo-cli/nsd/app/index.html":{"path":"Demo CLI/nsd/app","action-uuid":"b926df1a-827d-4b94-8cc2-20d91837e0d8","title":"app","content":"Version: org.nasdanika.html.model.app.gen.cli@2024.5.1 \r\nUsage: nsd app [-hV] [COMMAND]\r\nHTML Application model commands\r\n  -h, --help      Show this help message and exit.\r\n  -V, --version   Print version information and exit.\r\nCommands:\r\n  site  Generates HTML site"},"html/models/bootstrap/index.html":{"path":"HTML/Models/Bootstrap","action-uuid":"3f232153-36f9-4bd7-8b62-1a5dc6e6dfac","title":"Bootstrap","content":"TODO"},"nsd-demo-cli/nsd/module-graph/index.html":{"path":"Demo CLI/nsd/module-graph","action-uuid":"f69e50a6-4cb9-4641-8eac-4eeecbdc1ba6","title":"module-graph","content":"Version: org.nasdanika.launcher.demo@2024.5.1 \r\nUsage: nsd module-graph [-h=&lt;height&gt;] [-t=&lt;template&gt;] [-w=&lt;width&gt;]\r\n                        [-e=&lt;excludeModules&gt;]... [-i=&lt;includeModules&gt;]...\r\n                        &lt;output&gt;\r\nGenerates module dependency graph\r\n      &lt;output&gt;            Output file\r\n  -e, --exclude-modules=&lt;excludeModules&gt;\r\n                          Modules to exclude\r\n                          Supports .* and .** patterns\r\n  -h, --height=&lt;height&gt;   Layout height, defaults to 1500\r\n  -i, --include-modules=&lt;includeModules&gt;\r\n                          Modules to include\r\n                          Supports .* and .** patterns\r\n  -t, --template=&lt;template&gt;\r\n                          HTML page template\r\n  -w, --width=&lt;width&gt;     Layout width, defaults to 2000"},"core/persistence/index.html":{"path":"Core/Persistence","action-uuid":"a052050d-7cfe-4b2f-8f94-fc143bfb87d7","title":"Persistence","content":"Sources Javadoc"},"html/emf/index.html":{"path":"HTML/EMF","action-uuid":"c6bccbed-2563-4066-9ed5-b092765dd8a8","title":"EMF","content":"Sources Javadoc"},"nsd-demo-cli/nsd/launcher/index.html":{"path":"Demo CLI/nsd/launcher","action-uuid":"ef8d8cc4-e6d8-453b-a767-bffcd6fe1e52","title":"launcher","content":"Version: org.nasdanika.cli@2024.5.1 \r\nUsage: nsd launcher [-hstvV] [-a=&lt;args&gt;] [-b=&lt;base&gt;] [-c=&lt;className&gt;]\r\n                    [-C=&lt;classPathModules&gt;] [-f=&lt;optionsFile&gt;]\r\n                    [-j=&lt;javaCommand&gt;] [-m=&lt;moduleName&gt;] [-M=&lt;modulesFile&gt;]\r\n                    [-o=&lt;output&gt;] [-p=&lt;pathSeparator&gt;] [-P=&lt;prefix&gt;]\r\n                    [-r=&lt;rootModules&gt;] [&lt;repositories&gt;...]\r\nGenerates Java command line from directories of modules/jars\r\n      [&lt;repositories&gt;...]    Directories to scan for modules,\r\n                             defaults to lib\r\n  -a, --args=&lt;args&gt;          Arguments,\r\n                             defaults to %*\r\n  -b, --base=&lt;base&gt;          Base repositories directory\r\n  -c, --class=&lt;className&gt;    Application class,\r\n                             defaults to org.nasdanika.cli.Application\r\n  -C, --claspath-modules=&lt;classPathModules&gt;\r\n                             Comma-separated list of classpath modules\r\n  -f, --options-file=&lt;optionsFile&gt;\r\n                             File to output options to\r\n  -h, --help                 Show this help message and exit.\r\n  -j, --java=&lt;javaCommand&gt;   Java command,\r\n                             defaults to java\r\n  -m, --module=&lt;moduleName&gt;  Application module,\r\n                             defaults to org.nasdanika.cli\r\n  -M, --modules=&lt;modulesFile&gt;\r\n                             Modules to add to the module path\r\n  -o, --output=&lt;output&gt;      Output file\r\n  -p, --path-separator=&lt;pathSeparator&gt;\r\n                             Path separator,\r\n                             defaults to the system path separator\r\n  -P, --prefix=&lt;prefix&gt;      Module path prefix\r\n  -r, --root-modules=&lt;rootModules&gt;\r\n                             Comma-separated list of root modules\r\n                             Supports .* and .** patterns\r\n  -s, --absolute             Use absolute paths\r\n  -t, --options              Output only options\r\n  -v, --verbose              Output debug invformation\r\n  -V, --version              Print version information and exit."},"core/cli/index.html":{"path":"Core/CLI","action-uuid":"90d839a6-d805-46fd-b8b8-60eff9e802fe","title":"CLI","content":"Classes in this module allow to declaratively construct command line interfaces. It uses picocli to execute commands and capability framework to collect sub-commands and mix-ins. This way command line interfaces can be constructed top-down (default picocli functionality) - parent commands explicitly define sub-commands, and bottom-up - sub-commands are added to parent commands by the framework. Top-down construction can be done using out-the-box picocli capabilities - programmatic add and annotations. Both top-down and bottom-up construction can be done using the capability framework which allows sub-commands/mix-ins to request capabilities they need and add themselves to parent commands only if all requirements are met. The module provides a capability to build polymorphic CLI&rsquo;s - sub-commands and mix-ins may override other sub-commands and mix-ins with the same name. This is similar to method overriding in Object-Oriented languages like Java. For example, a base CLI package may have a basic implementation of some sub-command. A derived package would add dependencies with advanced sub-commands to pom.xml. These sub-commands would replace (override) basic sub-commands during construction of the command hierarchy. Sources Javadoc Beyond PicoCLI Medium story Contributing sub-commands @SubCommands annotation @Parent annotation Programmatic match Contributing mix-ins @MixIns annotation @Parent annotation Programmatic match Overriding Extended documentation Commands Mix-ins Building distributions Downloading dependencies Generating launcher scripts Assembly Contributing sub-commands In addition to the picocli way of adding sub-commands programmatically and using @Command annotation subcommands element this module provides a few more ways to contribute sub-commands which are explained below. In all cases create a sub-class of SubCommandCapabilityFactory and implement/override the following methods: getCommandType - used for declarative matching createCommand for imperative (programmatic) matching doCreateCommand: Declarative - in combination with @SubCommands or @Parent Imperative - override match() as well. Add to module-info.java: provides org.nasdanika.capability.CapabilityFactory with &lt;factory class&gt; opens &lt;sub-command package name&gt; to info.picocli, org.nasdanika.html.model.app.gen.cli; Opening to org.nasdanika.html.model.app.gen.cli is needed if you want to generate extended documentation (see below). @SubCommands annotation This one is similar to @Command.subcommands - the parent command declares types of sub-commands. However: Sub-commands are collected using the capability framework from SubCommandCapabilityFactory&rsquo;s. Sub-commands types listed in the annotation are base types - classes or interfaces - not necessarily concrete implementation types. E.g. you may have HelpCommand interface or base class and all commands implementing/extending this class will be added to the parent command. If there are two commands with the same name one of them might override the other as explained below. @Parent annotation In this case the sub-command or mix-in class are annotated with @Parent annotation listing types of parents. The sub-command/mix-in will be added to all commands in the hierarchy which are instances of the specified parent types - exact class, interface implementation, or sub-class. Programmatic match The above two ways of matching parent commands and sub-commands are handled by the SubCommandCapabilityFactory.match() method. You may override this method or createCommand() method to programmatically match parent path and decide whether to contribute a sub-command or not. Contributing mix-ins Similar to sub-commands, mix-ins can be contributed top-down and bottom-up - declaratively using annotations and programmatically. In all cased create s sub-class of MixInCapabilityFactory, implement/override: getMixInType() - for declarative matching getName() createMixIn() for imperative matching, or doCreateMixIn() Declarative - in combination with @MixIns or @Parent Imperative - override match() as well. Add to module-info.java: provides org.nasdanika.capability.CapabilityFactory with &lt;factory class&gt; opens &lt;mix-in package name&gt; to info.picocli; @MixIns annotation Mix-ins are collected using the capability framework from MixInCapabilityFactory&rsquo;s. Mix-in types listed in the annotation are base types - classes or interfaces - not necessarily concrete implementation types. @Parent annotation See &ldquo;@Parent annotation&rdquo; sub-section in &ldquo;Contributing sub-commands&rdquo; section above. Programmatic match The above two ways of matching parent commands and sub-commands/mix-ins are handled by the MixInCapabilityFactory.match() method. You may override this method or createMixIn() method to programmatically match parent path and decide whether to contribute a mix-in or not. Overriding A command/mix-in overrides another command/mix-in if: It is a sub-class of that command/mix-in It implements Overrider interface and returns true from overrides(Object other) method. It is annotated with @Overrides and the other command is an instance of one of the value classes. Extended documentation You may annotate commands with @Description to provide additional information in generated HTML site. Commands The CLI module provides several base command classes: CommandBase - base class with standard help mix-in CommandGroup - base class for commands which don&rsquo;t have own functionality, only sub-commands ContextCommand - command with options to configure Context DelegatingCommand - options to configure Context and ProgressMonitor and delegate execution to SupplierFactory HelpCommand - outputs usage for the command hierarchy in text, html, action model, or generates a documentation site Mix-ins The module also provides several mix-ins: ContextMixIn - creates and configures Context ProgressMonitorMixIn - creates and configures ProgressMonitor ResourceSetMixIn - creates and configures ResourceSet using CapabilityLoader to add packages, resource and adapter factories, &hellip; Building distributions A distribution is a collection of modules contributing commands and mix-ins plus launcher scripts for different operating systems. org.nasdanika.cli and org.nasdanika.launcher modules are examples of building distributions as part of Maven build. Building a distribution involves the following steps: Downloading modules (dependencies) Generating launcher scripts Building an assembly (zip) All of the above steps are executed by mvn verify or mvn clean verify Downloading dependencies Dependencies can be downloaded using Maven dependency plug-in: &lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;\n\txmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;\n\txsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;\n\t\n\t...\n\n\t&lt;dependencies&gt;\n\t\t...\n\t&lt;/dependencies&gt;\n\n\t&lt;build&gt;\n\t\t&lt;plugins&gt;\n\t\t\t...\n\n\t\t\t&lt;plugin&gt;\n\t\t\t\t&lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;\n\t\t\t\t&lt;artifactId&gt;maven-dependency-plugin&lt;/artifactId&gt;\n\t\t\t\t&lt;version&gt;3.6.1&lt;/version&gt;\n\t\t\t\t&lt;executions&gt;\n\t\t\t\t\t&lt;execution&gt;\n\t\t\t\t\t\t&lt;id&gt;copy-dependencies&lt;/id&gt;\n\t\t\t\t\t\t&lt;phase&gt;prepare-package&lt;/phase&gt;\n\t\t\t\t\t\t&lt;goals&gt;\n\t\t\t\t\t\t\t&lt;goal&gt;copy-dependencies&lt;/goal&gt;\n\t\t\t\t\t\t&lt;/goals&gt;\n\t\t\t\t\t\t&lt;configuration&gt;\n\t\t\t\t\t\t\t&lt;outputDirectory&gt;\n\t\t\t\t\t\t\t\t${project.build.directory}/dist/lib\n\t\t\t\t\t\t\t&lt;/outputDirectory&gt;\n\t\t\t\t\t\t\t&lt;useRepositoryLayout&gt;true&lt;/useRepositoryLayout&gt;\t\t\t\t\t\t\t\n\t\t\t\t\t\t&lt;/configuration&gt;\n\t\t\t\t\t&lt;/execution&gt;\n\t\t\t\t&lt;/executions&gt;\n\t\t\t&lt;/plugin&gt;\n\t\t\t\n\t\t\t...\n\t&lt;/build&gt;\n\n\t...   \n&lt;/project&gt;\n Generating launcher scripts Launcher scripts can be generated using launcher command. The command can be issued manually from the command line. Alternatively, you can execute the launcher command from an integration test as shown below: public class BuildDistributionIT {\n\t\t\n\t@Test\n\tpublic void generateLauncher() throws IOException {\n\t\tfor (File tf: new File(&quot;target&quot;).listFiles()) {\n\t\t\tif (tf.getName().endsWith(&quot;.jar&quot;) &amp;&amp; !tf.getName().endsWith(&quot;-sources.jar&quot;) &amp;&amp; !tf.getName().endsWith(&quot;-javadoc.jar&quot;)) {\n\t\t\t\tFiles.copy(\n\t\t\t\t\t\ttf.toPath(), \n\t\t\t\t\t\tnew File(new File(&quot;target/dist/lib&quot;), tf.getName()).toPath(), \n\t\t\t\t\t\tStandardCopyOption.REPLACE_EXISTING);\t\t\n\t\t\t}\n\t\t}\t\t\n\t\t\n\t\tModuleLayer layer = Application.class.getModule().getLayer();\n\t\ttry (Writer writer = new FileWriter(new File(&quot;target/dist/modules&quot;))) {\n\t\t\tfor (String name: layer.modules().stream().map(Module::getName).sorted().toList()) {\n\t\t\t\twriter.write(name);\n\t\t\t\twriter.write(System.lineSeparator());\n\t\t\t};\n\t\t}\n\t\t\n\t\tCommandLine launcherCommandLine = new CommandLine(new LauncherCommand());\n\t\tlauncherCommandLine.execute(\n\t\t\t\t&quot;-b&quot;, &quot;target/dist&quot;, \n\t\t\t\t&quot;-M&quot;, &quot;target/dist/modules&quot;, \n\t\t\t\t&quot;-f&quot;, &quot;options&quot;,\n\t\t\t\t&quot;-j&quot;, &quot;@java&quot;,\n\t\t\t\t&quot;-o&quot;, &quot;nsd.bat&quot;);\n\t\t\n\t\tlauncherCommandLine.execute(\n\t\t\t\t&quot;-b&quot;, &quot;target/dist&quot;, \n\t\t\t\t&quot;-M&quot;, &quot;target/dist/modules&quot;, \n\t\t\t\t&quot;-j&quot;, &quot;#!/bin/bash\\n\\njava&quot;,\n\t\t\t\t&quot;-o&quot;, &quot;nsd&quot;,\n\t\t\t\t&quot;-p&quot;, &quot;:&quot;,\n\t\t\t\t&quot;-a&quot;, &quot;$@&quot;);\t\t\n\t\t\n\t}\n\n}\n If the Maven project which builds the distribution does not contribute its own code, then the for loop copying the jar file can be omitted. Assembly Create an assembly file dist.xml similar to the one below in src\\assembly directory: &lt;assembly xmlns=&quot;http://maven.apache.org/ASSEMBLY/2.0.0&quot;\n  xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;\n  xsi:schemaLocation=&quot;http://maven.apache.org/ASSEMBLY/2.0.0 http://maven.apache.org/xsd/assembly-2.0.0.xsd&quot;&gt;\n  &lt;id&gt;dist&lt;/id&gt;\n  &lt;formats&gt;\n    &lt;format&gt;tar.gz&lt;/format&gt;\n    &lt;format&gt;tar.bz2&lt;/format&gt;\n    &lt;format&gt;zip&lt;/format&gt;\n  &lt;/formats&gt;\n  &lt;fileSets&gt;\n    &lt;fileSet&gt;\n      &lt;directory&gt;${project.build.directory}/dist&lt;/directory&gt;\n      &lt;outputDirectory&gt;/&lt;/outputDirectory&gt;\n      &lt;useDefaultExcludes&gt;false&lt;/useDefaultExcludes&gt;\n    &lt;/fileSet&gt;\n  &lt;/fileSets&gt;\n&lt;/assembly&gt;\n then add the following plugin definition to pom.xml: &lt;plugin&gt;\n\t&lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt;\n\t&lt;version&gt;3.7.1&lt;/version&gt;\n\t&lt;configuration&gt;\n\t\t&lt;outputDirectory&gt;${project.build.directory}&lt;/outputDirectory&gt;\n\t\t&lt;formats&gt;zip&lt;/formats&gt;\n\t\t&lt;appendAssemblyId&gt;false&lt;/appendAssemblyId&gt;\n\t\t&lt;finalName&gt;nsd-cli-${project.version}&lt;/finalName&gt;\n\t\t&lt;descriptors&gt;\n\t\t\t&lt;descriptor&gt;src/assembly/dist.xml&lt;/descriptor&gt;\n\t\t&lt;/descriptors&gt;\n\t&lt;/configuration&gt;\n        &lt;executions&gt;\n          &lt;execution&gt;\n            &lt;id&gt;create-archive&lt;/id&gt;\n            &lt;phase&gt;verify&lt;/phase&gt;\n            &lt;goals&gt;\n              &lt;goal&gt;single&lt;/goal&gt;\n            &lt;/goals&gt;\n          &lt;/execution&gt;\n        &lt;/executions&gt;\n&lt;/plugin&gt;\t\t        \t\t\t\n Change the final name to your CLI name. E.g. my-company-cli."},"core/resources/index.html":{"path":"Core/Resources","action-uuid":"27c4d62b-3463-4b1e-ae2b-fe9d385a18a6","title":"Resources","content":"Sources Javadoc"},"nsd-demo-cli/nsd/rules/action-model/index.html":{"path":"Demo CLI/nsd/rules/action-model","action-uuid":"8c6f2c85-2d64-434e-bea2-233f91f7f74a","title":"action-model","content":"Usage: nsd rules action-model [-dfhjRV] [-p=&lt;progressOutput&gt;]\r\n                              [-c=&lt;String=String&gt;]... [-C=URL]...\r\n                              [-M=&lt;String=String&gt;]... &lt;model&gt; &lt;output&gt;\r\nGenerates rule set documentation action model\r\n      &lt;model&gt;         Model URI or file path, resolved relative\r\n                      to the current directory\r\n                      or looked up in registered rule sets\r\n                      if -R option is provided\r\n      &lt;output&gt;        Output file\r\n  -c, --context-entry=&lt;String=String&gt;\r\n                      Context entries.\r\n                      Shadow entries in contexts and mounts.\r\n  -C, --context=URL   Context resource URL relative to the current directory.\r\n                        YAML, JSON, or properties. In properties dots are\r\n                        treated as key path separators. Type is inferred from\r\n                        the content type header, if it is present, or\r\n                        extension. Contexts are composed in the order of\r\n                        definition, later context entries shadowing the former\r\n  -d, --data          Output progress data\r\n  -f, --file          Mdel parameter is a file path\r\n  -h, --help          Show this help message and exit.\r\n  -j, --json          Output progress in JSON\r\n  -M, --context-mount=&lt;String=String&gt;\r\n                      MappingContext resource URL relative to the current\r\n                        directory. YAML, JSON, or properties. In properties\r\n                        dots are treated as key path separators. Type is\r\n                        inferred from the content type header, if it is\r\n                        present, or extension. Mounts shadow context entries.\r\n  -p, --progress=&lt;progressOutput&gt;\r\n                      Output file for progress monitor\r\n  -R, --registered    Use registered rule set\r\n                      with provided URI\r\n  -V, --version       Print version information and exit."},"practices/index.html":{"action-uuid":"bfaf53da-5d2e-40e9-b216-0a500c369703","title":"Practices","content":"Practices explain how to use Nasdanika products to achieve specific goals and explain why particular design choices wer made. The enterprise model provides deeper insight on the WHY in general. The practices are organized into an enterprise continuum from the most generic on the left to the most specific on the right. However, the most specific on the right is still generic and needs to be specialized for a particular application (embodiment): Analysis, Visualization &amp; Generation - describes a general approach on using Nasdanika products. Java Analysis, Visualization &amp; Generation - application of the above to the Java model1 Loading and analyzing Java sources and bytecode, generation of non-Java artifacts such as HTML reports Generation of Java sources. JUnit test generation for low coverage methods - further specialization of the Java practice to identify methods with low test coverage using the Coverage Model and then generate JUnit tests for those methods using the Java model and OpenAI. You can think of the three practices above as progressive &ldquo;binding of decision&rdquo; as you move from the left to the right to reach &ldquo;executability&rdquo; - ability to deliver value. A java analogy for progressive specialization would be incremental binding of generic types as exemplified below: Map&lt;K,V&gt; - generic map. MyMap&lt;K extends Comparable&gt; extends Map&lt;&lt;K, MyValue&lt;K&gt;&gt; - the above map bound to a single generic parameter with an upper bound. It is a specialization of the above generic map which is also generic. Some decisions were bound, but there are still decisions to be bound. MyMap&lt;String&gt; theMap = ...; - fully bound map. Decisions are bound at variation point. For example, &ldquo;storage&rdquo; is a variation point, &ldquo;blob storage&rdquo; is one of alternatives, decision to use &ldquo;blob storage&rdquo; binds the variation point to a specific alternative. Decision binding forms a graph. Once you bind, say, &ldquo;storage&rdquo; variation point, some downstream alternatives may become unavailable because they are incompatible with that binding. Some might be available, but make no sense. For example, a decision to send data unencrypted over a public network is compatible with a decision to purchase some additional strong encryption hardware to use on-prem, but does it make business sense? Different alternatives feature different &ldquo;quality attributes&rdquo; - performance, reliability, cost. As the number of variation points and alternatives grows purely human-based decision making becomes inefficient. In this case variation points can be modeled as requirements and alternatives as capability providers or capabilities with quality attributes (seecapability). After this a list of &ldquo;designs&rdquo; (a.k.a. &ldquo;provisioning plans&rdquo;) can be created. A design/provisioning plan is a collection of compatible capabilities. If a list of designs is short enough it can be analyzed by humans directly. In the case of long lists or a large number of very similar designs decision analysis can be employed for making a selection of a design which is best fit for purpose. The page provides a general overview and the book goes into more details. ↩"},"nsd-demo-cli/nsd/rules/list/index.html":{"path":"Demo CLI/nsd/rules/list","action-uuid":"e2eb3de7-45bc-4e86-b431-a2e35614ce25","title":"list","content":"Usage: nsd rules list [-dhjrV] [-o=&lt;output&gt;] [-p=&lt;progressOutput&gt;]\r\n                      [--exclude-rule[=&lt;ruleExcludes&gt;...]]...\r\n                      [--exclude-rule-set[=&lt;ruleSetExcludes&gt;...]]...\r\n                      [--include-rule[=&lt;ruleIncludes&gt;...]]...\r\n                      [--include-rule-set[=&lt;ruleSetIncludes&gt;...]]...\r\nLists available rule sets and rules\r\n  -d, --data              Output progress data\r\n      --exclude-rule[=&lt;ruleExcludes&gt;...]\r\n                          ID's of rules to exclude\r\n      --exclude-rule-set[=&lt;ruleSetExcludes&gt;...]\r\n                          ID's of rule sets to exclude\r\n  -h, --help              Show this help message and exit.\r\n      --include-rule[=&lt;ruleIncludes&gt;...]\r\n                          ID's of rules to include\r\n      --include-rule-set[=&lt;ruleSetIncludes&gt;...]\r\n                          ID's of rule sets to include\r\n  -j, --json              Output progress in JSON\r\n  -o, --output=&lt;output&gt;   Output file\r\n  -p, --progress=&lt;progressOutput&gt;\r\n                          Output file for progress monitor\r\n  -r, --[no-]rules        Output rules\r\n  -V, --version           Print version information and exit."},"core/emf/index.html":{"path":"Core/EMF","action-uuid":"435f462f-6788-4725-a493-f86d9961fdb3","title":"EMF","content":"Sources Javadoc"},"nsd-cli/nsd/index.html":{"path":"CLI/nsd","action-uuid":"a7d901c3-8031-4175-b831-251ca51ba9d6","title":"nsd","content":"Version: org.nasdanika.cli@2024.5.1 \r\nUsage: nsd [-hV] COMMAND\r\nNasdanika Command Line Interface\r\n  -h, --help      Show this help message and exit.\r\n  -V, --version   Print version information and exit.\r\nCommands:\r\n  launcher     Generates Java command line from directories of modules/jars\r\n  app          HTML Application model commands\r\n  help         Outputs usage for all registred commands\r\n  http-server  Serves HTTP routes\r\n  java         Commands related to Java\r\n  rules        Rules commands"},"nsd-demo-cli/nsd/inspect-yaml/index.html":{"path":"Demo CLI/nsd/inspect-yaml","action-uuid":"2667cc0d-8a9d-49c9-a086-19135466763c","title":"inspect-yaml","content":"Version: org.nasdanika.launcher.demo@2024.5.1 \r\nUsage: nsd inspect-yaml [-dhjV] [--parallel] [--stop-on-first-fail]\r\n                        [--limit=&lt;limit&gt;] [-o=&lt;output&gt;] [-p=&lt;progressOutput&gt;]\r\n                        [-c=&lt;String=String&gt;]... [-C=URL]...\r\n                        [--content-type-resource-factory=&lt;String=Class&gt;]...\r\n                        [--extension-resource-factory=&lt;String=Class&gt;]...\r\n                        [-f=&lt;failOnSeverities&gt;]... [-M=&lt;String=String&gt;]...\r\n                        [--protocol-resource-factory=&lt;String=Class&gt;]... [-e\r\n                        [=&lt;resourceExcludes&gt;...]]... [--exclude-rule\r\n                        [=&lt;ruleExcludes&gt;...]]... [--exclude-rule-set\r\n                        [=&lt;ruleSetExcludes&gt;...]]... [--exclude-type\r\n                        [=&lt;typeExcludes&gt;...]]... [-i\r\n                        [=&lt;resourceIncludes&gt;...]]... [--include-rule\r\n                        [=&lt;ruleIncludes&gt;...]]... [--include-rule-set\r\n                        [=&lt;ruleSetIncludes&gt;...]]... [--include-type\r\n                        [=&lt;typeIncludes&gt;...]]... &lt;inputs&gt;...\r\nDemo of YAML inspection\r\n      &lt;inputs&gt;...            Files and directories\r\n                             to inspect\r\n  -c, --context-entry=&lt;String=String&gt;\r\n                             Context entries.\r\n                             Shadow entries in contexts and mounts.\r\n  -C, --context=URL          Context resource URL relative to the current\r\n                               directory. YAML, JSON, or properties. In\r\n                               properties dots are treated as key path\r\n                               separators. Type is inferred from the content\r\n                               type header, if it is present, or extension.\r\n                               Contexts are composed in the order of\r\n                               definition, later context entries shadowing the\r\n                               former\r\n      --content-type-resource-factory=&lt;String=Class&gt;\r\n                             Maps content type to resource factory class\r\n  -d, --data                 Output progress data\r\n  -e, --exclude-resource[=&lt;resourceExcludes&gt;...]\r\n                             Resources to exclude from inspection\r\n                             Ant pattern\r\n      --exclude-rule[=&lt;ruleExcludes&gt;...]\r\n                             ID's of rules to exclude\r\n      --exclude-rule-set[=&lt;ruleSetExcludes&gt;...]\r\n                             ID's of rule sets to exclude\r\n      --exclude-type[=&lt;typeExcludes&gt;...]\r\n                             Target types to exclude\r\n      --extension-resource-factory=&lt;String=Class&gt;\r\n                             Maps extension to resource factory class\r\n  -f, --fail-on=&lt;failOnSeverities&gt;\r\n                             Names of severities to fail on\r\n  -h, --help                 Show this help message and exit.\r\n  -i, --include-resource[=&lt;resourceIncludes&gt;...]\r\n                             Resources to include in inspection\r\n                             Ant pattern\r\n      --include-rule[=&lt;ruleIncludes&gt;...]\r\n                             ID's of rules to include\r\n      --include-rule-set[=&lt;ruleSetIncludes&gt;...]\r\n                             ID's of rule sets to include\r\n      --include-type[=&lt;typeIncludes&gt;...]\r\n                             Target types to include\r\n  -j, --json                 Output progress in JSON\r\n      --limit=&lt;limit&gt;        Max number of results to report\r\n  -M, --context-mount=&lt;String=String&gt;\r\n                             MappingContext resource URL relative to the\r\n                               current directory. YAML, JSON, or properties. In\r\n                               properties dots are treated as key path\r\n                               separators. Type is inferred from the content\r\n                               type header, if it is present, or extension.\r\n                               Mounts shadow context entries.\r\n  -o, --output=&lt;output&gt;      Output file\r\n  -p, --progress=&lt;progressOutput&gt;\r\n                             Output file for progress monitor\r\n      --parallel             Parallel inspection\r\n      --protocol-resource-factory=&lt;String=Class&gt;\r\n                             Maps protocol to resource factory class\r\n      --stop-on-first-fail   Stop on first failure\r\n  -V, --version              Print version information and exit."},"nsd-demo-cli/nsd/rules/site/index.html":{"path":"Demo CLI/nsd/rules/site","action-uuid":"154f8f56-6ec1-460e-87a0-7ed185438663","title":"site","content":"Usage: nsd rules site [-dfhjlRV] [-b=&lt;baseDir&gt;] [-m=&lt;domian&gt;]\r\n                      [-p=&lt;progressOutput&gt;] [-P=&lt;parallelism&gt;]\r\n                      [-r=&lt;pageErrors&gt;] [--root-action-icon=&lt;rootActionIcon&gt;]\r\n                      [--root-action-location=&lt;rootActionLocation&gt;]\r\n                      [--root-action-text=&lt;rootActionText&gt;] [-t=&lt;timeout&gt;]\r\n                      [-T=&lt;pageTemplate&gt;] [-w=&lt;workDir&gt;]\r\n                      [-c=&lt;String=String&gt;]... [-C=URL]...\r\n                      [-M=&lt;String=String&gt;]... [-e[=&lt;excludes&gt;...]]... [-i\r\n                      [=&lt;includes&gt;...]]... &lt;model&gt; &lt;output&gt;\r\nGenerates rule set documentation site\r\n      &lt;model&gt;                Model URI, resolved relative\r\n                             to the current directory\r\n                             or looked up in registered rule sets\r\n                             if -R option is provided\r\n      &lt;output&gt;               Output directory\r\n  -b, --base-dir=&lt;baseDir&gt;   Base directory\r\n  -c, --context-entry=&lt;String=String&gt;\r\n                             Context entries.\r\n                             Shadow entries in contexts and mounts.\r\n  -C, --context=URL          Context resource URL relative to the current\r\n                               directory. YAML, JSON, or properties. In\r\n                               properties dots are treated as key path\r\n                               separators. Type is inferred from the content\r\n                               type header, if it is present, or extension.\r\n                               Contexts are composed in the order of\r\n                               definition, later context entries shadowing the\r\n                               former\r\n  -d, --data                 Output progress data\r\n  -e, --exclude[=&lt;excludes&gt;...]\r\n                             Output directory clean excludes\r\n                             Ant pattern\r\n  -f, --file                 Mdel parameter is a file path\r\n  -h, --help                 Show this help message and exit.\r\n  -i, --include[=&lt;includes&gt;...]\r\n                             Output directory clean includes\r\n                             Ant pattern\r\n  -j, --json                 Output progress in JSON\r\n  -l, --[no-]clean           Clean working directory\r\n                             defaults to true\r\n  -m, --domain=&lt;domian&gt;      Sitemap domain\r\n  -M, --context-mount=&lt;String=String&gt;\r\n                             MappingContext resource URL relative to the\r\n                               current directory. YAML, JSON, or properties. In\r\n                               properties dots are treated as key path\r\n                               separators. Type is inferred from the content\r\n                               type header, if it is present, or extension.\r\n                               Mounts shadow context entries.\r\n  -p, --progress=&lt;progressOutput&gt;\r\n                             Output file for progress monitor\r\n  -P, --parallelism=&lt;parallelism&gt;\r\n                             If the value greater than one then an executor\r\n                               service is created and injected into the context\r\n                               to allow concurrent execution.\r\n  -r, --errors=&lt;pageErrors&gt;  Expected number of page errors\r\n  -R, --registered           Use registered rule set\r\n                             with provided URI\r\n      --root-action-icon=&lt;rootActionIcon&gt;\r\n                             Root action icon\r\n      --root-action-location=&lt;rootActionLocation&gt;\r\n                             Root action location\r\n      --root-action-text=&lt;rootActionText&gt;\r\n                             Root action text\r\n  -t, --timeout=&lt;timeout&gt;    If parallelism is greater than one this option\r\n                               specifies timout in seconds awaiting completion\r\n                               of execution. Default value is 60.\r\n  -T, --page-template=&lt;pageTemplate&gt;\r\n                             Page template URI relative\r\n                             to the current directory\r\n  -V, --version              Print version information and exit.\r\n  -w, --work-dir=&lt;workDir&gt;   Working directory\r\nExit codes:\r\n  Non-negative number   Delegate result\r\n  -1                    Unhandled exception during execution\r\n  -2                    Invalid input\r\n  -3                    Diagnostic failed\r\n  -4                    Execution failed or was cancelled, successful rollback\r\n  -5                    Execution failed or was cancelled, rollback failed\r\n  -6                    Executor service termination timed out"},"html/models/html/index.html":{"path":"HTML/Models/HTML","action-uuid":"d94455a4-d756-48a9-8d29-acf99261595d","title":"HTML","content":"TODO"},"html/jstree/index.html":{"path":"HTML/JsTree","action-uuid":"e1864e97-d407-4059-8436-353ef83dd1b9","title":"JsTree","content":"Sources Javadoc"},"glossary.html":{"action-uuid":"7b29ddd6-80bd-4768-8d4e-9200121aa6d7","title":"Glossary","content":"Clear Identifier(s) Hide UUID {{data.value.name}} {{data.value[0].value}} {{item.value}}"},"nsd-cli/nsd/rules/index.html":{"path":"CLI/nsd/rules","action-uuid":"75c9acc7-6bda-4cbd-9a14-53affbab9706","title":"rules","content":"Usage: nsd rules [-hV] [COMMAND]\r\nRules commands\r\n  -h, --help      Show this help message and exit.\r\n  -V, --version   Print version information and exit.\r\nCommands:\r\n  action-model  Generates rule set documentation action model\r\n  list          Lists available rule sets and rules\r\n  site          Generates rule set documentation site"},"core/exec/index.html":{"path":"Core/Exec","action-uuid":"9fc7c061-6571-48ef-a0e9-d4ec3b883d7e","title":"Exec","content":"Sources Javadoc"},"html/html/index.html":{"path":"HTML/HTML","action-uuid":"9d193cb5-050d-4116-abc0-fb82a6e93eda","title":"HTML","content":"Sources Javadoc"},"nsd-demo-cli/nsd/java/junit/index.html":{"path":"Demo CLI/nsd/java/junit","action-uuid":"8c3090be-64a7-4f09-b6a6-a451cbd4adce","title":"junit","content":"Version: org.nasdanika.models.java.cli@2024.5.1 \r\nUsage: nsd java junit [-dhjVw] [--[no-]ai] [--[no-]comment-response]\r\n                      [--disabled] [--api-endpoint=&lt;apiEndpoint&gt;]\r\n                      [-c=&lt;classes&gt;] [--class-suffix=&lt;classSuffix&gt;]\r\n                      [-J=&lt;jacoco&gt;] [-k=&lt;apiKey&gt;] [-l=&lt;limit&gt;]\r\n                      [-m=&lt;deploymentOrModelName&gt;] [-p=&lt;progressOutput&gt;]\r\n                      [--package-suffix=&lt;packageSuffix&gt;] [-r=&lt;prompt&gt;]\r\n                      [-s=&lt;sources&gt;] [-t=&lt;coverageType&gt;]\r\n                      [-v=&lt;apiKeyEnvironmentVariable&gt;] [-e[=&lt;excludes&gt;...]]...\r\n                      [-i[=&lt;includes&gt;...]]... &lt;projectDir&gt; &lt;coverageThreshold&gt;\r\n                      &lt;output&gt;\r\nGenerates JUnit tests\r\n      &lt;projectDir&gt;          Project directory\r\n      &lt;coverageThreshold&gt;   Coverage threshold\r\n      &lt;output&gt;              Output directory\r\n                            relative to the project directory\r\n      --[no-]ai             Use AI, defaults to true\r\n      --api-endpoint=&lt;apiEndpoint&gt;\r\n                            OpenAPI endpoint, defaults to\r\n                            https://api.openai.com/v1/chat/completions\r\n  -c, --classes=&lt;classes&gt;   Classes directory path relative\r\n                            to the project directory,\r\n                            defaults to target/classes\r\n      --class-suffix=&lt;classSuffix&gt;\r\n                            Test class suffix\r\n                            defaults to Tests\r\n      --[no-]comment-response\r\n                            Comment AI responses\r\n                            defaults to true\r\n  -d, --data                Output progress data\r\n      --disabled            Generate disabled tests\r\n  -e, --exclude[=&lt;excludes&gt;...]\r\n                            Source excludes\r\n                            Ant pattern\r\n  -h, --help                Show this help message and exit.\r\n  -i, --include[=&lt;includes&gt;...]\r\n                            Source includes\r\n                            Ant pattern\r\n  -j, --json                Output progress in JSON\r\n  -J, --jacoco=&lt;jacoco&gt;     jacoco.exec file path relative\r\n                            to the project directory,\r\n                            defaults to target/jacoco.exec\r\n  -k, --api-key=&lt;apiKey&gt;    OpenAPI key\r\n  -l, --limit=&lt;limit&gt;       Maximum number of test classes\r\n                            to generate\r\n  -m, --model=&lt;deploymentOrModelName&gt;\r\n                            OpenAPI deployment or model\r\n                            defaults to gpt-4\r\n  -p, --progress=&lt;progressOutput&gt;\r\n                            Output file for progress monitor\r\n      --package-suffix=&lt;packageSuffix&gt;\r\n                            Test package suffix\r\n                            defaults to .tests\r\n  -r, --prompt=&lt;prompt&gt;     Propmt\r\n                            defaults to 'Generate a JUnit 5 test method\r\n                              leveraging Mockito for the following Java method'\r\n  -s, --sources=&lt;sources&gt;   Sources directory path relative\r\n                            to the project directory,\r\n                            defaults to src/main/java\r\n  -t, --coverage-type=&lt;coverageType&gt;\r\n                            Coverage type\r\n                            Valid values: complexity, instruction, branch, line\r\n                            defaults to line\r\n  -v, --api-key-variable=&lt;apiKeyEnvironmentVariable&gt;\r\n                            OpenAPI key environment variable\r\n                            defaults to OPENAI_API_KEY\r\n  -V, --version             Print version information and exit.\r\n  -w, --overwrite           Overwrite existing tests"},"nsd-cli/nsd/java/index.html":{"path":"CLI/nsd/java","action-uuid":"a330398c-e76f-4619-9370-20a5428521b0","title":"java","content":"Version: org.nasdanika.models.java.cli@2024.5.1 \r\nUsage: nsd java [-hV] [COMMAND]\r\nCommands related to Java\r\n  -h, --help      Show this help message and exit.\r\n  -V, --version   Print version information and exit.\r\nCommands:\r\n  junit  Generates JUnit tests"},"nsd-cli/nsd/help/site/index.html":{"path":"CLI/nsd/help/site","action-uuid":"2fd6fca2-a455-4fd4-a42e-adb1a5e51183","title":"site","content":"Usage: nsd help site [-dhjlV] [-b=&lt;baseDir&gt;] [-m=&lt;domian&gt;]\r\n                     [-p=&lt;progressOutput&gt;] [-P=&lt;parallelism&gt;] [-r=&lt;pageErrors&gt;]\r\n                     [--root-action-icon=&lt;rootActionIcon&gt;]\r\n                     [--root-action-location=&lt;rootActionLocation&gt;]\r\n                     [--root-action-text=&lt;rootActionText&gt;] [-t=&lt;timeout&gt;]\r\n                     [-T=&lt;pageTemplate&gt;] [-w=&lt;workDir&gt;] [-c=&lt;String=String&gt;]...\r\n                     [-C=URL]... [-M=&lt;String=String&gt;]... [-e\r\n                     [=&lt;excludes&gt;...]]... [-i[=&lt;includes&gt;...]]... &lt;output&gt;\r\nGenerates help HTML site\r\n      &lt;output&gt;               Output directory\r\n  -b, --base-dir=&lt;baseDir&gt;   Base directory\r\n  -c, --context-entry=&lt;String=String&gt;\r\n                             Context entries.\r\n                             Shadow entries in contexts and mounts.\r\n  -C, --context=URL          Context resource URL relative to the current\r\n                               directory. YAML, JSON, or properties. In\r\n                               properties dots are treated as key path\r\n                               separators. Type is inferred from the content\r\n                               type header, if it is present, or extension.\r\n                               Contexts are composed in the order of\r\n                               definition, later context entries shadowing the\r\n                               former\r\n  -d, --data                 Output progress data\r\n  -e, --exclude[=&lt;excludes&gt;...]\r\n                             Output directory clean excludes\r\n                             Ant pattern\r\n  -h, --help                 Show this help message and exit.\r\n  -i, --include[=&lt;includes&gt;...]\r\n                             Output directory clean includes\r\n                             Ant pattern\r\n  -j, --json                 Output progress in JSON\r\n  -l, --[no-]clean           Clean working directory\r\n                             defaults to true\r\n  -m, --domain=&lt;domian&gt;      Sitemap domain\r\n  -M, --context-mount=&lt;String=String&gt;\r\n                             MappingContext resource URL relative to the\r\n                               current directory. YAML, JSON, or properties. In\r\n                               properties dots are treated as key path\r\n                               separators. Type is inferred from the content\r\n                               type header, if it is present, or extension.\r\n                               Mounts shadow context entries.\r\n  -p, --progress=&lt;progressOutput&gt;\r\n                             Output file for progress monitor\r\n  -P, --parallelism=&lt;parallelism&gt;\r\n                             If the value greater than one then an executor\r\n                               service is created and injected into the context\r\n                               to allow concurrent execution.\r\n  -r, --errors=&lt;pageErrors&gt;  Expected number of page errors\r\n      --root-action-icon=&lt;rootActionIcon&gt;\r\n                             Root action icon\r\n      --root-action-location=&lt;rootActionLocation&gt;\r\n                             Root action location\r\n      --root-action-text=&lt;rootActionText&gt;\r\n                             Root action text\r\n  -t, --timeout=&lt;timeout&gt;    If parallelism is greater than one this option\r\n                               specifies timout in seconds awaiting completion\r\n                               of execution. Default value is 60.\r\n  -T, --page-template=&lt;pageTemplate&gt;\r\n                             Page template URI relative\r\n                             to the current directory\r\n  -V, --version              Print version information and exit.\r\n  -w, --work-dir=&lt;workDir&gt;   Working directory\r\nExit codes:\r\n  Non-negative number   Delegate result\r\n  -1                    Unhandled exception during execution\r\n  -2                    Invalid input\r\n  -3                    Diagnostic failed\r\n  -4                    Execution failed or was cancelled, successful rollback\r\n  -5                    Execution failed or was cancelled, rollback failed\r\n  -6                    Executor service termination timed out"},"nsd-demo-cli/nsd/help/index.html":{"path":"Demo CLI/nsd/help","action-uuid":"a4f45c4a-5033-4334-80f9-f7a76f849296","title":"help","content":"Usage: nsd help [-ahHV] [-l=&lt;level&gt;] [-o=&lt;output&gt;] [COMMAND]\r\nOutputs usage for all registred commands\r\n  -a, --action-model      Output to action model\r\n  -h, --help              Show this help message and exit.\r\n  -H, --html              Output to HTML\r\n  -l, --header-level=&lt;level&gt;\r\n                          Starting level for HTML header tags in HTML output,\r\n                            the default value is 1.\r\n  -o, --output=&lt;output&gt;   Output file\r\n  -V, --version           Print version information and exit.\r\nCommands:\r\n  site  Generates help HTML site"},"nsd-demo-cli/nsd/app/site/index.html":{"path":"Demo CLI/nsd/app/site","action-uuid":"c38c8dfe-6768-4e60-adf3-fd7abd82ecab","title":"site","content":"Version: org.nasdanika.html.model.app.gen.cli@2024.5.1 \r\nUsage: nsd app site [-dhjlV] [-b=&lt;baseDir&gt;] [-m=&lt;domian&gt;] [-p=&lt;progressOutput&gt;]\r\n                    [-P=&lt;parallelism&gt;] [-r=&lt;pageErrors&gt;] [-t=&lt;timeout&gt;]\r\n                    [-T=&lt;pageTemplate&gt;] [-w=&lt;workDir&gt;] [-c=&lt;String=String&gt;]...\r\n                    [-C=URL]... [-M=&lt;String=String&gt;]... [-e[=&lt;excludes&gt;...]]...\r\n                    [-i[=&lt;includes&gt;...]]... &lt;model&gt; &lt;output&gt;\r\nGenerates HTML site\r\n      &lt;model&gt;                Model URI, resolved relative\r\n                             to the current directory\r\n      &lt;output&gt;               Output directory\r\n  -b, --base-dir=&lt;baseDir&gt;   Base directory\r\n  -c, --context-entry=&lt;String=String&gt;\r\n                             Context entries.\r\n                             Shadow entries in contexts and mounts.\r\n  -C, --context=URL          Context resource URL relative to the current\r\n                               directory. YAML, JSON, or properties. In\r\n                               properties dots are treated as key path\r\n                               separators. Type is inferred from the content\r\n                               type header, if it is present, or extension.\r\n                               Contexts are composed in the order of\r\n                               definition, later context entries shadowing the\r\n                               former\r\n  -d, --data                 Output progress data\r\n  -e, --exclude[=&lt;excludes&gt;...]\r\n                             Output directory clean excludes\r\n                             Ant pattern\r\n  -h, --help                 Show this help message and exit.\r\n  -i, --include[=&lt;includes&gt;...]\r\n                             Output directory clean includes\r\n                             Ant pattern\r\n  -j, --json                 Output progress in JSON\r\n  -l, --[no-]clean           Clean working directory\r\n                             defaults to true\r\n  -m, --domain=&lt;domian&gt;      Sitemap domain\r\n  -M, --context-mount=&lt;String=String&gt;\r\n                             MappingContext resource URL relative to the\r\n                               current directory. YAML, JSON, or properties. In\r\n                               properties dots are treated as key path\r\n                               separators. Type is inferred from the content\r\n                               type header, if it is present, or extension.\r\n                               Mounts shadow context entries.\r\n  -p, --progress=&lt;progressOutput&gt;\r\n                             Output file for progress monitor\r\n  -P, --parallelism=&lt;parallelism&gt;\r\n                             If the value greater than one then an executor\r\n                               service is created and injected into the context\r\n                               to allow concurrent execution.\r\n  -r, --errors=&lt;pageErrors&gt;  Expected number of page errors\r\n  -t, --timeout=&lt;timeout&gt;    If parallelism is greater than one this option\r\n                               specifies timout in seconds awaiting completion\r\n                               of execution. Default value is 60.\r\n  -T, --page-template=&lt;pageTemplate&gt;\r\n                             Page template URI relative\r\n                             to the current directory\r\n  -V, --version              Print version information and exit.\r\n  -w, --work-dir=&lt;workDir&gt;   Working directory\r\nExit codes:\r\n  Non-negative number   Delegate result\r\n  -1                    Unhandled exception during execution\r\n  -2                    Invalid input\r\n  -3                    Diagnostic failed\r\n  -4                    Execution failed or was cancelled, successful rollback\r\n  -5                    Execution failed or was cancelled, rollback failed\r\n  -6                    Executor service termination timed out"},"nsd-demo-cli/nsd/help/site/index.html":{"path":"Demo CLI/nsd/help/site","action-uuid":"460021e7-66a6-416d-af3e-e0209fdad29e","title":"site","content":"Usage: nsd help site [-dhjlV] [-b=&lt;baseDir&gt;] [-m=&lt;domian&gt;]\r\n                     [-p=&lt;progressOutput&gt;] [-P=&lt;parallelism&gt;] [-r=&lt;pageErrors&gt;]\r\n                     [--root-action-icon=&lt;rootActionIcon&gt;]\r\n                     [--root-action-location=&lt;rootActionLocation&gt;]\r\n                     [--root-action-text=&lt;rootActionText&gt;] [-t=&lt;timeout&gt;]\r\n                     [-T=&lt;pageTemplate&gt;] [-w=&lt;workDir&gt;] [-c=&lt;String=String&gt;]...\r\n                     [-C=URL]... [-M=&lt;String=String&gt;]... [-e\r\n                     [=&lt;excludes&gt;...]]... [-i[=&lt;includes&gt;...]]... &lt;output&gt;\r\nGenerates help HTML site\r\n      &lt;output&gt;               Output directory\r\n  -b, --base-dir=&lt;baseDir&gt;   Base directory\r\n  -c, --context-entry=&lt;String=String&gt;\r\n                             Context entries.\r\n                             Shadow entries in contexts and mounts.\r\n  -C, --context=URL          Context resource URL relative to the current\r\n                               directory. YAML, JSON, or properties. In\r\n                               properties dots are treated as key path\r\n                               separators. Type is inferred from the content\r\n                               type header, if it is present, or extension.\r\n                               Contexts are composed in the order of\r\n                               definition, later context entries shadowing the\r\n                               former\r\n  -d, --data                 Output progress data\r\n  -e, --exclude[=&lt;excludes&gt;...]\r\n                             Output directory clean excludes\r\n                             Ant pattern\r\n  -h, --help                 Show this help message and exit.\r\n  -i, --include[=&lt;includes&gt;...]\r\n                             Output directory clean includes\r\n                             Ant pattern\r\n  -j, --json                 Output progress in JSON\r\n  -l, --[no-]clean           Clean working directory\r\n                             defaults to true\r\n  -m, --domain=&lt;domian&gt;      Sitemap domain\r\n  -M, --context-mount=&lt;String=String&gt;\r\n                             MappingContext resource URL relative to the\r\n                               current directory. YAML, JSON, or properties. In\r\n                               properties dots are treated as key path\r\n                               separators. Type is inferred from the content\r\n                               type header, if it is present, or extension.\r\n                               Mounts shadow context entries.\r\n  -p, --progress=&lt;progressOutput&gt;\r\n                             Output file for progress monitor\r\n  -P, --parallelism=&lt;parallelism&gt;\r\n                             If the value greater than one then an executor\r\n                               service is created and injected into the context\r\n                               to allow concurrent execution.\r\n  -r, --errors=&lt;pageErrors&gt;  Expected number of page errors\r\n      --root-action-icon=&lt;rootActionIcon&gt;\r\n                             Root action icon\r\n      --root-action-location=&lt;rootActionLocation&gt;\r\n                             Root action location\r\n      --root-action-text=&lt;rootActionText&gt;\r\n                             Root action text\r\n  -t, --timeout=&lt;timeout&gt;    If parallelism is greater than one this option\r\n                               specifies timout in seconds awaiting completion\r\n                               of execution. Default value is 60.\r\n  -T, --page-template=&lt;pageTemplate&gt;\r\n                             Page template URI relative\r\n                             to the current directory\r\n  -V, --version              Print version information and exit.\r\n  -w, --work-dir=&lt;workDir&gt;   Working directory\r\nExit codes:\r\n  Non-negative number   Delegate result\r\n  -1                    Unhandled exception during execution\r\n  -2                    Invalid input\r\n  -3                    Diagnostic failed\r\n  -4                    Execution failed or was cancelled, successful rollback\r\n  -5                    Execution failed or was cancelled, rollback failed\r\n  -6                    Executor service termination timed out"},"core/index.html":{"action-uuid":"f154f2f2-07f5-48d1-94fb-1455b53570bc","title":"Core","content":"Sources"},"html/models/index.html":{"path":"HTML/Models","action-uuid":"77de63bf-73c8-475f-bda4-68b148f178b4","title":"Models","content":"TODO"},"practices/generic/index.html":{"path":"Practices/Analysis, Visualization &amp; Generation","action-uuid":"b19896ba-7762-4614-bac7-86b925a257cd","title":"Analysis, Visualization &amp; Generation","content":"This practice explains how to use Nasdanika products (specifically models) and related products. The above diagram shows the core idea - load input data into a model, modify the model or create a new model from it, and save the models to native (raw) formats. Loading to a model as opposed to working with raw formats gives the following benefits: Unified API Generated model documentation with visualizations Different models may extend classes from core models and be treated similarly Model classes may be subclassed and mixed Cross-reference model elements URI handlers allows to load models from diverse sources On-demand loading of resources and features of model elements Conversion of models to graphs and making them executable with graph processors E.g. want to read/write Excel files - take a look at the Excel metamodel and then use Ecore API to work with the model. Now want to work with PDF? A different metamodel, the same model API. You have Java sources stored in GitLab and want model elements to reflect both Java and GitLab natures of your sources? Create a GitLabRepositoryCompilationUnit class which extends both Compilation Unit and Repository File. Customize Loader to create this class for repository files with java extension. Want to load a PDF file directly from GitLab without having to clone the entire repository? Use GitLabURIHandler! The below diagram illustrates the above concepts: Models can be visualized using: ECharts using the ECharts model, ECharts-Java or by directly generating JavaScript/JSON. Example. PlantUML using DiagramGenerator, the diagram module or by directly generating PlantUML text and calling Plant UML API&rsquo;s. Example. Holistic model of an organization One use case for the modeling approach outlined above is creation of a holistic model of an organization/corporation as exemplified by the below diagram1 In a corporation different elements of the model are typically stored in different systems and documents like Excel spreadsheets. The modeling approach allows to load those elements in a single resource set and cross-reference them. Elements which are not stored in structured formats can be captured by modeling them in diagrams and mapping those diagrams to models, see Beyond Diagrams. One important reason why a holistic model might be beneficial for an organization is the ability of using it for AI insights. For example, using RAG/Chat on top of the organization model. Such chat can be made context-aware, chatting with the Operations will return result relevant to operations. The above diagram is very simple, a large organization may have many layers, thousands of applications, millions of lines of code. A model for such an organization would take some time to build, but it can be built incrementally - department by department, application by application. The value of building such a model will grow exponentially as more and more elements are added due to the network effect. While the resulting model might be &ldquo;large&rdquo;, &hellip; define large. Experiments show that a model element in a model like the above takes ~ 500 bytes of RAM. As such, 1 GB of RAM would hold about 2 million model elements. Also, model resources are loaded on demand, so only the model elements needed by some task would be loaded to complete that task. With DynamicDelegate it is possible to have model elements loading their data from multiple sources on demand. The organization model can be built on top of existing &ldquo;generic&rdquo; models such as Java, Maven, GitLab, Azure, &hellip; Resources TOGAF Enterprise Metamodel Corporate structure ↩ Output Model Transformation Input Model Raw Input Raw Output Cell Excel Resource Paragraph PDF Resource Resource Set GitLab URI Handler MS Excel Workbook GitLab Excel Resource Factory PDF Resource Factory PDF File File system Corporation Marketing Finance Uses Operations HR Builds IT Execution environments Binary packages Source Code Application"},"nsd-demo-cli/nsd/java/index.html":{"path":"Demo CLI/nsd/java","action-uuid":"d14cf22b-8224-424d-b42e-a5945fe0d2d6","title":"java","content":"Version: org.nasdanika.models.java.cli@2024.5.1 \r\nUsage: nsd java [-hV] [COMMAND]\r\nCommands related to Java\r\n  -h, --help      Show this help message and exit.\r\n  -V, --version   Print version information and exit.\r\nCommands:\r\n  junit  Generates JUnit tests"},"core/http/index.html":{"path":"Core/HTTP","action-uuid":"fb2444f6-0c65-4e6b-aa4e-ddfb4207059a","title":"HTTP","content":"Sources Javadoc"},"nsd-cli/nsd/help/index.html":{"path":"CLI/nsd/help","action-uuid":"2344a101-b549-4855-982d-9762419b452b","title":"help","content":"Usage: nsd help [-ahHV] [-l=&lt;level&gt;] [-o=&lt;output&gt;] [COMMAND]\r\nOutputs usage for all registred commands\r\n  -a, --action-model      Output to action model\r\n  -h, --help              Show this help message and exit.\r\n  -H, --html              Output to HTML\r\n  -l, --header-level=&lt;level&gt;\r\n                          Starting level for HTML header tags in HTML output,\r\n                            the default value is 1.\r\n  -o, --output=&lt;output&gt;   Output file\r\n  -V, --version           Print version information and exit.\r\nCommands:\r\n  site  Generates help HTML site"}}