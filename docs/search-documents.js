var searchDocuments = {"html/index.html":{"action-uuid":"a731ddc8-10c7-4208-886a-47ace42898ec","title":"HTML","content":"Sources"},"nsd-cli/nsd/model/html-app/site/index.html":{"path":"CLI/nsd/model/html-app/site","action-uuid":"b94f0638-1e48-4f96-83c6-6f0cd01f5c8f","title":"site","content":"Version: org.nasdanika.cli \r\nUsage: nsd model html-app site [-hlV] [--progress-console] [--progress-data]\r\n                               [--progress-json] [-b=&lt;baseDir&gt;]\r\n                               [-F=&lt;pageTemplateFile&gt;] [-m=&lt;domian&gt;]\r\n                               [-P=&lt;parallelism&gt;]\r\n                               [--progress-output=&lt;progressOutput&gt;]\r\n                               [-r=&lt;pageErrors&gt;] [-t=&lt;timeout&gt;]\r\n                               [-T=&lt;pageTemplate&gt;] [-w=&lt;workDir&gt;]\r\n                               [-c=&lt;String=String&gt;]... [-C=URL]...\r\n                               [-M=&lt;String=String&gt;]... [-e[=&lt;excludes&gt;...]]...\r\n                               [-i[=&lt;includes&gt;...]]... &lt;output&gt;\r\nGenerates HTML site\r\n      &lt;output&gt;               Output directory relative to the base directory\r\n  -b, --base-dir=&lt;baseDir&gt;   Base directory\r\n  -c, --context-entry=&lt;String=String&gt;\r\n                             Context entries.\r\n                             Shadow entries in contexts and mounts.\r\n  -C, --context=URL          Context resource URL relative to the current\r\n                               directory. YAML, JSON, or properties. In\r\n                               properties dots are treated as key path\r\n                               separators. Type is inferred from the content\r\n                               type header, if it is present, or extension.\r\n                               Contexts are composed in the order of\r\n                               definition, later context entries shadowing the\r\n                               former\r\n  -e, --exclude[=&lt;excludes&gt;...]\r\n                             Output directory clean excludes\r\n                             Ant pattern\r\n  -F, --page-template-file=&lt;pageTemplateFile&gt;\r\n                             Page template file relative\r\n                             to the current directory\r\n  -h, --help                 Show this help message and exit.\r\n  -i, --include[=&lt;includes&gt;...]\r\n                             Output directory clean includes\r\n                             Ant pattern\r\n  -l, --[no-]clean           Clean working directory\r\n                             defaults to true\r\n  -m, --domain=&lt;domian&gt;      Sitemap domain\r\n  -M, --context-mount=&lt;String=String&gt;\r\n                             MappingContext resource URL relative to the\r\n                               current directory. YAML, JSON, or properties. In\r\n                               properties dots are treated as key path\r\n                               separators. Type is inferred from the content\r\n                               type header, if it is present, or extension.\r\n                               Mounts shadow context entries.\r\n  -P, --parallelism=&lt;parallelism&gt;\r\n                             If the value greater than one then an executor\r\n                               service is created and injected into the context\r\n                               to allow concurrent execution.\r\n      --progress-console     Output progress to console\r\n      --progress-data        Output progress data\r\n      --progress-json        Output progress in JSON\r\n      --progress-output=&lt;progressOutput&gt;\r\n                             Output file for progress monitor\r\n  -r, --errors=&lt;pageErrors&gt;  Expected number of page errors\r\n                             -1 for any (not fail on errors)\r\n                             default is 0\r\n  -t, --timeout=&lt;timeout&gt;    If parallelism is greater than one this option\r\n                               specifies timout in seconds awaiting completion\r\n                               of execution. Default value is 60.\r\n  -T, --page-template=&lt;pageTemplate&gt;\r\n                             Page template URI relative\r\n                             to the current directory\r\n  -V, --version              Print version information and exit.\r\n  -w, --work-dir=&lt;workDir&gt;   Working directory\r\nExit codes:\r\n  Non-negative number   Delegate result\r\n  -1                    Unhandled exception during execution\r\n  -2                    Invalid input\r\n  -3                    Diagnostic failed\r\n  -4                    Execution failed or was cancelled, successful rollback\r\n  -5                    Execution failed or was cancelled, rollback failed\r\n  -6                    Executor service termination timed out"},"core/maven/index.html":{"path":"Core/Maven","action-uuid":"be322903-f8dc-40a3-b3e9-85bde855708d","title":"Maven","content":"Nasdanika Maven module uses Maven Resolver Supplier to provide capabilities for Dependency and ClassLoader requirements. Sources Javadoc Dependency CapabilityLoader capabilityLoader = new CapabilityLoader();\nDependencyRequestRecord requirement = new DependencyRequestRecord(\n\t\tnew String[] { &quot;org.apache.groovy:groovy-all:pom:4.0.23&quot; }, \n\t\tnull, \n\t\tnull, \n\t\t&quot;target/test-repo&quot;);\n\t\t\nProgressMonitor progressMonitor = new PrintStreamProgressMonitor();\nCollection&lt;File&gt; result = capabilityLoader.loadOne(requirement, progressMonitor);\n The above code snippet loads org.apache.groovy:groovy-all:pom:4.0.23 and its dependencies into target/test-repo directory and returns a list of jar files. ClassLoader CapabilityLoader capabilityLoader = new CapabilityLoader();\nClassLoaderRequirement requirement = new ClassLoaderRequirement(\n\t\tnull, // String[] modulePath,\n\t\tnull, // String[] rootModules,\n\t\tnew ModuleLayer[] { getClass().getModule().getLayer() }, \n\t\tgetClass().getClassLoader(), // ClassLoader parentClassLoader,\n\t\ttrue, // boolean singleLayerClassLoader,\t\t\t\t\n\t\tnew String[] { &quot;org.apache.groovy:groovy-all:pom:4.0.23&quot; }, \n\t\tnull, \n\t\tnull, \n\t\t&quot;target/test-repo&quot;,\n\t\tSystem.out::println);\n\t\t\nProgressMonitor progressMonitor = new PrintStreamProgressMonitor();\nClassLoader result = capabilityLoader.loadOne(\n\t\tServiceCapabilityFactory.createRequirement(ClassLoader.class, null, requirement),\n\t\tprogressMonitor);\n\t\t\nClass&lt;?&gt; scriptEngineFactoryClass = result.loadClass(&quot;org.codehaus.groovy.jsr223.GroovyScriptEngineFactory&quot;);\n The above code snippet: Loads org.apache.groovy:groovy-all:pom:4.0.23 and its dependencies into target/test-repo directory Creates a ClassLoader Loads org.codehaus.groovy.jsr223.GroovyScriptEngineFactory class"},"core/diagram/index.html":{"path":"Core/Diagram","action-uuid":"267f3afd-3603-465a-8760-8b9c36af41aa","title":"Diagram","content":"Sources Javadoc"},"nsd-cli/nsd/rules/action-model/index.html":{"path":"CLI/nsd/rules/action-model","action-uuid":"c1062c1f-6b8e-4642-a4ee-6ce112c8e2cf","title":"action-model","content":"Usage: nsd rules action-model [-fhRV] [--progress-console] [--progress-data]\r\n                              [--progress-json]\r\n                              [--progress-output=&lt;progressOutput&gt;]\r\n                              [-c=&lt;String=String&gt;]... [-C=URL]...\r\n                              [-M=&lt;String=String&gt;]... &lt;model&gt; &lt;output&gt;\r\nGenerates rule set documentation action model\r\n      &lt;model&gt;              Model URI or file path, resolved relative\r\n                           to the current directory\r\n                           or looked up in registered rule sets\r\n                           if -R option is provided\r\n      &lt;output&gt;             Output file\r\n  -c, --context-entry=&lt;String=String&gt;\r\n                           Context entries.\r\n                           Shadow entries in contexts and mounts.\r\n  -C, --context=URL        Context resource URL relative to the current\r\n                             directory. YAML, JSON, or properties. In\r\n                             properties dots are treated as key path\r\n                             separators. Type is inferred from the content type\r\n                             header, if it is present, or extension. Contexts\r\n                             are composed in the order of definition, later\r\n                             context entries shadowing the former\r\n  -f, --file               Mdel parameter is a file path\r\n  -h, --help               Show this help message and exit.\r\n  -M, --context-mount=&lt;String=String&gt;\r\n                           MappingContext resource URL relative to the current\r\n                             directory. YAML, JSON, or properties. In\r\n                             properties dots are treated as key path\r\n                             separators. Type is inferred from the content type\r\n                             header, if it is present, or extension. Mounts\r\n                             shadow context entries.\r\n      --progress-console   Output progress to console\r\n      --progress-data      Output progress data\r\n      --progress-json      Output progress in JSON\r\n      --progress-output=&lt;progressOutput&gt;\r\n                           Output file for progress monitor\r\n  -R, --registered         Use registered rule set\r\n                           with provided URI\r\n  -V, --version            Print version information and exit."},"html/bootstrap/index.html":{"path":"HTML/Bootstrap","action-uuid":"7f443bf1-aa57-458a-a45e-6d1405893cb7","title":"Bootstrap","content":"Sources Javadoc"},"nsd-cli/nsd/app/index.html":{"path":"CLI/nsd/app","action-uuid":"c0a52985-e17e-45ef-b149-a97b07acbda8","title":"app","content":"Version: org.nasdanika.html.model.app.gen.cli \r\nUsage: nsd app [-hV] [COMMAND]\r\nHTML Application model commands\r\n  -h, --help      Show this help message and exit.\r\n  -V, --version   Print version information and exit.\r\nCommands:\r\n  site  Generates HTML site"},"nsd-cli/nsd/exit/index.html":{"path":"CLI/nsd/exit","action-uuid":"ab9d2b1b-8d72-4226-912b-5e2d9bb3253b","title":"exit","content":"Version: org.nasdanika.cli \r\nUsage: nsd exit [-hV]\r\nExits shell\r\n  -h, --help      Show this help message and exit.\r\n  -V, --version   Print version information and exit."},"index.html":{"action-uuid":"397303bc-81bc-4713-96cd-2fe602684c9f","title":"Nasdanika","content":" Common Resources Persistence Ncore Diagram Graph Drawio EMF Exec Maven Capability CLI HTTP Core HTML HTML Bootstrap App Models JsTree Bootstrap EMF HTML GitLab Family Architecture Git Excel ECharts Nature Bank PDF Party Coverage Source Engineering Java Maven Enterprise Function Flow Rules Azure Decision Analysis Capability Flow Ecore Jira Models Data Sources Loader Store Key Extractor Query Engine Requestor Generator Responder Retrieval Augmented Generation (RAG) Analysis, Visualization &amp; Generation Java Analysis, Visualization &amp; Generation JUnit Tests Generation Practices Beyond Diagrams Java Analysis, Visualization, and Generation Books CLI YouTube Channel Demos Medium Publication Template Repositories Common Resources Persistence Ncore Diagram Graph Drawio EMF Exec Maven Capability CLI HTTP Core HTML HTML Bootstrap App Models JsTree Bootstrap EMF HTML GitLab Family Architecture Git Excel ECharts Nature Bank PDF Party Coverage Source Engineering Java Maven Enterprise Function Flow Rules Azure Decision Analysis Capability Flow Ecore Jira Models Data Sources Loader Store Key Extractor Query Engine Requestor Generator Responder Retrieval Augmented Generation (RAG) Analysis, Visualization &amp; Generation Java Analysis, Visualization &amp; Generation JUnit Tests Generation Practices Beyond Diagrams Java Analysis, Visualization, and Generation Books CLI YouTube Channel Demos Medium Publication Template Repositories"},"nsd-cli/nsd/model/ecore-html-app/save/index.html":{"path":"CLI/nsd/model/ecore-html-app/save","action-uuid":"eeea3853-145b-41b9-9f77-6e3e5e2af6dc","title":"save","content":"Version: org.nasdanika.cli \r\nUsage: nsd model ecore-html-app save [-hV] [--progress-console]\r\n                                     [--progress-data] [--progress-json]\r\n                                     [--progress-output=&lt;progressOutput&gt;]\r\n                                     [--content-type-resource-factory=&lt;String=Cl\r\n                                     ass&gt;]...\r\n                                     [--extension-resource-factory=&lt;String=Class\r\n                                     &gt;]...\r\n                                     [--protocol-resource-factory=&lt;String=Class&gt;\r\n                                     ]... &lt;output&gt;\r\nSaves model to a file\r\n      &lt;output&gt;             Output file\r\n      --content-type-resource-factory=&lt;String=Class&gt;\r\n                           Maps content type to resource factory class\r\n      --extension-resource-factory=&lt;String=Class&gt;\r\n                           Maps extension to resource factory class\r\n  -h, --help               Show this help message and exit.\r\n      --progress-console   Output progress to console\r\n      --progress-data      Output progress data\r\n      --progress-json      Output progress in JSON\r\n      --progress-output=&lt;progressOutput&gt;\r\n                           Output file for progress monitor\r\n      --protocol-resource-factory=&lt;String=Class&gt;\r\n                           Maps protocol to resource factory class\r\n  -V, --version            Print version information and exit."},"nsd-cli/nsd/app/site/index.html":{"path":"CLI/nsd/app/site","action-uuid":"fe886d62-e8a5-487c-bc4d-be3207dd6423","title":"site","content":"Version: org.nasdanika.html.model.app.gen.cli \r\nUsage: nsd app site [-hlV] [--progress-console] [--progress-data]\r\n                    [--progress-json] [-b=&lt;baseDir&gt;] [-m=&lt;domian&gt;]\r\n                    [-P=&lt;parallelism&gt;] [--progress-output=&lt;progressOutput&gt;]\r\n                    [-r=&lt;pageErrors&gt;] [-t=&lt;timeout&gt;] [-T=&lt;pageTemplate&gt;]\r\n                    [-w=&lt;workDir&gt;] [-c=&lt;String=String&gt;]... [-C=URL]...\r\n                    [-M=&lt;String=String&gt;]... [-e[=&lt;excludes&gt;...]]... [-i\r\n                    [=&lt;includes&gt;...]]... &lt;model&gt; &lt;output&gt;\r\nGenerates HTML site\r\n      &lt;model&gt;                Model URI, resolved relative\r\n                             to the current directory\r\n      &lt;output&gt;               Output directory\r\n  -b, --base-dir=&lt;baseDir&gt;   Base directory\r\n  -c, --context-entry=&lt;String=String&gt;\r\n                             Context entries.\r\n                             Shadow entries in contexts and mounts.\r\n  -C, --context=URL          Context resource URL relative to the current\r\n                               directory. YAML, JSON, or properties. In\r\n                               properties dots are treated as key path\r\n                               separators. Type is inferred from the content\r\n                               type header, if it is present, or extension.\r\n                               Contexts are composed in the order of\r\n                               definition, later context entries shadowing the\r\n                               former\r\n  -e, --exclude[=&lt;excludes&gt;...]\r\n                             Output directory clean excludes\r\n                             Ant pattern\r\n  -h, --help                 Show this help message and exit.\r\n  -i, --include[=&lt;includes&gt;...]\r\n                             Output directory clean includes\r\n                             Ant pattern\r\n  -l, --[no-]clean           Clean working directory\r\n                             defaults to true\r\n  -m, --domain=&lt;domian&gt;      Sitemap domain\r\n  -M, --context-mount=&lt;String=String&gt;\r\n                             MappingContext resource URL relative to the\r\n                               current directory. YAML, JSON, or properties. In\r\n                               properties dots are treated as key path\r\n                               separators. Type is inferred from the content\r\n                               type header, if it is present, or extension.\r\n                               Mounts shadow context entries.\r\n  -P, --parallelism=&lt;parallelism&gt;\r\n                             If the value greater than one then an executor\r\n                               service is created and injected into the context\r\n                               to allow concurrent execution.\r\n      --progress-console     Output progress to console\r\n      --progress-data        Output progress data\r\n      --progress-json        Output progress in JSON\r\n      --progress-output=&lt;progressOutput&gt;\r\n                             Output file for progress monitor\r\n  -r, --errors=&lt;pageErrors&gt;  Expected number of page errors\r\n                             -1 for any (not fail on errors)\r\n                             default is 0\r\n  -t, --timeout=&lt;timeout&gt;    If parallelism is greater than one this option\r\n                               specifies timout in seconds awaiting completion\r\n                               of execution. Default value is 60.\r\n  -T, --page-template=&lt;pageTemplate&gt;\r\n                             Page template URI relative\r\n                             to the current directory\r\n  -V, --version              Print version information and exit.\r\n  -w, --work-dir=&lt;workDir&gt;   Working directory\r\nExit codes:\r\n  Non-negative number   Delegate result\r\n  -1                    Unhandled exception during execution\r\n  -2                    Invalid input\r\n  -3                    Diagnostic failed\r\n  -4                    Execution failed or was cancelled, successful rollback\r\n  -5                    Execution failed or was cancelled, rollback failed\r\n  -6                    Executor service termination timed out"},"core/common/index.html":{"path":"Core/Common","action-uuid":"7c76d119-29e7-4003-8845-6eb8344272cc","title":"Common","content":"Sources Javadoc"},"nsd-cli/nsd/model/html-app/index.html":{"path":"CLI/nsd/model/html-app","action-uuid":"380990af-4974-447d-9e0b-123a5b37be34","title":"html-app","content":"Version: org.nasdanika.cli \r\nUsage: nsd model html-app [-fhRV] [-P=&lt;insertionIndex&gt;] [-r=&lt;rootLabel&gt;]\r\n                          [-c=&lt;String=String&gt;]... [-C=URL]...\r\n                          [--content-type-resource-factory=&lt;String=Class&gt;]...\r\n                          [--extension-resource-factory=&lt;String=Class&gt;]...\r\n                          [-M=&lt;String=String&gt;]...\r\n                          [--protocol-resource-factory=&lt;String=Class&gt;]...\r\n                          [COMMAND]\r\nGenerates html application model from a drawio document\r\n  -c, --context-entry=&lt;String=String&gt;\r\n                      Context entries.\r\n                      Shadow entries in contexts and mounts.\r\n  -C, --context=URL   Context resource URL relative to the current directory.\r\n                        YAML, JSON, or properties. In properties dots are\r\n                        treated as key path separators. Type is inferred from\r\n                        the content type header, if it is present, or\r\n                        extension. Contexts are composed in the order of\r\n                        definition, later context entries shadowing the former\r\n      --content-type-resource-factory=&lt;String=Class&gt;\r\n                      Maps content type to resource factory class\r\n      --extension-resource-factory=&lt;String=Class&gt;\r\n                      Maps extension to resource factory class\r\n  -f, --file          Root action option is a file path\r\n  -h, --help          Show this help message and exit.\r\n  -M, --context-mount=&lt;String=String&gt;\r\n                      MappingContext resource URL relative to the current\r\n                        directory. YAML, JSON, or properties. In properties\r\n                        dots are treated as key path separators. Type is\r\n                        inferred from the content type header, if it is\r\n                        present, or extension. Mounts shadow context entries.\r\n  -P, --position=&lt;insertionIndex&gt;\r\n                      Insertion position\r\n                      Defaults to 0\r\n      --protocol-resource-factory=&lt;String=Class&gt;\r\n                      Maps protocol to resource factory class\r\n  -r, --root-label=&lt;rootLabel&gt;\r\n                      Root label URL or file path, resolved relative\r\n                      to the current directory\r\n  -R, --add-to-root   Add labels to the root\r\n                      even if the principal is present\r\n  -V, --version       Print version information and exit.\r\nCommands:\r\n  save  Saves model to a file\r\n  site  Generates HTML site"},"practices/junit/index.html":{"path":"Practices/JUnit Tests Generation","action-uuid":"4eb163cf-33fa-4dbb-8c0a-a149a0fefcc0","title":"JUnit Tests Generation","content":"This practice is a specialization of the Java Analysis, Visualization &amp; Generation Practice for generation of JUnit tests. In particular: Generation of tests for methods or classes with low test coverage Leveraging Gen AI such as OpenAI ChatGPT or Azure OpenAI Service for test generation The above diagram shows Java development activities and artifacts. Black arrows show the typical process, blue arrows show the test generation loop. The developer produces source artifacts which may include non-java artifacts used to generate Java code (e.g. Ecore models), &ldquo;main&rdquo; Java sources and test Java sources. Java sources are compiled into bytecode (class files). Here it is important to note that matching of bytecode classes and methods to source code classes and methods might be non-trivial because of: Lambdas Anonymous and method-scope classes Annotation processors like Lombok JUnit tests are compiled and executed. If code coverage, such as jacoco, is configured then test execution produces coverage data. Jacoco stores coverage data in jacoco.exec file. This file is used to generate a coverage report and upload coverage information to systems like SonarQube. In this practice it is also used to select which methods to generate tests for based on coverage data. This diagram provides an insight into the test generation activity: Coverage data and bytecode are used as input to load the Coverage model. Source files, the coverage model, and bytecode (optional) are used to load the Java model of source code. The generator traverses the model and generates unit tests for method with low coverage using a combination of programmatic (traditional) generation and Gen AI. Tests are generated as a Java model as well and then are delivered to the developer for review, modification, and inclusion into the unit test suite. The following section provides an overview of two &ldquo;local loop&rdquo; reference implementations (a.k.a. designs/embodiments) - all-in-one and componentized. There are many possible designs leveraging different alternatives at multiple variation points. The sections after the reference implementations section provide an overview of variation points, alternatives, and factors to take into consideration during alternative selection. Command line Reference Implementations All-in-one Componentized Repository scan/crawl Variation points and alternatives Stakeholders &amp; Activities Developer Build machine Test generator GenAI Messages Channels Developer -&gt; Build Machine/Test Generation : Source code Build Machine -&gt; Test Generator : Coverage results, possibly with bytecode Test Generation -&gt; Developer : Generated tests Test Generation - GenAI : Prompt Command line Nasdanika CLI features JUnit command which generates JUnit tests as explained above. Reference Implementations This section explains reference implementations All-in-one All-in-one generations is implemented as a JUnit test is available in TestGenerator. An example of tests generated by this generator - PetControllerTests. As the name implies, all steps of source analysis and generation are implemented in a single class and are executed in one go. Componentized Componentized test generation which is also executed in one go is implemented in these classes: TestJavaAnalyzers - loads sources, coverage, and inspectors, passes the sources to the inspectors, aggregates and saves results. Coverage Inspector - generates tests for methods with low coverage leveraging TestGenerator capability provided by OpenAITestGenerator. Repository scan/crawl TestGitLab demonstrates how to scan a source repository (GitLab) using REST API, inspect code, generate unit tests, commit them to the server (also over the REST API) and create a merge request. This implementation does not use coverage information, its purpose is to demonstrate operation over the REST API without having to clone a repository, which might be an expensive operation. The implementation uses GitLab Model to communicate with the repository. It uses Java model to load sources and StringBuilder to build test cases. Variation points and alternatives As you have seen above, you can have an AI-powered JUnit test generator in about 230 lines of code, and maybe it would all you need. However, there are many variation points (design dimensions), alternatives at each point and, as such, possible permutations of thereof (designs). This section provides a high level overview of variation points and alternatives. How to assemble a solution from those alternative is specific to your context and there might be different solutions for different contexts and multiple solutions complementing each other. As you proceed with assembling a solution, or a portfolio of solutions, you may identify more variation points and alternatives. To manage the complexity you may use: Enterprise Model for general guidance, Capability framework or Capability model to create a catalog of variation points and alternatives and compute solutions (designs) from them Decision Analysis to select from the computed list of designs Flow to map your development process AS-IS and then augment it with test generation activities at different points. In this section we&rsquo;ll use the below diagram and the concept of an Enterprise with Stakeholders performing activities and exchanging Messages over Channels. The mission of our enterprise is to deliver quality Java code. The loss function to minimize is loss function = cost * risk / business value. For our purposes we&rsquo;ll define risk as inversely proportional to tests coverage risk = missed lines / total lines - that&rsquo;s all we can measure in this simple model. The cost includes resources costs - salary, usage fees for OpenAI. Below is a summary of our enterprise: Stakeholders &amp; Activities: Developer - writes code Build machine - compiles code and executes tests Test generator - generates unit tests GenAI - leveraged by the Test Generator Messages: Source code Bytecode Coverage results Prompt to generate a test Generated tests Channels Developer -&gt; Build Machine : Source code Developer -&gt; Test Generation : Source code Build Machine -&gt; Test Generator : Coverage results, possibly with bytecode Test Generation -&gt; Developer : Generated tests Test Generation - GenAI : Prompt The below sections outline variation points and alternatives for the list items above Stakeholders &amp; Activities Developer A developer writes code - both &ldquo;business&rdquo; and test. They use some kind of an editor, likely an IDE - Eclipse, IntelliJ, VS Code. Different IDE&rsquo;s come with different sets of plug-ins, including AI assistants. Forcing a developer to switch from their IDE of preference to another IDE is likely to cause considerable productivity drop, at least for some period of time, even if the new IDE is considered superior to the old IDE. So, if you want to switch to another IDE just because it has some plug-in which you like - think twice. Build machine A build machine compiles code and executes tests. Technically, compilation and test execution may be separated in two individual activities. We are not doing it for this analysis because it doesn&rsquo;t carry much relevance to test generation. You can do it for yours. Test generator Test generator generates tests by &ldquo;looking&rdquo; at the source code, bytecode, and code coverage results. Because the source code is a model element representing piece of code (method, constructor, &hellip;), the generator may traverse the model to &ldquo;understand&rdquo; the context. E.g. it may take a look at the method&rsquo;s class, other classes in the module. If the sources are loaded from a version control system, it may take a look at the commits. And if the source model is part of an organization model, it may look at &ldquo;sibling&rdquo; modules and other resources. By analyzing source and bytecode the generator would know methods a given method calls, objects it creates, and also it would know methods calling the method. It will also &ldquo;know&rdquo; branch conditions, e.g. switch cases. Using this information the generator may: Generate comments to help the developer Generate mocks, including constructor and static methods mocks Generate tests for different branches Build a variety of prompts for GenAI The test generator may do the following code generated by GenAI: Add to generated test methods commented out - as it is done in the reference implementations &ldquo;Massage&rdquo; - remove backticks, parse, add imports - generated and implied. In addition to code generation the generator may ask GenAI to explain code and generate recommendations - it will help the developer to understand the source method and possibly improve it along the way. It may also generate dependency graphs and sequence diagrams. GenAI There may GenAI models out there - cloud, self hosted. Which one to use heavily depends on the context. For example, if you have a large codebase with considerable amount of technical debt having an on-prem model may be a good choice because: You may fine-tune it. Even if you don&rsquo;t have tons of GPU power and your model is relatively slow you can crawl you code base, generate tests and deliver them to developers for review and inclusion into test suites. In this scenario your cost is on-prem infrastructure and power. Your savings are not having to pay for GenAI in the cloud and developer productivity if your fined tuned model turns out to be more efficient than a &ldquo;vanilla&rdquo; LLM. There are many other considerations, of course! Messages In this section we&rsquo;ll take a look just at bytecode and coverage results delivered to the test generator. The generator operates on models. As such, bytecode and coverage results can be delivered in a &ldquo;raw&rdquo; format to be loaded to a model by the generator, or pre-loaded to a model and saved to a file. The second option results in fewer files to pass to the test generator. The model file can be in XMI format or in compressed binary. The XMI format is human-readable, the binary format takes less space on disk. Channels Developer -&gt; Build Machine/Test Generation : Source code For local development the build machine is the same machine where developer creates sources. The test generator is also executed on the developer&rsquo;s workstation. As such, the delivery channels is the file system. In the case of CI/CD pipeline/build server such as Jenkins or GitHub Actions, a version control systems is the delivery channel. Build Machine -&gt; Test Generator : Coverage results, possibly with bytecode The test generator needs coverage results. If the coverage results are delivered in the raw form, it also needs bytecode (class files) to make sense of the results. Coverage results can be delivered to the test generator using the following channels: Filesystem Jenkins workspace made available to the test generator over HTTP(S) Binary repository. For example, coverage results might be published to the Maven repository as an assembly along with sources, jar file, and javadoc. They can be published in a raw format or as a model. In this modality the tests generator can get everything it needs from a Maven repository. You can use Maven model or Maven Artifact Resolver API to work with Maven repositories. See also Apache Maven Artifact Resolver. Additional value of storing coverage data in a binary repository is that it can serve as an evidence of code quality stored with the compiled code, not in some other system. Source repository. Traditionally storing derived artifacts in a source repository is frowned upon. However, storage is cheap, GitHub Pages use this approach - so, whatever floats your boat! SonarQube - it doesn&rsquo;t store method level coverage, so the solution would have to operate on the class level and generate test methods for all methods in a class with low coverage. You may have a specialized application/model repository/database and store coverage information there, possibly aligned to your organization structure. Test Generation -&gt; Developer : Generated tests The goal is to deliver generated tests to the developer, make the developer aware that they are available, and possibly track progress of incorporating the generated tests into the test suite. With this in mind, there are the following alternatives/options: Filesystem - for the local loop Source control system - commit, create a merge/pull request. When using this channels you can check if there is already a generated test and whether it needs to be re-generated. If, say, the source method hasn&rsquo;t changed (the same SHA digest), and the generator version and configuration hasn&rsquo;t changed - do not re-generate, it will only consume resources and create &ldquo;noise&rdquo; - the LLM may return a different response, developers will have to spend time understanding what has changed. You may fork a repository instead of creating a branch. This way all work on tests will be done in the forked repository and the source repository will receive pull requests with fully functional tests. Tests can be generated to a separate directory and then copied to the source directory, or they can be generated directly to the source directory. Tests may be generated with @Disabled annotation so they are clearly visible in the test execution tree, and with @Generated annotation to track changes and merge generated and hand-crafted code. Issue tracking system - either attach generated tests to issues, or create a merge request and reference it from the generated issues. In systems like Jira you may create a hierarchy of issues (epic/story), assign components, labels, fix versions, assignees, etc. You may assign different generated tests to different developers based on size and complexity of the source method. E.g. tests for short methods with low complexity can be assigned to junior developers. This alone may give your team a productivity boost! E-mail or other messaging system. Issue trackers and messaging systems may be used to deliver generated documentation while source control will deliver generated tests. Developers will use the generated documentation such as graphs, sequence diagrams and GenAI explanations/recommendations in conjunction with the generated test code. This channel may implement some sort of backpressure by saying &ldquo;it is enough for now&rdquo;, as a human developer would by crying &ldquo;Enough is enough, I have other stories to work on in this sprint!&rdquo;. Generating just enough tests is beneficial in the following ways: Does not overwhelm developers Does not result in a stale generated code waiting to be taken a look at Does not waste resources and time to generate code which nobody would look at in the near future Uses the latest (and hopefully the greatest) generator version With backpressure a question of prioritization/sorting arises - what to work on first? Source methods can be sorted according to: Size/complexity Dependency. E.g. method b (caller) calls method a (callee) One strategy might be to work on callee methods first (method a) to provide a solid foundation. Another is to work on caller methods first because callee methods might be tested along the way. These strategies might be combined - some developers (say junior) may work on callee tests and senior developers may be assigned to test (complex) caller (top level) methods. Also, the top-down approach (callers first) might be better for addressing technical debt accrued over time, while bottom-up (callees first) for new development. Test Generation - GenAI : Prompt GenAI is neither free not blazing fast. As such, this channel may implement: Billing Rate limiting (throttling) Budgeting - so many calls per time period Caching Java Sources Source Artifacts Bytecode Coverage Data Developer JUnit Tests Gen AI Code Generation Compilation Test Execution JUnit Test Generation Coverage Report Java Sources Bytecode Coverage Data Developer Gen AI Coverage Model Source Code Model Tests Model Generator JUnit Test Generation Writing Code Compilation Testing Test Generation Gen AI"},"nsd-cli/index.html":{"action-uuid":"388cf1ef-d35b-492d-a22d-7f082c8a2d9e","title":"CLI","content":"Nasdanika Command Line Interface (CLI) is a suite of Nasdanika capabilities packaged as command line tools. Sources Prerequisites To run Nasdanika CLI you&rsquo;d need Java 17+. To build from sources you&rsquo;d also need Maven. Installation Download installation archive from the releases page. On Linux make nsd executable: chmod a+x nsd. Building from sources Download sources as a zip file or clone the repository Run mvn clean verify After the build completes the distribuion will be available in target/dist directory Adding to PATH The distribution is portable and local - it can be put to any directory, but it can only be executed from that directory. To create an installation which can be used from any directory you will need to create launcher files with absolute paths. Windows nsd.bat launcher -f options-global -o nsd-global.bat -s -m org.nasdanika.launcher -c org.nasdanika.launcher.Launcher -M modules -j &quot;@java&quot;\n Add the installation to the PATH environment variable. You may delete/rename nsd.bat and rename nsd-global.bat to nsd.bat. Linux ./nsd launcher -o nsd-global -s -m org.nasdanika.launcher -c org.nasdanika.launcher.Launcher -M modules\n Open nsd-global in a text editor and add #!/bin/bash line before the java command line. Make the file executable and add the installation directory to the path. You may remove/rename nsd and rename nsd-global to nsd. If you get java.lang.module.FindException: Module &lt;module name&gt; not found error, open the file in a text editor, locate the problematic module and remove it from the --add-modules list."},"core/drawio/index.html":{"path":"Core/Drawio","action-uuid":"e9ddef1e-fa0c-4d23-b3c5-a142d307c19f","title":"Drawio","content":"Nasdankia provides two Maven modules for working with Drawio diagrams - API and Model. The modules require Java 17 or above. API Page and element links Generating documentation sites Executable diagrams Model API Drawio module provides Java API for reading and manipulating Drawio diagrams. It is built on top of Graph. The module provides the following interfaces representing elements of a diagram file: Document - the root object of the API representing a file/resource which contains one or more pages. Page - a page containing a diagram (Model). Model - a diagram model containing the diagram root. Root - the root of the model containing layers. Layer - a diagram may have one or more layers. Layers contain Nodes and Connections. Node - a node can be connected to other nodes with connections. A node may contain other nodes and connections. Connection - a connection between two nodes. The below diagram shows relationships between the above interfaces including their super-interfaces: Util provides utility methods such as layout() and methods to navigate and query documents and their elements. Sources JavaDoc Page and element links Nasdanika Drawio API extends the concept of linking to pages to cross-document linking to pages and page elements by name or ID. Link targets (pages or elements) are available via getLinkTarget() method. Drawio page links have the following format: data:page/id,&lt;page id&gt; with page/id being the &ldquo;media type&rdquo; and &lt;page id&gt; being the &ldquo;data&rdquo; of a Data URL. Nasdanika Drawio API extends it to additional media types: page/name element/id element/name The data (selector) format has the following format: Page: [&lt;diagram resource&gt;#]&lt;page selector&gt; Diagram resource is a URI resolved relative to the current document URI. If not present then the link target page is in the same document. Page selector is either page ID or URL encoded page name depending on the media type - id or name. Element: [&lt;diagram resource&gt;#][&lt;page selector&gt;/]&lt;element selector&gt;] Diagram resource is a URI resolved relative to the current document URI. If not present then the link target element is in the same document. Page selector is either of: id,&lt;page id&gt; name,&lt;URL encoded page name&gt; Element selector is either page ID or URL encoded element label text (stripped of HTML formatting) depending on the media type - id or name. For elements URL&rsquo;s page selector is required if diagram resource URI is present. Examples: Page links: data:page/name,compressed.drawio#Page-1 - Link to compressed first page data:page/name,compressed.drawio#Page+2 - Link to compressed second page Element links: data:element/id,7KSC1_O8d7ACaxm1iSCq-1 - Link by ID to an element on the same page data:element/name,name,Page+2/Linked - Link by name to Linked on Page 2 referenced by name data:element/name,compressed.drawio#name,Page+2/Linked - Link to Linked on compressed second page This approach allows to create a multi-resource graph of diagrams. Nasdanika Drawio API also supports loading of documents from arbitrary URI&rsquo;s using a URI resolver. For example, maven://&lt;gav&gt;/&lt;resource path&gt; to load from Maven resources or gitlab://&lt;project&gt;/&lt;path&gt; to load resources from GitLab without cloning a repository, provided there is a handler (Function&lt;URI,InputStream&gt;) supporting the aforementioned URI&rsquo;s. Generating documentation sites With Nasdanika CLI drawio &gt; html-app &gt; site command pipeline can be used to generate documentation web sites from Drawio diagrams: Demo Video explaining how the above demo was created Template repository Internet Banking System - another demo: a sample C4 Model Visual Communication Continuum - a Medium story which provides an overview of the approach and compares it with semantic mapping Executable diagrams With Nasdanika Drawio API and other products you can make your diagrams executable. There are two primary methods: Creating graph element processors for diagram elements Mapping diagrams to a semantic model and then making the model executable, possibly using graph processors The first option requires less coding, the second is more flexible. Executable (computational) graphs &amp; diagrams story provides a high level overview of executable graphs and diagrams. Graph documentation features more technical details and code samples. Beyond Diagrams book explains the mapping approach. And Compute Graph Demo provides examples of the both approaches using the compute graph from the &ldquo;Executable (computational) graphs &amp; diagrams&rdquo; story. Model Drawio Model module provides an EMF Ecore model for diagrams. A model instance can be obtained from the API document by calling Document.toModelDocument() method. The model makes it more convenient to work with the diagram elements by: Making links from diagram elements to pages and other diagram elements bi-directional. Introducing Tag class as opposed to a string in the API. Tag is contained by Page and has bi-directional reference with tagged elements. Sources JavaDoc Document The root object of the API representing a file/resource which contains one or more pages Page A page containing a diagram (Model) Model A diagram model containing the diagram root Root The root of the model containing layers Layer A diagram may have one or more layers. Layers contain Nodes and Connections. Layer Element Element Model Element Node A node can be connected to other nodes with connections. A node may contain other nodes and connections. Connection A connection between two nodes * source 0..1 outgoingConnections * 1 1 1..* * target 0..1 incomingConnections * Tag * * * Link Target linkTarget 0..1"},"nsd-cli/nsd/java/junit/index.html":{"path":"CLI/nsd/java/junit","action-uuid":"545f6db6-1eea-4ff1-bacf-714839c89bdb","title":"junit","content":"Version: org.nasdanika.models.java.cli \r\nUsage: nsd java junit [-hVw] [--[no-]ai] [--[no-]comment-response] [--disabled]\r\n                      [--progress-console] [--progress-data] [--progress-json]\r\n                      [--api-endpoint=&lt;apiEndpoint&gt;] [-c=&lt;classes&gt;]\r\n                      [--class-suffix=&lt;classSuffix&gt;] [-J=&lt;jacoco&gt;]\r\n                      [-k=&lt;apiKey&gt;] [-l=&lt;limit&gt;] [-m=&lt;deploymentOrModelName&gt;]\r\n                      [--package-suffix=&lt;packageSuffix&gt;]\r\n                      [--progress-output=&lt;progressOutput&gt;] [-r=&lt;prompt&gt;]\r\n                      [-s=&lt;sources&gt;] [-t=&lt;coverageType&gt;]\r\n                      [-v=&lt;apiKeyEnvironmentVariable&gt;] [-e[=&lt;excludes&gt;...]]...\r\n                      [-i[=&lt;includes&gt;...]]... &lt;projectDir&gt; &lt;coverageThreshold&gt;\r\n                      &lt;output&gt;\r\nGenerates JUnit tests\r\n      &lt;projectDir&gt;          Project directory\r\n      &lt;coverageThreshold&gt;   Coverage threshold\r\n      &lt;output&gt;              Output directory\r\n                            relative to the project directory\r\n      --[no-]ai             Use AI, defaults to true\r\n      --api-endpoint=&lt;apiEndpoint&gt;\r\n                            OpenAPI endpoint, defaults to\r\n                            https://api.openai.com/v1/chat/completions\r\n  -c, --classes=&lt;classes&gt;   Classes directory path relative\r\n                            to the project directory,\r\n                            defaults to target/classes\r\n      --class-suffix=&lt;classSuffix&gt;\r\n                            Test class suffix\r\n                            defaults to Tests\r\n      --[no-]comment-response\r\n                            Comment AI responses\r\n                            defaults to true\r\n      --disabled            Generate disabled tests\r\n  -e, --exclude[=&lt;excludes&gt;...]\r\n                            Source excludes\r\n                            Ant pattern\r\n  -h, --help                Show this help message and exit.\r\n  -i, --include[=&lt;includes&gt;...]\r\n                            Source includes\r\n                            Ant pattern\r\n  -J, --jacoco=&lt;jacoco&gt;     jacoco.exec file path relative\r\n                            to the project directory,\r\n                            defaults to target/jacoco.exec\r\n  -k, --api-key=&lt;apiKey&gt;    OpenAPI key\r\n  -l, --limit=&lt;limit&gt;       Maximum number of test classes\r\n                            to generate\r\n  -m, --model=&lt;deploymentOrModelName&gt;\r\n                            OpenAPI deployment or model\r\n                            defaults to gpt-4\r\n      --package-suffix=&lt;packageSuffix&gt;\r\n                            Test package suffix\r\n                            defaults to .tests\r\n      --progress-console    Output progress to console\r\n      --progress-data       Output progress data\r\n      --progress-json       Output progress in JSON\r\n      --progress-output=&lt;progressOutput&gt;\r\n                            Output file for progress monitor\r\n  -r, --prompt=&lt;prompt&gt;     Propmt\r\n                            defaults to 'Generate a JUnit 5 test method\r\n                              leveraging Mockito for the following Java method'\r\n  -s, --sources=&lt;sources&gt;   Sources directory path relative\r\n                            to the project directory,\r\n                            defaults to src/main/java\r\n  -t, --coverage-type=&lt;coverageType&gt;\r\n                            Coverage type\r\n                            Valid values: complexity, instruction, branch, line\r\n                            defaults to line\r\n  -v, --api-key-variable=&lt;apiKeyEnvironmentVariable&gt;\r\n                            OpenAPI key environment variable\r\n                            defaults to OPENAI_API_KEY\r\n  -V, --version             Print version information and exit.\r\n  -w, --overwrite           Overwrite existing tests"},"nsd-cli/nsd/model/save/index.html":{"path":"CLI/nsd/model/save","action-uuid":"266ce5c2-50f7-47bc-9be0-5bcf6d1a678f","title":"save","content":"Version: org.nasdanika.cli \r\nUsage: nsd model save [-hV] [--progress-console] [--progress-data]\r\n                      [--progress-json] [--progress-output=&lt;progressOutput&gt;]\r\n                      [--content-type-resource-factory=&lt;String=Class&gt;]...\r\n                      [--extension-resource-factory=&lt;String=Class&gt;]...\r\n                      [--protocol-resource-factory=&lt;String=Class&gt;]... &lt;output&gt;\r\nSaves model to a file\r\n      &lt;output&gt;             Output file\r\n      --content-type-resource-factory=&lt;String=Class&gt;\r\n                           Maps content type to resource factory class\r\n      --extension-resource-factory=&lt;String=Class&gt;\r\n                           Maps extension to resource factory class\r\n  -h, --help               Show this help message and exit.\r\n      --progress-console   Output progress to console\r\n      --progress-data      Output progress data\r\n      --progress-json      Output progress in JSON\r\n      --progress-output=&lt;progressOutput&gt;\r\n                           Output file for progress monitor\r\n      --protocol-resource-factory=&lt;String=Class&gt;\r\n                           Maps protocol to resource factory class\r\n  -V, --version            Print version information and exit."},"nsd-cli/nsd/drawio/html-app/index.html":{"path":"CLI/nsd/drawio/html-app","action-uuid":"5499b72a-da44-4fbb-8374-74e943f04532","title":"html-app","content":"Version: org.nasdanika.cli \r\nUsage: nsd drawio html-app [-fhRV] [-b=&lt;base&gt;] [-P=&lt;insertionIndex&gt;]\r\n                           [-r=&lt;rootLabel&gt;]\r\n                           [--content-type-resource-factory=&lt;String=Class&gt;]...\r\n                           [--extension-resource-factory=&lt;String=Class&gt;]...\r\n                           [--protocol-resource-factory=&lt;String=Class&gt;]...\r\n                           [COMMAND]\r\nGenerates html application model from a drawio document\r\n  -b, --base-uri=&lt;base&gt;   Base URI. E.g. 'pages/'\r\n      --content-type-resource-factory=&lt;String=Class&gt;\r\n                          Maps content type to resource factory class\r\n      --extension-resource-factory=&lt;String=Class&gt;\r\n                          Maps extension to resource factory class\r\n  -f, --file              Root action option is a file path\r\n  -h, --help              Show this help message and exit.\r\n  -P, --position=&lt;insertionIndex&gt;\r\n                          Insertion position\r\n                          Defaults to 0\r\n      --protocol-resource-factory=&lt;String=Class&gt;\r\n                          Maps protocol to resource factory class\r\n  -r, --root-label=&lt;rootLabel&gt;\r\n                          Root label URL or file path, resolved relative\r\n                          to the current directory\r\n  -R, --add-to-root       Add labels to the root\r\n                          even if the principal is present\r\n  -V, --version           Print version information and exit.\r\nCommands:\r\n  save  Saves model to a file\r\n  site  Generates HTML site"},"practices/java/index.html":{"path":"Practices/Java Analysis, Visualization &amp; Generation","action-uuid":"8050c3e7-c358-4886-8120-b4573821b95b","title":"Java Analysis, Visualization &amp; Generation","content":"This practice is a specialization of the Analysis, Visualization &amp; Generation Practice for using the Java model as a source model, target model, or both. This page provides a high level reference and the book goes into details. So what is possible to do with the Java model/language in addition to generic analysis, visualization and generation? Analysis Java model can be loaded from sources and bytecode. Tests coverage can be loaded from jacoco.exec and class files and associated with model elements. Bytecode information can be used to establish bi-directional references between model elements - field access, method calls. Bytecode can be instrumented to collect runtime cross-referencing such as reflective method calls and field access. Visualization Module, package, class, method dependency graphs. The graphs may reflect coverage data so they can be used for prioritization of addressing technical debt. For example, many well-covered microservices may use a shared library with low coverage. Sequence diagrams Generation Documentation Documentation similar to documentation generated from Ecore models such as Java model above, Family model, or Enterprise model with: * Visualizations mentioned above\n* Documentation produced by GenAI - explainations and recommendations.\n Such documentation may be useful in modernization efforts where there is a need to understand a legacy codebase. It may also be useful in onboarding of new team members and it might help provide deeper insights into the codebase for all team members. Source code Source code with @Generated annotations or @generated Javadoc tags to allow detection of changes in the generated code and re-generation only if there changes in the generator inputs, and the output was not modified since the last generation. It allows concurrent evolution of the generator, generator inputs, and manual modifications. For more details see Solution instantiation. RAG/Chat RAG/Chat on top of the Java model may use bytecode and runtime introspection information in addition to just source code. For example &ldquo;This method is overridden by &hellip; and is called by &hellip;&rdquo;. RAG may be contextual - chat with a class, a method, a package, a module or an application (group of modules) if the model elements are &ldquo;mounted&rdquo; under higher level constructs such as products and segments."},"core/capability/index.html":{"path":"Core/Capability","action-uuid":"23c20a97-20d7-4ed0-bff5-cffd0af9b3bf","title":"Capability","content":"Nasdanika Capability framework1 allows to discover/load capabilities which meet a requirement. Capabilities are provided by CapabilityFactory create() method. Capability factories may request other capabilities they need. As such, capabilities can be chained. Factories create CapabilityLoaders which provide Flux reactive streams of capabilities. It allows to have an infinite stream of capabilities which are consumed (and produced) as needed. Capability providers may furnish additional information about capabilities. This information can be used for filtering or sorting providers. Capability providers may also provide functionality such as: Implement Autocloseable and release resources associated with capabilities upon closing. Implement Lock or ReadWriteLock to guard access to provided capabilities. Extending on the above, a capability provider may implement Domain/Realm with a command stack - obtain, execute commands with locking, close. A non-technical example of requirement/capability chain graph is a food chain/graph. Food is a requirement. Or &ldquo;I want to eat&rdquo; is a requirement. Bread and, say fried eggs are two capabilities meeting/addressing the requirement. Bread requires &ldquo;wheat&rdquo;, &ldquo;water&rdquo;, and &ldquo;bake&rdquo; capabilities. Fried eggs require &ldquo;egg&rdquo;, &ldquo;oil&rdquo;, and &ldquo;fry&rdquo; capabilities. &ldquo;bake&rdquo; capability is provided by an oven which may have a command stack or a lock because only one thing can be baked at a time. Bread capability provider may implement Vegan marker interface which can be used for filtering. All food capabilities may implement NutritionalInformation interface - it can be used for filtering or sorting. A more technical example is Java ServiceLoader with service type being a requirement and an instance of the service class being a capability. Nasdanika capability framework can operate on top of ServiceLoader and may be thought of as a generalization of service loading. In essence, the capability framework is a backward chaining engine as shown in one of the examples below. Sources Javadoc Client code - requesting a capability Service capabilities Providing a capability Loading Invocables from URIs Examples String value URL encoded URL and Base64 encoded Java Constructor Static method Script Spec JSON YAML Drawio diagram Specification URI Data value/ java/ application//invocable Hierarchical YAML/JSON specification EMF Requesting a ResourceSet With all packages and factories Selecting contributors Providing ResourceSet instance Contributing EPackages Resource factories URI handlers Applications Services Solutions for architectures Backward chaining Stream processing AI model training/fine-tuning Client code - requesting a capability Capabilities are loaded by CapabilityLoader. Capability loader can take an iterable of capability factories in its constructor, or it can load them using ServiceLoader as shown in the below code snippet: CapabilityLoader capabilityLoader = new CapabilityLoader();\ncapabilityLoader.getFactories().add(new TestServiceFactory&lt;Object&gt;());\nProgressMonitor progressMonitor = new PrintStreamProgressMonitor();\n\t\t\nfor (CapabilityProvider&lt;?&gt; cp: capabilityLoader.load(new TestCapabilityFactory.Requirement(&quot;Hello World&quot;), progressMonitor)) {\n\tSystem.out.println(cp);\n\tFlux&lt;?&gt; publisher = cp.getPublisher();\n\t\t\t\n\tpublisher.subscribe(System.out::println);\n}\n Factories can also be added post-construction with getFactories().add(factory). Service capabilities Service requirements and capabilities provide functionality similar to ServiceLoader - requesting instances of specific type, but extend it with ability to provide additional service requirement. This functionality is provided by ServiceCapabilityFactory and ServiceCapabilityFactory.Requirement. CapabilityLoader capabilityLoader = new CapabilityLoader();\ncapabilityLoader.getFactories().add(new TestServiceFactory&lt;Object&gt;());\nProgressMonitor progressMonitor = new PrintStreamProgressMonitor();\n\t\t\n@SuppressWarnings({ &quot;unchecked&quot;, &quot;rawtypes&quot; })\nServiceCapabilityFactory.Requirement&lt;List&lt;Double&gt;, Double&gt; requirement = (ServiceCapabilityFactory.Requirement) ServiceCapabilityFactory.createRequirement(List.class, null,  33.0);\nfor (CapabilityProvider&lt;?&gt; cp: capabilityLoader.load(requirement, progressMonitor)) {\n\tSystem.out.println(cp);\n\tFlux&lt;?&gt; publisher = cp.getPublisher();\n\t\t\t\n\tpublisher.subscribe(System.out::println);\n}\n It is also possible to load services from ServiceLoader using subclasses of Service. You&rsquo;d need to subclass ServiceFactory in a module which uses a particular service and override stream(Class&lt;S&gt; service) method as shown below: @Override\nprotected Stream&lt;Provider&lt;S&gt;&gt; stream(Class&lt;S&gt; service) {\n\treturn ServiceLoader.load(service).stream();\n}\n Then you&rsquo;d need to add the factory to the loader: capabilityLoader.getFactories().add(new TestServiceFactory&lt;Object&gt;());\n Providing a capability As it was mentioned above, capability factories can be explicitly added to CapabilityLoader or loaded using ServiceLoader. Below is an example of a capability factory: public class TestCapabilityFactory implements CapabilityFactory&lt;TestCapabilityFactory.Requirement, Integer&gt; {\n\t\n\tpublic record Requirement(String value){};\n\t\n\t@Override\n\tpublic boolean canHandle(Object requirement) {\n\t\treturn requirement instanceof Requirement;\n\t}\n\n\t@Override\n\tpublic CompletionStage&lt;Iterable&lt;CapabilityProvider&lt;Integer&gt;&gt;&gt; create(\n\t\t\tRequirement requirement,\n\t\t\tBiFunction&lt;Object, ProgressMonitor, CompletionStage&lt;Iterable&lt;CapabilityProvider&lt;Object&gt;&gt;&gt;&gt; resolver,\n\t\t\tProgressMonitor progressMonitor) {\n\t\t\n\t\treturn resolver.apply(MyService.class, progressMonitor).thenApply(cp -&gt; {;\n\t\t\t@SuppressWarnings({ &quot;unchecked&quot;, &quot;rawtypes&quot; })\n\t\t\tFlux&lt;MyService&gt; myServiceCapabilityPublisher = (Flux) cp.iterator().next().getPublisher();\n\t\t\t\n\t\t\treturn Collections.singleton(new CapabilityProvider&lt;Integer&gt;() {\n\t\n\t\t\t\t@Override\n\t\t\t\tpublic Flux&lt;Integer&gt; getPublisher() {\n\t\t\t\t\tFunction&lt;MyService, Integer&gt; mapper = ms -&gt; ms.count(((Requirement) requirement).value());\n\t\t\t\t\treturn myServiceCapabilityPublisher.map(mapper);\n\t\t\t\t}\n\t\t\t\t\n\t\t\t});\n\t\t});\n\t}\n\n}\n There is a number of implementations of CapabilityFactory is different Nasdanika modules, most of them extending ServiceCapability. In Eclipse or other IDE open CapabilityFactory type hierarchy to discover available implementations. Loading Invocables from URIs The capability framework allows to create/load implementations of Invocable from URI&rsquo;s: In conjunction with the Maven module implementations can be loaded from Maven repositories. Invocables can be implemented in scripting languages, e.g. Groovy. Scripts may use dependencies loaded from Maven repositories. Script engine themselves can be loaded from Maven repositories. Drawio diagrams can be made executable by adding invocable URI properties to diagram elements. They can then be wrapped into a dynamic proxy and invocable URI&rsquo;s. Examples String value URL encoded data:value/String,Hello+World data URL is converted to an Invocable which takes zero arguments and returns URL-decoded data part of the URL (after comma). CapabilityLoader capabilityLoader = new CapabilityLoader();\nProgressMonitor progressMonitor = new PrintStreamProgressMonitor();\nURI requirement = URI.createURI(&quot;data:value/String,Hello+World&quot;);\nInvocable invocable = capabilityLoader.loadOne(\n\t\tServiceCapabilityFactory.createRequirement(Invocable.class, null, requirement),\n\t\tprogressMonitor);\nObject result = invocable.invoke();\nSystem.out.println(result);\n URL and Base64 encoded data:value/String;base64,SGVsbG8= is converted to an Invocable which takes zero arguments and returns URL-decoded and then Base64 decoded data part converted to String. CapabilityLoader capabilityLoader = new CapabilityLoader();\nProgressMonitor progressMonitor = new PrintStreamProgressMonitor();\nURI requirement = URI.createURI(&quot;data:value/String;base64,SGVsbG8=&quot;);\nInvocable invocable = capabilityLoader.loadOne(\n\t\tServiceCapabilityFactory.createRequirement(Invocable.class, null, requirement),\n\t\tprogressMonitor);\nObject result = invocable.invoke();\nSystem.out.println(result);\n Java Constructor data:java/org.nasdanika.capability.tests.MyTestClass;base64,SGVsbG8= is converted to an Invocable which invokes MyTestClass constructor. CapabilityLoader capabilityLoader = new CapabilityLoader();\nProgressMonitor progressMonitor = new PrintStreamProgressMonitor();\nURI requirement = URI.createURI(&quot;data:java/org.nasdanika.capability.tests.MyTestClass;base64,SGVsbG8=&quot;);\nInvocable invocable = capabilityLoader.loadOne(\n\t\tServiceCapabilityFactory.createRequirement(Invocable.class, null, requirement),\n\t\tprogressMonitor);\nObject result = invocable.invoke();\nSystem.out.println(result);\n In the above code snippet invocable is invoked with no arguments, which matches the below constructor passing the decoded data part of the URL in binding argument: public MyTestClass(\n\t\tCapabilityFactory.Loader loader, \n\t\tProgressMonitor progressMonitor, \n\t\tbyte[] binding) {\n\t...\n}\t\n The below snippet passes 33 argument to invoke(): CapabilityLoader capabilityLoader = new CapabilityLoader();\nProgressMonitor progressMonitor = new PrintStreamProgressMonitor();\nURI requirement = URI.createURI(&quot;data:java/org.nasdanika.capability.tests.MyTestClass;base64,SGVsbG8=&quot;);\nInvocable invocable = capabilityLoader.loadOne(\n\t\tServiceCapabilityFactory.createRequirement(Invocable.class, null, requirement),\n\t\tprogressMonitor);\nObject result = invocable.invoke(33);\nSystem.out.println(result);\n Which matches the below constructor: public MyTestClass(\n\t\tCapabilityFactory.Loader loader, \n\t\tProgressMonitor progressMonitor, \n\t\tbyte[] binding, \n\t\tint arg) {\n\t...\n}\n 33 is passed via the arg argument. Static method Static methods can be addresed by adding :: and method name after the class name as in this URL: data:java/org.nasdanika.capability.tests.MyTestClass::factory;base64,SGVsbG8=. The resulting Invocable will select the best matching factory method. CapabilityLoader capabilityLoader = new CapabilityLoader();\nProgressMonitor progressMonitor = new PrintStreamProgressMonitor();\nURI requirement = URI.createURI(&quot;data:java/org.nasdanika.capability.tests.MyTestClass::factory;base64,SGVsbG8=&quot;);\nInvocable invocable = capabilityLoader.loadOne(\n\t\tServiceCapabilityFactory.createRequirement(Invocable.class, null, requirement),\n\t\tprogressMonitor);\nObject result = invocable.invoke();\nSystem.out.println(result);\n In the above code snippet invoke() has no arguments and therefore the below method matches: public static MyTestClass factory(\n\t\tCapabilityFactory.Loader loader, \n\t\tProgressMonitor progressMonitor, \n\t\tbyte[] binding) {\n\t...\n}\n As with constructors, the decoded data part is passed to the method as binding argument. In the below snippet invoke() takes 55 argument: CapabilityLoader capabilityLoader = new CapabilityLoader();\nProgressMonitor progressMonitor = new PrintStreamProgressMonitor();\nURI requirement = URI.createURI(&quot;data:java/org.nasdanika.capability.tests.MyTestClass::factory;base64,SGVsbG8=&quot;);\nInvocable invocable = capabilityLoader.loadOne(\n\t\tServiceCapabilityFactory.createRequirement(Invocable.class, null, requirement),\n\t\tprogressMonitor);\nObject result = invocable.invoke(55);\nSystem.out.println(result);\n Which matches the below method: public static MyTestClass factory(\n\t\tCapabilityFactory.Loader loader, \n\t\tProgressMonitor progressMonitor, \n\t\tbyte[] binding,\n\t\tint arg) {\n\t...\n}\n Script The below snippet exectutes test.groovy script in the current directory. ScriptEngineManger is used to get a ScriptEngine by extension. Therefore, the engine factory shall be registered with the script engine manager. CapabilityLoader capabilityLoader = new CapabilityLoader();\nProgressMonitor progressMonitor = new PrintStreamProgressMonitor();\nURI requirement = URI.createFileURI(new File(&quot;test.groovy&quot;).getCanonicalPath());\nInvocable invocable = capabilityLoader.loadOne(\n\t\tServiceCapabilityFactory.createRequirement(Invocable.class, null, requirement),\n\t\tprogressMonitor);\nObject result = invocable.invoke();\nSystem.out.println(result);\n This is the test script: import org.nasdanika.capability.CapabilityFactory.Loader\nimport org.nasdanika.common.ProgressMonitor\n\n// Script arguments for reference\nLoader loader = args[0];\nProgressMonitor loaderProgressMonitor = args[1];\nObject data = args[2];\n\nSystem.out.println(args);\n&quot;I've got &quot; + args.length + &quot; arguments!&quot;\n Similar to Java constructors and static methods, it takes the following arguments: CapabilityFactory.Loader to request additional capabilities if needed ProgressMonitor to report progress and pass to the loader methods URI&rsquo;s fragment value or null Invocable arguments In the below code the script receives Hello as its third argument (binding) and Universe as its fourth argument: CapabilityLoader capabilityLoader = new CapabilityLoader();\nProgressMonitor progressMonitor = new PrintStreamProgressMonitor();\nURI requirement = URI.createFileURI(new File(&quot;test.groovy&quot;).getCanonicalPath()).appendFragment(&quot;Hello&quot;);\nInvocable invocable = capabilityLoader.loadOne(\n\t\tServiceCapabilityFactory.createRequirement(Invocable.class, null, requirement),\n\t\tprogressMonitor);\nObject result = invocable.invoke(&quot;Universe&quot;);\nSystem.out.println(result);\n Spec Spec URI&rsquo;s allow to specify Maven dependencies to construct a ClassLoader for loading Java classes including script engine factories. It is also to specify a module path to construct a module layer. JSON CapabilityLoader capabilityLoader = new CapabilityLoader();\nProgressMonitor progressMonitor = new PrintStreamProgressMonitor();\nURI specUri = URI.createFileURI(new File(&quot;test-specs/java.json&quot;).getCanonicalPath()).appendFragment(&quot;Hello+World&quot;);\nInvocable invocable = capabilityLoader.loadOne(\n\t\tServiceCapabilityFactory.createRequirement(Invocable.class, null, new URIInvocableRequirement(specUri)),\n\t\tprogressMonitor);\nObject result = invocable.invoke();\nSystem.out.println(result);\n The above snippet uses the below spec to create an instance of MyTestClass: {\n\t&quot;type&quot;: &quot;org.nasdanika.capability.tests.MyTestClass&quot;,\n\t&quot;bind&quot;: [\n\t\t&quot;data:value/String,Some+other+value&quot;\n\t]\n}\t\n Similar to data URL&rsquo;s a matching constructor is found for the following arguments: CapabilityFactory.Loader ProgressMonitor String - URL decoded URI fragment, may be null Bindings loaded from the bind array of URI&rsquo;s Below is the matching constructor: public MyTestClass(\n\t\tCapabilityFactory.Loader loader, \n\t\tProgressMonitor progressMonitor, \n\t\tString fragment,\n\t\tString bind) {\n\t...;\n}\t\n YAML CapabilityLoader capabilityLoader = new CapabilityLoader();\nProgressMonitor progressMonitor = new PrintStreamProgressMonitor(true);\nURI specUri = URI.createFileURI(new File(&quot;test-specs/groovy.yml&quot;).getCanonicalPath()).appendFragment(&quot;Hello+World&quot;);\nInvocable invocable = capabilityLoader.loadOne(\n\t\tServiceCapabilityFactory.createRequirement(Invocable.class, null, new URIInvocableRequirement(specUri)),\n\t\tprogressMonitor);\nObject result = invocable.invoke();\nSystem.out.println(result);\n The above snippet executes Groovy script specified inline in the below YAML: script:\n  engineFactory: org.codehaus.groovy.jsr223.GroovyScriptEngineFactory\n  source: |\n    &quot;Hello, world! &quot; + myBinding + &quot; &quot; + args[2]\n  bindings:\n    myBinding: data:value/String,Some+value\ndependencies: org.apache.groovy:groovy-all:pom:4.0.23\nlocalRepository: target/groovy-test-repo\n In this case org.apache.groovy:groovy-all:pom:4.0.23 Maven coordinates are used to load Groovy with all dependencies and construct a ClassLoader. Because the engine was loaded at runtime, it is not known to the ScriptEngineManager and has to be explicitly specified. The script gets an args array with loader, progress monitor, decoded fragment and arguments passed to invoke(). It also gets named bindings loaded from the bindings map entries. Drawio diagram Below is a YAML spec with an embedded diagram: diagram:\n  source: |\n    &lt;mxfile ...abridged... &lt;/mxfile&gt;\n  processor: processor\n  bind: bind\n  interfaces: java.util.function.Function\n And this is a YAML specification which references a diagram: diagram:\n  location: diagram.drawio\n  processor: processor\n  bind: bind\n  interfaces: java.util.function.Function\n The below code loads the spec, passes the fragment to the diagram as properties in addition to the properties from the spec, creates a dynamic proxy which invokes diagram element processors, and uses the proxy to execute the diagram logic: CapabilityLoader capabilityLoader = new CapabilityLoader();\nProgressMonitor progressMonitor = new PrintStreamProgressMonitor();\nURI specUri = URI.createFileURI(new File(&quot;diagram-function.yml&quot;).getCanonicalPath()).appendFragment(&quot;my-property=Hello&quot;);\nInvocable invocable = capabilityLoader.loadOne(\n\t\tServiceCapabilityFactory.createRequirement(Invocable.class, null, new URIInvocableRequirement(specUri)),\n\t\tprogressMonitor);\nFunction&lt;String,Object&gt; result = invocable.invoke();\nSystem.out.println(result);\nSystem.out.println(result.apply(&quot;YAML&quot;));\n See Capability tests and Executable Diagrams Dynamic Proxy demo for more examples. Specification URI This section explains supported URI formats. Please note that using a custom URIHandler you may: Normalize &ldquo;logical&rdquo; URI&rsquo;s to supported &ldquo;physical&rdquo; URI&rsquo;s. Implement openStream() For example normalized my-building-blocks://gen-ai/chat-completions to a specification of a chat completions component, say, gitlab://my-shared-components/open-ai/chat-completions.yml and then implement openStream() which supports gitlab scheme[^gitlab_urihandler] Data Data URI has the following format: data:[&lt;mediatype&gt;][;base64],&lt;data&gt;[#fragment]. The following sections describe supported media types. value/ an instance of the class is constructed from the data part bytes, fragment is ignored. if the class name does not contain dots then java.lang. prefix is added to the class name. Examples: * data:value/String,Hello+World * data:value/String;base64,SGVsbG8= java/ Class constructors or static methods are wrapped into an Invocable and the matching constructor/method is invoked from the resulting Invocable.invoke(). Constructors/methods shall have the following signature: CapabilityFactory.Loader to request additional capabilities if needed ProgressMonitor to report progress and pass to the loader methods byte[] - the data part String - fragment Optional additional parameters for arguments passed to the result Invocable Examples: data:java/org.nasdanika.capability.tests.MyTestClass;base64,SGVsbG8=#World data:java/org.nasdanika.capability.tests.MyTestClass::factory;base64,SGVsbG8= application//invocable With format being either yaml or json. YAML or JSON specification (see below) encoded into the data part. Example: data:application/yaml/invocable;base64,c2Nya...abridged...1yZXBv Hierarchical If the hierarchical URI&rsquo;s last segment ends with .yml or .yaml (case insensitive) it is treated as a YAML specification (see below). If the last segment ends with .json (also case insensitive) it is treated as a JSON specification. Otherwise a script engine is looked up by extension (the part of the last segments after the last dot). E.g. groovy. Scripts receive args binding (variable) of type Object[] with the following elements: CapabilityFactory.Loader to request additional capabilities if needed ProgressMonitor to report progress and pass to the loader methods String - fragment Arguments passed to the result Invocable YAML/JSON specification YAML/JSON specification is pre-processed and then loaded into InvocableRequirement. The specification supports the following configuration entries: diagram - Map, loaded into DiagramRecord: location - String, URI of the diagram location relative to the specification location. source - String, diagram source. Either location or source shall be used. base - String, base URI if source is used properties - Map, properties to pass to the diagram. Nested properties can be addressed using &ldquo;.&rdquo; (dot) separator. For arrays index is used as key. E.g. people.3.name. If URI fragment is present it is parsed into name/value pairs in the same way as query strings are parsed. Fragment properties overwrite spec properties. processor - optional String, property to load processor specifications from. One diagram element may have multiple processor specifications in different properties. Also, property expansion can be used to customize processor specification. E.g. %env%/storage.yaml would point to different specifications depending on the value of %env% property. bind - optional String, property for a dynamic proxy method name or signature interfaces - optional String or List, dynamic proxy interfaces type - String, class name or method reference is ends with ::&lt;static method name&gt; script - Map, loaded into ScriptRecord: location - String, URI of script sources source - String, script source. Either location or source shall be used language - String, script language (mime type) for source. For location if language is not specified it is derived from extension. engineFactory - String, fully qualified name of a script engine factory implementation. Use if the engine is loaded from dependencies and therefore is not visible to the script engine manager. If engineFactory is specified language and location extension are ignored. bindings - Map, values are treated as Invocable URIs providing binding values. Loader, progress monitor, fragment and invocable arguments are available to the script via the args binding of type Object[]. bind - String or List, Invocable URIs to bind to the type Invocable. Not supported by diagram and script. modulePath - optional String or List, module path. If null, derived from root modules if they are present rootModules - optional String or List, root modules. The first root module is used to obtain the class loader oneLayerClassLoader - optional boolean indicating whether a single class loader shall be used for all modules in in the layer dependencies - optional String or List of dependencies in &lt;groupId&gt;:&lt;artifactId&gt;[:&lt;extension&gt;[:&lt;classifier&gt;]]:&lt;version&gt;} format. E.g. org.apache.groovy:groovy-all:pom:4.0.23 managedDependencies - optional String or List of dependencies in &lt;groupId&gt;:&lt;artifactId&gt;[:&lt;extension&gt;[:&lt;classifier&gt;]]:&lt;version&gt;} format remoteRepositories - Map (single remote repository) or List of Maps of remote repository definitions loaded into RemoteRepoRecord: id - String, repo ID type - String, optional repo type url - String, repository URL proxy - optional Map: type - String, http or https host - String port - integer auth - authentication (see below) auth - Map: username - String password - String mirroredRepositories - Map or List, mirrored repositories localRepository - optional String, path to the local repository to download dependencies to. Defaults to repository. Maven dependency resolution uses default values as explained in the Maven module documentation. diagram, type and script are mutually exclusive. Note: extends key is reserved for future releases to support spec inheritance. EMF Many of Nasdanika capabilities are based on Eclipse Modeling Framework (EMF)2, Ecore3 models in particular. One of key objects in EMF Ecore is a ResourceSet. Resource set has a package registry, resource factory registry, and URI converter. org.nasdanika.capability.emf packages provides capability factories for contributing to resource set. It allows to request resource set from a capability loader and the returned resource set would be configured with registered EPackages, resource factories, adapter factories and URIHandlers. Requesting a ResourceSet With all packages and factories CapabilityLoader capabilityLoader = new CapabilityLoader();\nProgressMonitor progressMonitor = new PrintStreamProgressMonitor();\nRequirement&lt;ResourceSetRequirement, ResourceSet&gt; requirement = ServiceCapabilityFactory.createRequirement(ResourceSet.class);\t\t\nfor (CapabilityProvider&lt;?&gt; capabilityProvider: capabilityLoader.load(requirement, progressMonitor)) {\n\tResourceSet resourceSet = (ResourceSet) capabilityProvider.getPublisher().blockFirst();\n}\n Selecting contributors CapabilityLoader capabilityLoader = new CapabilityLoader();\nProgressMonitor progressMonitor = new PrintStreamProgressMonitor();\n\nPredicate&lt;ResourceSetContributor&gt; contributorPredicate = ...;\nResourceSetRequirement serviceRequirement = new ResourceSetRequirement(null, contributorPredicate);\n\t\t\nRequirement&lt;ResourceSetRequirement, ResourceSet&gt; requirement = ServiceCapabilityFactory.createRequirement(ResourceSet.class, null, serviceRequirement);\t\t\n\nfor (CapabilityProvider&lt;?&gt; capabilityProvider: capabilityLoader.load(requirement, progressMonitor)) {\n\tResourceSet resourceSet = (ResourceSet) capabilityProvider.getPublisher().blockFirst();\n}\n Providing ResourceSet instance You may provide an instance of ResourceSet to configure in the requirement. Contributing EPackages Create a class extending EPackageCapabilityFactory: public class NcoreEPackageResourceSetCapabilityFactory extends EPackageCapabilityFactory {\n\n\t@Override\n\tprotected EPackage getEPackage() {\n\t\treturn NcorePackage.eINSTANCE;\n\t}\n\n\t@Override\n\tprotected URI getDocumentationURI() {\n\t\treturn URI.createURI(&quot;https://ncore.models.nasdanika.org/&quot;);\n\t}\n\n}\n and add it to module-info.java provides: provides CapabilityFactory with NcoreEPackageResourceSetCapabilityFactory;\n Resource factories Create a class extending ResourceFactoryCapabilityFactory: public class XMIResourceFactoryCapabilityFactory extends ResourceFactoryCapabilityFactory {\n\n\t@Override\n\tprotected Factory getResourceFactory() {\n\t\treturn new XMIResourceFactoryImpl();\n\t}\n\t\n\t@Override\n\tprotected String getExtension() {\n\t\treturn Resource.Factory.Registry.DEFAULT_EXTENSION;\n\t}\n\n}\n and add it to module-info.java provides CapabilityFactory. URI handlers Create a class extending URIConverterContributorCapabilityFactory: public class ClassPathURIHandlerResourceSetCapabilityFactory extends URIConverterContributorCapabilityFactory {\n\n\t@Override\n\tprotected void contribute(URIConverter uriConverter, ProgressMonitor progressMonitor) {\t\n\t\turiConverter.getURIHandlers().add(0, new URIHandlerImpl() {\n\n\t\t\t@Override\n\t\t\tpublic boolean canHandle(URI uri) {\n\t\t\t\treturn uri != null &amp;&amp; Util.CLASSPATH_SCHEME.equals(uri.scheme());\n\t\t\t}\n\n\t\t\t@Override\n\t\t\tpublic InputStream createInputStream(URI uri, Map&lt;?, ?&gt; options) throws IOException {\n\t\t\t\treturn DefaultConverter.INSTANCE.toInputStream(uri);\n\t\t\t}\n\t\t\t\n\t\t});\n\t\t\n\t}\n\t\n}\n and add it to module-info.java provides CapabilityFactory. Applications Services Service capabilities explained above a used by Graph and Function Flow for loading node processors and connection processors for a specific requirement using NodeProcessorFactory and ConnectionProcessorFactory respectively. For example, code generation, execution, simulation. Solutions for architectures One of future application of the capability framework is creation a list of solution alternatives for an architecture/pattern. For example, there might be multiple RAG embodiments with different key types, key extractors, stores, &hellip; Some of &ldquo;design dimensions&rdquo; are listed below: Key type: Bag of words. Multiple options - just words, words with frequency, tokenized words, word stems. Embedding vector - different embedding models, different dimensions. Store - multiple stores for multiple key types. Multiple indexing and retrieval methods. Chunk size, chunk overlap, chunking algorithm. Generator - multiple models and prompts As you can see a number of potential combinations can easily go into thousands or even be infinite. Reactive approach with filtering and sorting may be helpful in selecting a solution which is a good fit for a particular use case - number and type of data sources etc. For example, if the total size of data is under a few gigabytes an in-memory store may be a better choice than, say, an external (vector) database. Also an old good bag of words might be better than embeddings. E.g. it might be cheaper. Solution alternatives may include temporal aspect or monetary aspects. For example, version X of Y is available at time Z. Z might be absolute or relative. Say, Z days after project kick-off or license fee payment. Identified solutions meeting requirements can have different quality attributes - costs (to build, to run), timeline, etc. These quality attributes can be used for solution analysis. E.g. one solution can be selected as a transition architecture and another as the target architecture. Backward chaining Family reasoning demonstrates application of the capability framework as a backward chaining engine. Family relationships such as grandfather and cousin are constructed by requiring and combining relationships such as child and sibling. Stream processing This possible application is similar to backward reasoning. Imagine an algorithmic trading strategy which uses several technical indicators, such as moving averages, to make trading decisions. Such a strategy would submit requirements for technical indicators which would include symbol, indicator configuration, time frame size. Technical indicators in turn would submit a requirement for raw trading data. A technical indicator such as moving average would start publishing its events once it receives enough trading data frames to compute its average. A trading engine would submit a requirement for strategies. A strategy factory may produce multiple strategies with different configurations. The trading engine would perform &ldquo;paper&rdquo; trades, select well-performing strategies and discard ones which perform poorly. This can be an ongoing process - if a strategy deteriorates then it is discarded and a new strategy is requested from strategy publishers - this process can be infinite. AI model training/fine-tuning This application is similar to stream processing and may be combined with backward reasoning. Let&rsquo;s say we want to train a model to answer questions about family relationships for a specific family. For example, &ldquo;Who is Alan&rsquo;s great grandmother?&rdquo; A single relationship in the model can be expressed in multiple ways in natural language. And multiple relationships can be expressed in a single sentence. For example: Elias is a person Elias is a man Elias is a male Elias is a parent of Fiona Fiona is a child of Elias Elias is a father of Fiona Fiona is a daughter of Elias Paul and Isa are parents of Lea and Elias &hellip; So, on top of a model there might be a collection of text generators. Output of those generators can be fed to a model: Supervised - question and answer &ldquo;How many sisters does Bryan have?&rdquo; - &ldquo;Two&rdquo; &ldquo;Who are Bryan&rsquo;s sisters?&rdquo; - &ldquo;Clara and Fiona&rdquo; Unsupervised - factual statements A similar approach can be applied to other models - customer/accounts, organization or architecture model, etc. For example, from the Internet Banking System we can generate something like &ldquo;Accounts Summary Controller uses Mainframe Banking System Facade to make API calls to the Mainframe Banking System over XML/HTTPS&rdquo;. &ldquo;make API calls&rdquo; may also be generated as &ldquo;connect&rdquo; or &ldquo;make requests&rdquo;. In a similar fashion a number of questions/answers can be generated. Javadoc ↩ See Eclipse Modeling Framework (EMF) - Tutorial and EMF Eclipse Modeling Framework book for more details. ↩ See EMF Ecore chapter in Beyond Diagrams book for a high-level overview of EMF Ecore. ↩"},"nsd-cli/nsd/shell/index.html":{"path":"CLI/nsd/shell","action-uuid":"b22821ff-759c-4eb7-80ef-678d429c0030","title":"shell","content":"Usage: nsd shell [-hV]\r\nStarts an interactive shell\r\nor executes commands from input\r\nfiles or URL's\r\n  -h, --help      Show this help message and exit.\r\n  -V, --version   Print version information and exit."},"core/graph/index.html":{"path":"Core/Graph","action-uuid":"82915e02-62f2-4459-9752-d463d7c14b10","title":"Graph","content":"Nasdanika Graph module provides classes for visiting and processing graphs with two types of relationships between graph elements: Containment - one element is contained by another Connection - one element (node) connecting to another node via a connection. On the diagram below containment relationships are shown in bold black and connections in blue Examples of such graphs: A file system with directories containing files and other directories. Connections may take multiple forms such as symbolic links or files, e.g. HTML files, referencing other files. Organizational structure with a hierarchy of organizational units and connections between them. For example, one unit may pass work product to another unit, or a unit may provide services to other units. Country, state, county, city, street, house, people living in that house; family relationships between people and ownership relationships between people and houses. Diagrams, such as Drawio diagrams with a diagram file (resource) containing a Document which contains pages, pages containing layers, and layers containing nodes and connections. Nodes may be nested. Nasdanika Drawio is a module for working with Drawio diagrams. It is built on top of this module. Processes/(work)flows - processes consist of activities and nested processes. Activities are connected by transitions. Distributed systems, such as cloud solutions - availability zones, data centers, clusters, nodes, pods, containers, processes inside containers. All of them communicating to each other via network connections. Work hierarchy and dependencies - in issue trackers issues may be organized into a hierarchy (e.g. Initiative, Epic, Story, Sub-Task in Jira) and have different types of dependencies. In Java a jar contains packages containing sub-packages and classes. Classes contain fields and methods. Fields reference their types, methods call methods of other classes, &hellip; EMF Ecore models contain packages. Packages contain sub-packages and classifiers including classes. Classes contain references to other classes. References may be configured as containment (composition) or non-containment. Sources Javadoc Executable (computational) graphs &amp; diagrams Medium Story Graph API Processing Dispatching Processors and processor factories Reflection ReflectiveProcessorFactoryProvider Capability Wiring Graph API The graph API has 3 interfaces: Element - super-interface for Connection and Node below. Elements may contain other elements. Containment is implemented with &lt;T&gt; T accept(BiFunction&lt;? super Element, Map&lt;? extends Element, T&gt;, T&gt; visitor), which can be thought of as a hierarchical bottom-up reduce - the visitor function is invoked with an element being visited as its first argument and a map of element&rsquo;s children to results returned by the visitor as the second argument. For leaf elements the second argument may be either an empty map or null. Depending on the map type used by implementations they may also need to implement equals() and hashCode(). Node extends Element and may have incoming and outgoing connections. Connection extends Element and has source and target nodes. Processing Graph processing means associating some behavior with graph elements. That behavior (code execution) may modify the graph or perform other actions. Examples of graph processing: Generate code (HTML site) from a diagram. Demos: Internet Banking System Sample Family Living beings Update a diagram with information from external source. For example, there might be a diagram of a (software) system. Diagram elements can be updated as follows: During development - colors may reflect completion status. Say, in progress elements in blue, completed elements in green, elements with issues in red or amber. In production - color elements based on their monitoring status. Offline - grey, good - green, overloaded - amber, broken - red. The above two examples may be combined - a documentation site might be generated from a system diagram. The diagram may be updated with statuses as part of the generation process and embedded to the home page. A click on a diagram element would navigate to an element documentation page, which may contain detailed status information pulled from tracking/monitoring systems during generation. Dispatching One form of graph processing is dispatching of graph elements to Java methods annotated with Handler annotation. The annotation takes a Spring boolean expression. Graph elements are passed to methods for which the expression is blank or evaluates to true. Below is a code snippet from AliceBobHandlers class: @Handler(&quot;getProperty('my-property') == 'xyz'&quot;)\npublic String bob(Node bob) {\n\tSystem.out.println(bob.getLabel());\n\treturn bob.getLabel();\n}\n Below is a test method from TestDrawio.testDispatch() test method which dispatches to the above handler method: Document document = Document.load(getClass().getResource(&quot;alice-bob.drawio&quot;));\n\t\t\nAliceBobHandlers aliceBobHandlers = new AliceBobHandlers();\t\t\nObject result = document.dispatch(aliceBobHandlers);\nSystem.out.println(result);\n Dispatching is suitable for processing where processing logic for different graph elements does not need to access processing logic of other elements. An example of such logic would be updating diagram elements based on statuses retrieved from tracking/monitoring systems - each element is updated individually. Processors and processor factories Processor package provides means for creating graph element processors and wiring them together so they can interact. One area of where such functionality would be needed is executable diagrams. For example, a flow processor/simulator. Activity processors would need to pass control to connected activities via connection processors. Activity processors may also need to access facilities of their parent processors. The below diagram shows interaction of two nodes via a connection. Connections are bi-directional - source processor may interact with the target processor and vice versa. Some connections may be &ldquo;pass-through&rdquo; - just passing interactions without doing any processing. A pass-through connection is depicted below. Graph element processors are wired together with handlers and endpoints: A handler is a java object provided by a processor for receiving interactions from other processors via endpoints. An endpoint is a java object provided to a processor for interacting with other processors. An endpoint may be of the same type as a handler or a handler may be used as an endpoint. This might be the case if processing is performed sequentially in a single JVM. Alternatively, an endpoint may be of different type than the handler it passes interactions to. For example: Endpoint methods may return Futures or CompletionStages of counterpart handler methods - when an endpoint method is invoked it would invoke handler&rsquo;s method asynchronously. Endpoint methods may take different parameters. E.g. an endpoint method can take InputStream, save it to some storage and pass a URL to the handler method. Processors can also interact by looking up other processors in the processor registry. Endpoints are created by implementations Processors are created in two steps: Processor configs are created by subclasses of ProcessorConfigFactory, e.g. NopEndpointProcessorConfigFactory Processors are created from configs by subclasses of ProcessorFactory overriding createProcessor() method. Client code creates processors by calling createProcessors() method. This method return a registry - Map&lt;Element,ProcessorInfo&lt;P&gt;&gt;. The registry allows the client code to interact with the handler/endpoint/processor wiring created from the graph. TestDrawio.testProcessor() method provides an example of using an anonymous implementation of NopEndpointProcessorFactory for graph processing. Reflection A good deal of processor creation logic is selection of a processor to create for a given graph element in a given situation/context and then &ldquo;wiring&rdquo; configuration to the processor. There are two processor factory classes and ReflectiveProcessorWirer class which make the selection/matching/wiring process easier. ReflectiveProcessorFactoryProvider ReflectiveProcessorFactoryProvider invokes methods annotated with Processor annotation to create processors. SyncProcessorFactory is an example of reflective processor factory. Below is one of factory methods: @Processor(\n\ttype = NodeAdapter.class,\n\tvalue = &quot;get() instanceof T(org.nasdanika.models.functionflow.FunctionFlow)&quot;)\npublic Object createFunctionFlowProcessor(\n\tNodeProcessorConfig&lt;?,?&gt; config, \n\tboolean parallel, \n\tBiConsumer&lt;Element,BiConsumer&lt;ProcessorInfo&lt;Object&gt;,ProgressMonitor&gt;&gt; infoProvider,\n\tFunction&lt;ProgressMonitor, Object&gt; next,\t\t\n\tProgressMonitor progressMonitor) {\t\n\treturn new FunctionFlowProcessor();\n}\n Capability CapabilityProcessorFactory uses the Nasdanika Capability Framework to delegate processor creation to capability factories. ReflectiveProcessorServiceFactory provides such a capability by collecting reflective targets from capability providers and then using ReflectiveProcessorFactoryProvider mentioned above. This approach provides high level of decoupling between code which executes the graph and code which creates processors. FunctionFlowTests executes a graph loaded from a Drawio diagram. It constructs a processor factory as shown below: CapabilityLoader capabilityLoader = new CapabilityLoader();\t\t\nCapabilityProcessorFactory&lt;Object, BiFunction&lt;Object, ProgressMonitor, Object&gt;&gt; processorFactory = new CapabilityProcessorFactory&lt;Object, BiFunction&lt;Object, ProgressMonitor, Object&gt;&gt;(\n\t\tBiFunction.class, \n\t\tBiFunction.class, \n\t\tBiFunction.class, \n\t\tnull, \n\t\tcapabilityLoader); \n SyncProcessorFactory mentioned above is contributed by SyncCapabilityFactory: @Override\npublic boolean canHandle(Object requirement) {\n\tif (requirement instanceof ReflectiveProcessorFactoryProviderTargetRequirement) {\n\t\tReflectiveProcessorFactoryProviderTargetRequirement&lt;?,?&gt; targetRequirement = (ReflectiveProcessorFactoryProviderTargetRequirement&lt;?,?&gt;) requirement;\n\t\tif (targetRequirement.processorType() == BiFunction.class) { // To account for generic parameters create a non-generic sub-interface binding those parameters.\n\t\t\tProcessorRequirement&lt;?, ?&gt; processorRequiremment = targetRequirement.processorRequirement();\n\t\t\tif (processorRequiremment.handlerType() == BiFunction.class &amp;&amp; processorRequiremment.endpointType() == BiFunction.class) {\n\t\t\t\treturn processorRequiremment.requirement() == null; // Customize if needed\n\t\t\t}\n\t\t}\n\t}\n\treturn false;\n}\n\n@Override\npublic CompletionStage&lt;Iterable&lt;CapabilityProvider&lt;Object&gt;&gt;&gt; create(\n\tReflectiveProcessorFactoryProviderTargetRequirement&lt;Object, BiFunction&lt;Object, ProgressMonitor, Object&gt;&gt; requirement,\n\tBiFunction&lt;Object, ProgressMonitor, CompletionStage&lt;Iterable&lt;CapabilityProvider&lt;Object&gt;&gt;&gt;&gt; resolver,\n\tProgressMonitor progressMonitor) {\t\t\n\treturn CompletableFuture.completedStage(Collections.singleton(CapabilityProvider.of(new SyncProcessorFactory())));\t\n}\n canHandle() returns true if the factory can handle the requriement passed to it. create() creates a new instance of SyncProcessorFactory. Note, that create() may request other capabilities. Say, an instsance of OpenAIClient to generate code using chat completions. SyncCapabilityFactory is registered in module-info.java: exports org.nasdanika.models.functionflow.processors.targets.java.sync;\nopens org.nasdanika.models.functionflow.processors.targets.java.sync to org.nasdanika.common; // For loading resources\n\nprovides CapabilityFactory with SyncCapabilityFactory;\n Note that a package containing reflective factories and processors shall be opened to org.nasdanika.common for reflection to work. Wiring Processors created by the above factories are introspected for the following annotations: All processors: ChildProcessor - field a method to inject processor or config of element&rsquo;s child matching the selector expression. ChildProcessors - field or method to inject a map of children elements to their processor info. ParentProcessor - field or method to inject processor or config of element&rsquo;s parent. ProcessorElement - field or method to inject the graph element. Registry - field or method to inject the registry - a map of graph elements to their info. RegistryEntry - field or method to inject a matching registry entry. Node processors: IncomingEndpoint - field or method to inject a matching incoming endpoint. IncomingEndpoints - field or method to inject a map of incoming connections to their endpoints completion stages. IncomingHandler - field or method to obtain a handler for an incoming connection. IncomingHandlerConsumers - field or method to inject a map of incoming connections to java.util.function.Consumers of handlers. OutgoingEndpoint - field or method to inject a matching outgoing endpoint. OutgoingEndpoints - field or method to inject a map of outgoing connections to their endpoints completion stages. OutgoingHandler - field or method to obtain a handler for an outgoing connection. OutgoingHandlerConsumers - field or method to inject a map of outgoing connections to consumers of handlers. Connection processors: SourceEndpoint - field or method into which a connection source endpoint is injected. Source endpoint allows the connection processor to interact with the connection source handler. SourceHandler - field or method from which the connection source handler is obtained. TargetEndpoint - field or method into which a connection target endpoint is injected. Target endpoint allows the connection processor to interact with the connection target handler. TargetHandler - Field or method from which the connection target handler is obtained. Element/Node/Connection configuration is declaratively &ldquo;wired&rdquo; to processors&rsquo; fields and methods. Configuration can also be wired imperatively. Declarative and imperative styles can be used together. Below is an example of using @OutgoingEndpoint annotation by StartProcessor: public class StartProcessor implements BiFunction&lt;Object, ProgressMonitor, Object&gt; {\n\n\tprotected Collection&lt;BiFunction&lt;Object, ProgressMonitor, Object&gt;&gt; outgoingEndpoints = Collections.synchronizedCollection(new ArrayList&lt;&gt;());\t\n\t\n\t@Override\n\tpublic Object apply(Object arg, ProgressMonitor progressMonitor) {\n\t\tMap&lt;BiFunction&lt;Object, ProgressMonitor, Object&gt;, Object&gt; outgoingEndpointsResults = new LinkedHashMap&lt;&gt;();\n\t\tfor (BiFunction&lt;Object, ProgressMonitor, Object&gt; e: outgoingEndpoints) {\n\t\t\toutgoingEndpointsResults.put(e, e.apply(arg, progressMonitor));\n\t\t}\n\t\treturn outgoingEndpointsResults;\n\t}\n\t\n\t@OutgoingEndpoint\n\tpublic void addOutgoingEndpoint(BiFunction&lt;Object, ProgressMonitor, Object&gt; endpoint) {\n\t\toutgoingEndpoints.add(endpoint);\n\t}\n\n}``` Root A B A1 A2 B1 Node Processor Node Processor source -&gt; target processor target -&gt; source processor Node Processor Node Processor"},"nsd-cli/nsd/drawio/html-app/site/index.html":{"path":"CLI/nsd/drawio/html-app/site","action-uuid":"f36deb05-976f-4ab5-9b69-793389c06ef9","title":"site","content":"Version: org.nasdanika.cli \r\nUsage: nsd drawio html-app site [-hlV] [--progress-console] [--progress-data]\r\n                                [--progress-json] [-b=&lt;baseDir&gt;]\r\n                                [-F=&lt;pageTemplateFile&gt;] [-m=&lt;domian&gt;]\r\n                                [-P=&lt;parallelism&gt;]\r\n                                [--progress-output=&lt;progressOutput&gt;]\r\n                                [-r=&lt;pageErrors&gt;] [-t=&lt;timeout&gt;]\r\n                                [-T=&lt;pageTemplate&gt;] [-w=&lt;workDir&gt;]\r\n                                [-c=&lt;String=String&gt;]... [-C=URL]...\r\n                                [-M=&lt;String=String&gt;]... [-e[=&lt;excludes&gt;...]]...\r\n                                [-i[=&lt;includes&gt;...]]... &lt;output&gt;\r\nGenerates HTML site\r\n      &lt;output&gt;               Output directory relative to the base directory\r\n  -b, --base-dir=&lt;baseDir&gt;   Base directory\r\n  -c, --context-entry=&lt;String=String&gt;\r\n                             Context entries.\r\n                             Shadow entries in contexts and mounts.\r\n  -C, --context=URL          Context resource URL relative to the current\r\n                               directory. YAML, JSON, or properties. In\r\n                               properties dots are treated as key path\r\n                               separators. Type is inferred from the content\r\n                               type header, if it is present, or extension.\r\n                               Contexts are composed in the order of\r\n                               definition, later context entries shadowing the\r\n                               former\r\n  -e, --exclude[=&lt;excludes&gt;...]\r\n                             Output directory clean excludes\r\n                             Ant pattern\r\n  -F, --page-template-file=&lt;pageTemplateFile&gt;\r\n                             Page template file relative\r\n                             to the current directory\r\n  -h, --help                 Show this help message and exit.\r\n  -i, --include[=&lt;includes&gt;...]\r\n                             Output directory clean includes\r\n                             Ant pattern\r\n  -l, --[no-]clean           Clean working directory\r\n                             defaults to true\r\n  -m, --domain=&lt;domian&gt;      Sitemap domain\r\n  -M, --context-mount=&lt;String=String&gt;\r\n                             MappingContext resource URL relative to the\r\n                               current directory. YAML, JSON, or properties. In\r\n                               properties dots are treated as key path\r\n                               separators. Type is inferred from the content\r\n                               type header, if it is present, or extension.\r\n                               Mounts shadow context entries.\r\n  -P, --parallelism=&lt;parallelism&gt;\r\n                             If the value greater than one then an executor\r\n                               service is created and injected into the context\r\n                               to allow concurrent execution.\r\n      --progress-console     Output progress to console\r\n      --progress-data        Output progress data\r\n      --progress-json        Output progress in JSON\r\n      --progress-output=&lt;progressOutput&gt;\r\n                             Output file for progress monitor\r\n  -r, --errors=&lt;pageErrors&gt;  Expected number of page errors\r\n                             -1 for any (not fail on errors)\r\n                             default is 0\r\n  -t, --timeout=&lt;timeout&gt;    If parallelism is greater than one this option\r\n                               specifies timout in seconds awaiting completion\r\n                               of execution. Default value is 60.\r\n  -T, --page-template=&lt;pageTemplate&gt;\r\n                             Page template URI relative\r\n                             to the current directory\r\n  -V, --version              Print version information and exit.\r\n  -w, --work-dir=&lt;workDir&gt;   Working directory\r\nExit codes:\r\n  Non-negative number   Delegate result\r\n  -1                    Unhandled exception during execution\r\n  -2                    Invalid input\r\n  -3                    Diagnostic failed\r\n  -4                    Execution failed or was cancelled, successful rollback\r\n  -5                    Execution failed or was cancelled, rollback failed\r\n  -6                    Executor service termination timed out"},"nsd-cli/nsd/model/html-app/save/index.html":{"path":"CLI/nsd/model/html-app/save","action-uuid":"5250a36e-4a92-4c19-b0c6-a32aa7714876","title":"save","content":"Version: org.nasdanika.cli \r\nUsage: nsd model html-app save [-hV] [--progress-console] [--progress-data]\r\n                               [--progress-json]\r\n                               [--progress-output=&lt;progressOutput&gt;]\r\n                               [--content-type-resource-factory=&lt;String=Class&gt;].\r\n                               ..\r\n                               [--extension-resource-factory=&lt;String=Class&gt;]...\r\n                               [--protocol-resource-factory=&lt;String=Class&gt;]...\r\n                               &lt;output&gt;\r\nSaves model to a file\r\n      &lt;output&gt;             Output file\r\n      --content-type-resource-factory=&lt;String=Class&gt;\r\n                           Maps content type to resource factory class\r\n      --extension-resource-factory=&lt;String=Class&gt;\r\n                           Maps extension to resource factory class\r\n  -h, --help               Show this help message and exit.\r\n      --progress-console   Output progress to console\r\n      --progress-data      Output progress data\r\n      --progress-json      Output progress in JSON\r\n      --progress-output=&lt;progressOutput&gt;\r\n                           Output file for progress monitor\r\n      --protocol-resource-factory=&lt;String=Class&gt;\r\n                           Maps protocol to resource factory class\r\n  -V, --version            Print version information and exit."},"nsd-cli/nsd/rules/list/index.html":{"path":"CLI/nsd/rules/list","action-uuid":"b9ded513-28f7-48d9-b498-2a32cc61c025","title":"list","content":"Usage: nsd rules list [-hrV] [--progress-console] [--progress-data]\r\n                      [--progress-json] [-o=&lt;output&gt;]\r\n                      [--progress-output=&lt;progressOutput&gt;] [--exclude-rule\r\n                      [=&lt;ruleExcludes&gt;...]]... [--exclude-rule-set\r\n                      [=&lt;ruleSetExcludes&gt;...]]... [--include-rule\r\n                      [=&lt;ruleIncludes&gt;...]]... [--include-rule-set\r\n                      [=&lt;ruleSetIncludes&gt;...]]...\r\nLists available rule sets and rules\r\n      --exclude-rule[=&lt;ruleExcludes&gt;...]\r\n                           ID's of rules to exclude\r\n      --exclude-rule-set[=&lt;ruleSetExcludes&gt;...]\r\n                           ID's of rule sets to exclude\r\n  -h, --help               Show this help message and exit.\r\n      --include-rule[=&lt;ruleIncludes&gt;...]\r\n                           ID's of rules to include\r\n      --include-rule-set[=&lt;ruleSetIncludes&gt;...]\r\n                           ID's of rule sets to include\r\n  -o, --output=&lt;output&gt;    Output file\r\n      --progress-console   Output progress to console\r\n      --progress-data      Output progress data\r\n      --progress-json      Output progress in JSON\r\n      --progress-output=&lt;progressOutput&gt;\r\n                           Output file for progress monitor\r\n  -r, --[no-]rules         Output rules\r\n  -V, --version            Print version information and exit."},"nsd-cli/nsd/model/index.html":{"path":"CLI/nsd/model","action-uuid":"1738772b-c431-45a6-b99a-f553d2b8b6f4","title":"model","content":"Version: org.nasdanika.cli \r\nUsage: nsd model [-fhV] [--content-type-resource-factory=&lt;String=Class&gt;]...\r\n                 [--extension-resource-factory=&lt;String=Class&gt;]...\r\n                 [--protocol-resource-factory=&lt;String=Class&gt;]... &lt;uri&gt; [COMMAND]\r\nLoads EObject from a URI or file\r\n      &lt;uri&gt;       EObject URI or file path, resolved relative\r\n                  to the current directory\r\n      --content-type-resource-factory=&lt;String=Class&gt;\r\n                  Maps content type to resource factory class\r\n      --extension-resource-factory=&lt;String=Class&gt;\r\n                  Maps extension to resource factory class\r\n  -f, --file      URI parameter is a file path\r\n  -h, --help      Show this help message and exit.\r\n      --protocol-resource-factory=&lt;String=Class&gt;\r\n                  Maps protocol to resource factory class\r\n  -V, --version   Print version information and exit.\r\nCommands:\r\n  ecore-html-app  Generates Ecore model documentation html app model\r\n  html-app        Generates html application model from a drawio document\r\n  save            Saves model to a file"},"nsd-cli/nsd/launcher/index.html":{"path":"CLI/nsd/launcher","action-uuid":"5acebd85-9d29-420c-8e46-2159e39d4c43","title":"launcher","content":"Version: org.nasdanika.cli \r\nUsage: nsd launcher [-hstvV] [-a=&lt;args&gt;] [-b=&lt;base&gt;] [-c=&lt;className&gt;]\r\n                    [-C=&lt;classPathModules&gt;] [-f=&lt;optionsFile&gt;]\r\n                    [-j=&lt;javaCommand&gt;] [-m=&lt;moduleName&gt;] [-M=&lt;modulesFile&gt;]\r\n                    [-o=&lt;output&gt;] [-p=&lt;pathSeparator&gt;] [-P=&lt;prefix&gt;]\r\n                    [-r=&lt;rootModules&gt;] [&lt;repositories&gt;...]\r\nGenerates Java command line from directories of modules/jars\r\n      [&lt;repositories&gt;...]    Directories to scan for modules,\r\n                             defaults to lib\r\n  -a, --args=&lt;args&gt;          Arguments,\r\n                             defaults to %*\r\n  -b, --base=&lt;base&gt;          Base repositories directory\r\n  -c, --class=&lt;className&gt;    Application class,\r\n                             defaults to org.nasdanika.cli.Application\r\n  -C, --claspath-modules=&lt;classPathModules&gt;\r\n                             Comma-separated list of classpath modules\r\n  -f, --options-file=&lt;optionsFile&gt;\r\n                             File to output options to\r\n  -h, --help                 Show this help message and exit.\r\n  -j, --java=&lt;javaCommand&gt;   Java command,\r\n                             defaults to java\r\n  -m, --module=&lt;moduleName&gt;  Application module,\r\n                             defaults to org.nasdanika.cli\r\n  -M, --modules=&lt;modulesFile&gt;\r\n                             Modules to add to the module path\r\n  -o, --output=&lt;output&gt;      Output file\r\n  -p, --path-separator=&lt;pathSeparator&gt;\r\n                             Path separator,\r\n                             defaults to the system path separator\r\n  -P, --prefix=&lt;prefix&gt;      Module path prefix\r\n  -r, --root-modules=&lt;rootModules&gt;\r\n                             Comma-separated list of root modules\r\n                             Supports .* and .** patterns\r\n  -s, --absolute             Use absolute paths\r\n  -t, --options              Output only options\r\n  -v, --verbose              Output debug information\r\n  -V, --version              Print version information and exit."},"nsd-cli/nsd/rules/site/index.html":{"path":"CLI/nsd/rules/site","action-uuid":"06ad289e-49e7-4162-9ccb-25d174ba55da","title":"site","content":"Usage: nsd rules site [-fhlRV] [--progress-console] [--progress-data]\r\n                      [--progress-json] [-b=&lt;baseDir&gt;] [-m=&lt;domian&gt;]\r\n                      [-P=&lt;parallelism&gt;] [--progress-output=&lt;progressOutput&gt;]\r\n                      [-r=&lt;pageErrors&gt;] [--root-action-icon=&lt;rootActionIcon&gt;]\r\n                      [--root-action-location=&lt;rootActionLocation&gt;]\r\n                      [--root-action-text=&lt;rootActionText&gt;] [-t=&lt;timeout&gt;]\r\n                      [-T=&lt;pageTemplate&gt;] [-w=&lt;workDir&gt;]\r\n                      [-c=&lt;String=String&gt;]... [-C=URL]...\r\n                      [-M=&lt;String=String&gt;]... [-e[=&lt;excludes&gt;...]]... [-i\r\n                      [=&lt;includes&gt;...]]... &lt;model&gt; &lt;output&gt;\r\nGenerates rule set documentation site\r\n      &lt;model&gt;                Model URI, resolved relative\r\n                             to the current directory\r\n                             or looked up in registered rule sets\r\n                             if -R option is provided\r\n      &lt;output&gt;               Output directory\r\n  -b, --base-dir=&lt;baseDir&gt;   Base directory\r\n  -c, --context-entry=&lt;String=String&gt;\r\n                             Context entries.\r\n                             Shadow entries in contexts and mounts.\r\n  -C, --context=URL          Context resource URL relative to the current\r\n                               directory. YAML, JSON, or properties. In\r\n                               properties dots are treated as key path\r\n                               separators. Type is inferred from the content\r\n                               type header, if it is present, or extension.\r\n                               Contexts are composed in the order of\r\n                               definition, later context entries shadowing the\r\n                               former\r\n  -e, --exclude[=&lt;excludes&gt;...]\r\n                             Output directory clean excludes\r\n                             Ant pattern\r\n  -f, --file                 Mdel parameter is a file path\r\n  -h, --help                 Show this help message and exit.\r\n  -i, --include[=&lt;includes&gt;...]\r\n                             Output directory clean includes\r\n                             Ant pattern\r\n  -l, --[no-]clean           Clean working directory\r\n                             defaults to true\r\n  -m, --domain=&lt;domian&gt;      Sitemap domain\r\n  -M, --context-mount=&lt;String=String&gt;\r\n                             MappingContext resource URL relative to the\r\n                               current directory. YAML, JSON, or properties. In\r\n                               properties dots are treated as key path\r\n                               separators. Type is inferred from the content\r\n                               type header, if it is present, or extension.\r\n                               Mounts shadow context entries.\r\n  -P, --parallelism=&lt;parallelism&gt;\r\n                             If the value greater than one then an executor\r\n                               service is created and injected into the context\r\n                               to allow concurrent execution.\r\n      --progress-console     Output progress to console\r\n      --progress-data        Output progress data\r\n      --progress-json        Output progress in JSON\r\n      --progress-output=&lt;progressOutput&gt;\r\n                             Output file for progress monitor\r\n  -r, --errors=&lt;pageErrors&gt;  Expected number of page errors\r\n                             -1 for any (not fail on errors)\r\n                             default is 0\r\n  -R, --registered           Use registered rule set\r\n                             with provided URI\r\n      --root-action-icon=&lt;rootActionIcon&gt;\r\n                             Root action icon\r\n      --root-action-location=&lt;rootActionLocation&gt;\r\n                             Root action location\r\n      --root-action-text=&lt;rootActionText&gt;\r\n                             Root action text\r\n  -t, --timeout=&lt;timeout&gt;    If parallelism is greater than one this option\r\n                               specifies timout in seconds awaiting completion\r\n                               of execution. Default value is 60.\r\n  -T, --page-template=&lt;pageTemplate&gt;\r\n                             Page template URI relative\r\n                             to the current directory\r\n  -V, --version              Print version information and exit.\r\n  -w, --work-dir=&lt;workDir&gt;   Working directory\r\nExit codes:\r\n  Non-negative number   Delegate result\r\n  -1                    Unhandled exception during execution\r\n  -2                    Invalid input\r\n  -3                    Diagnostic failed\r\n  -4                    Execution failed or was cancelled, successful rollback\r\n  -5                    Execution failed or was cancelled, rollback failed\r\n  -6                    Executor service termination timed out"},"core/persistence/index.html":{"path":"Core/Persistence","action-uuid":"cd8f336a-422a-4a55-a98d-d6cf8895529a","title":"Persistence","content":"Sources Javadoc"},"html/emf/index.html":{"path":"HTML/EMF","action-uuid":"6ae6ec40-e48a-4b55-80f1-2dcffd2315ea","title":"EMF","content":"Sources Javadoc"},"nsd-cli/nsd/drawio/index.html":{"path":"CLI/nsd/drawio","action-uuid":"2d190813-2794-4ca1-93dd-d7892b4dd099","title":"drawio","content":"Version: org.nasdanika.cli \r\nUsage: nsd drawio [-fhV] [-c=&lt;String=String&gt;]... [-C=URL]...\r\n                  [-M=&lt;String=String&gt;]... &lt;document&gt; [COMMAND]\r\nLoads Drawio document from a URI or file\r\n      &lt;document&gt;      Document URI or file path, resolved relative\r\n                      to the current directory\r\n  -c, --context-entry=&lt;String=String&gt;\r\n                      Context entries.\r\n                      Shadow entries in contexts and mounts.\r\n  -C, --context=URL   Context resource URL relative to the current directory.\r\n                        YAML, JSON, or properties. In properties dots are\r\n                        treated as key path separators. Type is inferred from\r\n                        the content type header, if it is present, or\r\n                        extension. Contexts are composed in the order of\r\n                        definition, later context entries shadowing the former\r\n  -f, --file          Document parameter is a file path\r\n  -h, --help          Show this help message and exit.\r\n  -M, --context-mount=&lt;String=String&gt;\r\n                      MappingContext resource URL relative to the current\r\n                        directory. YAML, JSON, or properties. In properties\r\n                        dots are treated as key path separators. Type is\r\n                        inferred from the content type header, if it is\r\n                        present, or extension. Mounts shadow context entries.\r\n  -V, --version       Print version information and exit.\r\nCommands:\r\n  html-app  Generates html application model from a drawio document"},"core/cli/index.html":{"path":"Core/CLI","action-uuid":"c6c70e82-85fe-4a4d-a5bd-626aee3e52f0","title":"CLI","content":"Classes in this module allow to declaratively construct command line interfaces. It uses picocli to execute commands and capability framework to collect sub-commands and mix-ins. This way command line interfaces can be constructed top-down (default picocli functionality) - parent commands explicitly define sub-commands, and bottom-up - sub-commands are added to parent commands by the framework. Top-down construction can be done using out-the-box picocli capabilities - programmatic add and annotations. Both top-down and bottom-up construction can be done using the capability framework which allows sub-commands/mix-ins to request capabilities they need and add themselves to parent commands only if all requirements are met. The module provides a capability to build polymorphic CLI&rsquo;s - sub-commands and mix-ins may override other sub-commands and mix-ins with the same name. This is similar to method overriding in Object-Oriented languages like Java. For example, a base CLI package may have a basic implementation of some sub-command. A derived package would add dependencies with advanced sub-commands to pom.xml. These sub-commands would replace (override) basic sub-commands during construction of the command hierarchy. Sources Javadoc Medium stories: Beyond PicoCLI Declarative Command Pipelines Contributing sub-commands @SubCommands annotation @ParentCommands annotation Programmatic match Contributing mix-ins @MixIns annotation @ParentCommands annotation Programmatic match Overriding Extended documentation Commands Mix-ins Shell Closing commands Building distributions Downloading dependencies Generating launcher scripts Assembly Contributing sub-commands In addition to the picocli way of adding sub-commands programmatically and using @Command annotation subcommands element this module provides a few more ways to contribute sub-commands which are explained below. In all cases create a sub-class of SubCommandCapabilityFactory and implement/override the following methods: getCommandType - used for declarative matching createCommand for imperative (programmatic) matching doCreateCommand: Declarative - in combination with @SubCommands or @Parent Imperative - override match() as well. Add to module-info.java: provides org.nasdanika.capability.CapabilityFactory with &lt;factory class&gt; opens &lt;sub-command package name&gt; to info.picocli, org.nasdanika.html.model.app.gen.cli; Opening to org.nasdanika.html.model.app.gen.cli is needed if you want to generate extended documentation (see below). @SubCommands annotation This one is similar to @Command.subcommands - the parent command declares types of sub-commands. However: Sub-commands are collected using the capability framework from SubCommandCapabilityFactory&rsquo;s. Sub-commands types listed in the annotation are base types - classes or interfaces - not necessarily concrete implementation types. E.g. you may have HelpCommand interface or base class and all commands implementing/extending this class will be added to the parent command. If there are two commands with the same name one of them might override the other as explained below. @ParentCommands annotation In this case the sub-command or mix-in class are annotated with @ParentCommands annotation listing types of parents. The sub-command/mix-in will be added to all commands in the hierarchy which are instances of the specified parent types - exact class, interface implementation, or sub-class, or implement Adaptable and return non-null value from adaptTo(Class) method. This allows to create declarative command pipelines as explained in the Declarative Command Pipelines Medium story. Programmatic match The above two ways of matching parent commands and sub-commands are handled by the SubCommandCapabilityFactory.match() method. You may override this method or createCommand() method to programmatically match parent path and decide whether to contribute a sub-command or not. Contributing mix-ins Similar to sub-commands, mix-ins can be contributed top-down and bottom-up - declaratively using annotations and programmatically. In all cased create s sub-class of MixInCapabilityFactory, implement/override: getMixInType() - for declarative matching getName() createMixIn() for imperative matching, or doCreateMixIn() Declarative - in combination with @MixIns or @Parent Imperative - override match() as well. Add to module-info.java: provides org.nasdanika.capability.CapabilityFactory with &lt;factory class&gt; opens &lt;mix-in package name&gt; to info.picocli; @MixIns annotation Mix-ins are collected using the capability framework from MixInCapabilityFactory&rsquo;s. Mix-in types listed in the annotation are base types - classes or interfaces - not necessarily concrete implementation types. @ParentCommands annotation See &ldquo;@ParentCommands annotation&rdquo; sub-section in &ldquo;Contributing sub-commands&rdquo; section above. Programmatic match The above two ways of matching parent commands and sub-commands/mix-ins are handled by the MixInCapabilityFactory.match() method. You may override this method or createMixIn() method to programmatically match parent path and decide whether to contribute a mix-in or not. Overriding A command/mix-in overrides another command/mix-in if: It is a sub-class of that command/mix-in It implements Overrider interface and returns true from overrides(Object other) method. It is annotated with @Overrides and the other command is an instance of one of the value classes. Extended documentation You may annotate commands with @Description to provide additional information in generated HTML site. Commands The CLI module provides several base command classes: CommandBase - base class with standard help mix-in CommandGroup - base class for commands which don&rsquo;t have own functionality, only sub-commands ContextCommand - command with options to configure Context DelegatingCommand - options to configure Context and ProgressMonitor and delegate execution to SupplierFactory HelpCommand - outputs usage for the command hierarchy in text, html, action model, or generates a documentation site Mix-ins The module also provides several mix-ins: ContextMixIn - creates and configures Context ProgressMonitorMixIn - creates and configures ProgressMonitor ResourceSetMixIn - creates and configures ResourceSet using CapabilityLoader to add packages, resource and adapter factories, &hellip; Shell ShellCommand can be used to execute multiple commands in the same JVM. Closing commands Commands implementing org.nasdanika.common.Closeable, including CommandBase and its subclasses are closed recursively. This functionality can be used to release resources or save state to the permanent storage, e.g. file system. Building distributions A distribution is a collection of modules contributing commands and mix-ins plus launcher scripts for different operating systems. org.nasdanika.cli and org.nasdanika.launcher modules are examples of building distributions as part of a Maven build. Building a distribution involves the following steps: Downloading modules (dependencies) Generating launcher scripts Building an assembly (zip) All of the above steps are executed by mvn verify or mvn clean verify Downloading dependencies Dependencies can be downloaded using Maven dependency plug-in: &lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;\n\txmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;\n\txsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;\n\t\n\t...\n\n\t&lt;dependencies&gt;\n\t\t...\n\t&lt;/dependencies&gt;\n\n\t&lt;build&gt;\n\t\t&lt;plugins&gt;\n\t\t\t...\n\n\t\t\t&lt;plugin&gt;\n\t\t\t\t&lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;\n\t\t\t\t&lt;artifactId&gt;maven-dependency-plugin&lt;/artifactId&gt;\n\t\t\t\t&lt;version&gt;3.6.1&lt;/version&gt;\n\t\t\t\t&lt;executions&gt;\n\t\t\t\t\t&lt;execution&gt;\n\t\t\t\t\t\t&lt;id&gt;copy-dependencies&lt;/id&gt;\n\t\t\t\t\t\t&lt;phase&gt;prepare-package&lt;/phase&gt;\n\t\t\t\t\t\t&lt;goals&gt;\n\t\t\t\t\t\t\t&lt;goal&gt;copy-dependencies&lt;/goal&gt;\n\t\t\t\t\t\t&lt;/goals&gt;\n\t\t\t\t\t\t&lt;configuration&gt;\n\t\t\t\t\t\t\t&lt;outputDirectory&gt;\n\t\t\t\t\t\t\t\t${project.build.directory}/dist/lib\n\t\t\t\t\t\t\t&lt;/outputDirectory&gt;\n\t\t\t\t\t\t\t&lt;useRepositoryLayout&gt;true&lt;/useRepositoryLayout&gt;\t\t\t\t\t\t\t\n\t\t\t\t\t\t&lt;/configuration&gt;\n\t\t\t\t\t&lt;/execution&gt;\n\t\t\t\t&lt;/executions&gt;\n\t\t\t&lt;/plugin&gt;\n\t\t\t\n\t\t\t...\n\t&lt;/build&gt;\n\n\t...   \n&lt;/project&gt;\n Generating launcher scripts Launcher scripts can be generated using launcher command. The command can be issued manually from the command line. Alternatively, you can execute the launcher command from an integration test as shown below: public class BuildDistributionIT {\n\t\t\n\t@Test\n\tpublic void generateLauncher() throws IOException {\n\t\tfor (File tf: new File(&quot;target&quot;).listFiles()) {\n\t\t\tif (tf.getName().endsWith(&quot;.jar&quot;) &amp;&amp; !tf.getName().endsWith(&quot;-sources.jar&quot;) &amp;&amp; !tf.getName().endsWith(&quot;-javadoc.jar&quot;)) {\n\t\t\t\tFiles.copy(\n\t\t\t\t\t\ttf.toPath(), \n\t\t\t\t\t\tnew File(new File(&quot;target/dist/lib&quot;), tf.getName()).toPath(), \n\t\t\t\t\t\tStandardCopyOption.REPLACE_EXISTING);\t\t\n\t\t\t}\n\t\t}\t\t\n\t\t\n\t\tModuleLayer layer = Application.class.getModule().getLayer();\n\t\ttry (Writer writer = new FileWriter(new File(&quot;target/dist/modules&quot;))) {\n\t\t\tfor (String name: layer.modules().stream().map(Module::getName).sorted().toList()) {\n\t\t\t\twriter.write(name);\n\t\t\t\twriter.write(System.lineSeparator());\n\t\t\t};\n\t\t}\n\t\t\n\t\tCommandLine launcherCommandLine = new CommandLine(new LauncherCommand());\n\t\tlauncherCommandLine.execute(\n\t\t\t\t&quot;-b&quot;, &quot;target/dist&quot;, \n\t\t\t\t&quot;-M&quot;, &quot;target/dist/modules&quot;, \n\t\t\t\t&quot;-f&quot;, &quot;options&quot;,\n\t\t\t\t&quot;-j&quot;, &quot;@java&quot;,\n\t\t\t\t&quot;-o&quot;, &quot;nsd.bat&quot;);\n\t\t\n\t\tlauncherCommandLine.execute(\n\t\t\t\t&quot;-b&quot;, &quot;target/dist&quot;, \n\t\t\t\t&quot;-M&quot;, &quot;target/dist/modules&quot;, \n\t\t\t\t&quot;-j&quot;, &quot;#!/bin/bash\\n\\njava&quot;,\n\t\t\t\t&quot;-o&quot;, &quot;nsd&quot;,\n\t\t\t\t&quot;-p&quot;, &quot;:&quot;,\n\t\t\t\t&quot;-a&quot;, &quot;$@&quot;);\t\t\n\t\t\n\t}\n\n}\n If the Maven project which builds the distribution does not contribute its own code, then the for loop copying the jar file can be omitted. Assembly Create an assembly file dist.xml similar to the one below in src\\assembly directory: &lt;assembly xmlns=&quot;http://maven.apache.org/ASSEMBLY/2.0.0&quot;\n  xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;\n  xsi:schemaLocation=&quot;http://maven.apache.org/ASSEMBLY/2.0.0 http://maven.apache.org/xsd/assembly-2.0.0.xsd&quot;&gt;\n  &lt;id&gt;dist&lt;/id&gt;\n  &lt;formats&gt;\n    &lt;format&gt;tar.gz&lt;/format&gt;\n    &lt;format&gt;tar.bz2&lt;/format&gt;\n    &lt;format&gt;zip&lt;/format&gt;\n  &lt;/formats&gt;\n  &lt;fileSets&gt;\n    &lt;fileSet&gt;\n      &lt;directory&gt;${project.build.directory}/dist&lt;/directory&gt;\n      &lt;outputDirectory&gt;/&lt;/outputDirectory&gt;\n      &lt;useDefaultExcludes&gt;false&lt;/useDefaultExcludes&gt;\n    &lt;/fileSet&gt;\n  &lt;/fileSets&gt;\n&lt;/assembly&gt;\n then add the following plugin definition to pom.xml: &lt;plugin&gt;\n\t&lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt;\n\t&lt;version&gt;3.7.1&lt;/version&gt;\n\t&lt;configuration&gt;\n\t\t&lt;outputDirectory&gt;${project.build.directory}&lt;/outputDirectory&gt;\n\t\t&lt;formats&gt;zip&lt;/formats&gt;\n\t\t&lt;appendAssemblyId&gt;false&lt;/appendAssemblyId&gt;\n\t\t&lt;finalName&gt;nsd-cli-${project.version}&lt;/finalName&gt;\n\t\t&lt;descriptors&gt;\n\t\t\t&lt;descriptor&gt;src/assembly/dist.xml&lt;/descriptor&gt;\n\t\t&lt;/descriptors&gt;\n\t&lt;/configuration&gt;\n        &lt;executions&gt;\n          &lt;execution&gt;\n            &lt;id&gt;create-archive&lt;/id&gt;\n            &lt;phase&gt;verify&lt;/phase&gt;\n            &lt;goals&gt;\n              &lt;goal&gt;single&lt;/goal&gt;\n            &lt;/goals&gt;\n          &lt;/execution&gt;\n        &lt;/executions&gt;\n&lt;/plugin&gt;\t\t        \t\t\t\n Change the final name to your CLI name. E.g. my-company-cli."},"core/resources/index.html":{"path":"Core/Resources","action-uuid":"ef3efcb3-4ce1-4ee7-a735-81d06ab6a249","title":"Resources","content":"Sources Javadoc"},"practices/index.html":{"action-uuid":"5bbc7fe5-e3b4-4c8a-ac92-ae39b70d0d3e","title":"Practices","content":"Practices explain how to use Nasdanika products to achieve specific goals and explain why particular design choices wer made. The enterprise model provides deeper insight on the WHY in general. The practices are organized into an enterprise continuum from the most generic on the left to the most specific on the right. However, the most specific on the right is still generic and needs to be specialized for a particular application (embodiment): Analysis, Visualization &amp; Generation - describes a general approach on using Nasdanika products. Java Analysis, Visualization &amp; Generation - application of the above to the Java model1 Loading and analyzing Java sources and bytecode, generation of non-Java artifacts such as HTML reports Generation of Java sources. JUnit test generation for low coverage methods - further specialization of the Java practice to identify methods with low test coverage using the Coverage Model and then generate JUnit tests for those methods using the Java model and OpenAI. You can think of the three practices above as progressive &ldquo;binding of decision&rdquo; as you move from the left to the right to reach &ldquo;executability&rdquo; - ability to deliver value. A java analogy for progressive specialization would be incremental binding of generic types as exemplified below: Map&lt;K,V&gt; - generic map. MyMap&lt;K extends Comparable&gt; extends Map&lt;&lt;K, MyValue&lt;K&gt;&gt; - the above map bound to a single generic parameter with an upper bound. It is a specialization of the above generic map which is also generic. Some decisions were bound, but there are still decisions to be bound. MyMap&lt;String&gt; theMap = ...; - fully bound map. Decisions are bound at variation point. For example, &ldquo;storage&rdquo; is a variation point, &ldquo;blob storage&rdquo; is one of alternatives, decision to use &ldquo;blob storage&rdquo; binds the variation point to a specific alternative. Decision binding forms a graph. Once you bind, say, &ldquo;storage&rdquo; variation point, some downstream alternatives may become unavailable because they are incompatible with that binding. Some might be available, but make no sense. For example, a decision to send data unencrypted over a public network is compatible with a decision to purchase some additional strong encryption hardware to use on-prem, but does it make business sense? Different alternatives feature different &ldquo;quality attributes&rdquo; - performance, reliability, cost. As the number of variation points and alternatives grows purely human-based decision making becomes inefficient. In this case variation points can be modeled as requirements and alternatives as capability providers or capabilities with quality attributes (seecapability). After this a list of &ldquo;designs&rdquo; (a.k.a. &ldquo;provisioning plans&rdquo;) can be created. A design/provisioning plan is a collection of compatible capabilities. If a list of designs is short enough it can be analyzed by humans directly. In the case of long lists or a large number of very similar designs decision analysis can be employed for making a selection of a design which is best fit for purpose. The page provides a general overview and the book goes into more details. ↩"},"core/emf/index.html":{"path":"Core/EMF","action-uuid":"ba3c546c-dcbc-41a7-ba9d-0f6c4f686f91","title":"EMF","content":"Sources Javadoc"},"nsd-cli/nsd/index.html":{"path":"CLI/nsd","action-uuid":"08f3bdb8-534f-48c3-9f7a-834b5aa189c6","title":"nsd","content":"Version: org.nasdanika.cli \r\nUsage: nsd [-hV] COMMAND\r\nNasdanika Command Line Interface\r\n  -h, --help      Show this help message and exit.\r\n  -V, --version   Print version information and exit.\r\nCommands:\r\n  launcher  Generates Java command line from directories of modules/jars\r\n  app       HTML Application model commands\r\n  drawio    Loads Drawio document from a URI or file\r\n  help      Outputs usage for all registred commands\r\n  java      Commands related to Java\r\n  model     Loads EObject from a URI or file\r\n  rules     Rules commands\r\n  shell     Starts an interactive shell\r\n  exit      Exits shell"},"nsd-cli/nsd/drawio/html-app/save/index.html":{"path":"CLI/nsd/drawio/html-app/save","action-uuid":"42b63115-765b-43f9-b5ea-f1c839508b2c","title":"save","content":"Version: org.nasdanika.cli \r\nUsage: nsd drawio html-app save [-hV] [--progress-console] [--progress-data]\r\n                                [--progress-json]\r\n                                [--progress-output=&lt;progressOutput&gt;]\r\n                                [--content-type-resource-factory=&lt;String=Class&gt;]\r\n                                ...\r\n                                [--extension-resource-factory=&lt;String=Class&gt;]...\r\n\r\n                                [--protocol-resource-factory=&lt;String=Class&gt;]...\r\n                                &lt;output&gt;\r\nSaves model to a file\r\n      &lt;output&gt;             Output file\r\n      --content-type-resource-factory=&lt;String=Class&gt;\r\n                           Maps content type to resource factory class\r\n      --extension-resource-factory=&lt;String=Class&gt;\r\n                           Maps extension to resource factory class\r\n  -h, --help               Show this help message and exit.\r\n      --progress-console   Output progress to console\r\n      --progress-data      Output progress data\r\n      --progress-json      Output progress in JSON\r\n      --progress-output=&lt;progressOutput&gt;\r\n                           Output file for progress monitor\r\n      --protocol-resource-factory=&lt;String=Class&gt;\r\n                           Maps protocol to resource factory class\r\n  -V, --version            Print version information and exit."},"html/jstree/index.html":{"path":"HTML/JsTree","action-uuid":"05dc533c-9288-49b6-95e1-1392b514622d","title":"JsTree","content":"Sources Javadoc"},"nsd-cli/nsd/model/ecore-html-app/index.html":{"path":"CLI/nsd/model/ecore-html-app","action-uuid":"aa05ec84-1cd0-40b3-861f-bd386f55d4ba","title":"ecore-html-app","content":"Version: org.nasdanika.models.ecore.cli \r\nUsage: nsd model ecore-html-app [-fhRV] [-P=&lt;insertionIndex&gt;] [-r=&lt;rootLabel&gt;]\r\n                                [-c=&lt;String=String&gt;]... [-C=URL]...\r\n                                [--content-type-resource-factory=&lt;String=Class&gt;]\r\n                                ...\r\n                                [--extension-resource-factory=&lt;String=Class&gt;]...\r\n                                 [-M=&lt;String=String&gt;]...\r\n                                [--protocol-resource-factory=&lt;String=Class&gt;]...\r\n                                [COMMAND]\r\nGenerates Ecore model documentation html app model\r\n  -c, --context-entry=&lt;String=String&gt;\r\n                      Context entries.\r\n                      Shadow entries in contexts and mounts.\r\n  -C, --context=URL   Context resource URL relative to the current directory.\r\n                        YAML, JSON, or properties. In properties dots are\r\n                        treated as key path separators. Type is inferred from\r\n                        the content type header, if it is present, or\r\n                        extension. Contexts are composed in the order of\r\n                        definition, later context entries shadowing the former\r\n      --content-type-resource-factory=&lt;String=Class&gt;\r\n                      Maps content type to resource factory class\r\n      --extension-resource-factory=&lt;String=Class&gt;\r\n                      Maps extension to resource factory class\r\n  -f, --file          Root action option is a file path\r\n  -h, --help          Show this help message and exit.\r\n  -M, --context-mount=&lt;String=String&gt;\r\n                      MappingContext resource URL relative to the current\r\n                        directory. YAML, JSON, or properties. In properties\r\n                        dots are treated as key path separators. Type is\r\n                        inferred from the content type header, if it is\r\n                        present, or extension. Mounts shadow context entries.\r\n  -P, --position=&lt;insertionIndex&gt;\r\n                      Insertion position\r\n                      Defaults to 0\r\n      --protocol-resource-factory=&lt;String=Class&gt;\r\n                      Maps protocol to resource factory class\r\n  -r, --root-label=&lt;rootLabel&gt;\r\n                      Root label URL or file path, resolved relative\r\n                      to the current directory\r\n  -R, --add-to-root   Add labels to the root\r\n                      even if the principal is present\r\n  -V, --version       Print version information and exit.\r\nCommands:\r\n  save  Saves model to a file\r\n  site  Generates HTML site"},"glossary.html":{"action-uuid":"b47e9466-5186-44e2-9b6f-ed1d1ccd6a71","title":"Glossary","content":"Clear Identifier(s) Hide UUID {{data.value.name}} {{data.value[0].value}} {{item.value}}"},"nsd-cli/nsd/rules/index.html":{"path":"CLI/nsd/rules","action-uuid":"2f969946-f458-4536-bf5b-663f3d37e70a","title":"rules","content":"Usage: nsd rules [-hV] [COMMAND]\r\nRules commands\r\n  -h, --help      Show this help message and exit.\r\n  -V, --version   Print version information and exit.\r\nCommands:\r\n  action-model  Generates rule set documentation action model\r\n  list          Lists available rule sets and rules\r\n  site          Generates rule set documentation site"},"core/exec/index.html":{"path":"Core/Exec","action-uuid":"1f693d52-da21-47f8-a96a-1ea05011accb","title":"Exec","content":"Sources Javadoc"},"html/html/index.html":{"path":"HTML/HTML","action-uuid":"5bb8bb08-b7fa-492a-8c63-efb93ad629ef","title":"HTML","content":"Sources Javadoc"},"nsd-cli/nsd/java/index.html":{"path":"CLI/nsd/java","action-uuid":"e99b80ad-3e65-4512-b48d-1b431172e5fe","title":"java","content":"Version: org.nasdanika.models.java.cli \r\nUsage: nsd java [-hV] [COMMAND]\r\nCommands related to Java\r\n  -h, --help      Show this help message and exit.\r\n  -V, --version   Print version information and exit.\r\nCommands:\r\n  junit  Generates JUnit tests"},"nsd-cli/nsd/help/site/index.html":{"path":"CLI/nsd/help/site","action-uuid":"e22ff97b-061f-426a-b895-a0914cac53b9","title":"site","content":"Usage: nsd help site [-hlV] [--progress-console] [--progress-data]\r\n                     [--progress-json] [-b=&lt;baseDir&gt;] [-m=&lt;domian&gt;]\r\n                     [-P=&lt;parallelism&gt;] [--progress-output=&lt;progressOutput&gt;]\r\n                     [-r=&lt;pageErrors&gt;] [--root-action-icon=&lt;rootActionIcon&gt;]\r\n                     [--root-action-location=&lt;rootActionLocation&gt;]\r\n                     [--root-action-text=&lt;rootActionText&gt;] [-t=&lt;timeout&gt;]\r\n                     [-T=&lt;pageTemplate&gt;] [-w=&lt;workDir&gt;] [-c=&lt;String=String&gt;]...\r\n                     [-C=URL]... [-M=&lt;String=String&gt;]... [-e\r\n                     [=&lt;excludes&gt;...]]... [-i[=&lt;includes&gt;...]]... &lt;output&gt;\r\nGenerates help HTML site\r\n      &lt;output&gt;               Output directory\r\n  -b, --base-dir=&lt;baseDir&gt;   Base directory\r\n  -c, --context-entry=&lt;String=String&gt;\r\n                             Context entries.\r\n                             Shadow entries in contexts and mounts.\r\n  -C, --context=URL          Context resource URL relative to the current\r\n                               directory. YAML, JSON, or properties. In\r\n                               properties dots are treated as key path\r\n                               separators. Type is inferred from the content\r\n                               type header, if it is present, or extension.\r\n                               Contexts are composed in the order of\r\n                               definition, later context entries shadowing the\r\n                               former\r\n  -e, --exclude[=&lt;excludes&gt;...]\r\n                             Output directory clean excludes\r\n                             Ant pattern\r\n  -h, --help                 Show this help message and exit.\r\n  -i, --include[=&lt;includes&gt;...]\r\n                             Output directory clean includes\r\n                             Ant pattern\r\n  -l, --[no-]clean           Clean working directory\r\n                             defaults to true\r\n  -m, --domain=&lt;domian&gt;      Sitemap domain\r\n  -M, --context-mount=&lt;String=String&gt;\r\n                             MappingContext resource URL relative to the\r\n                               current directory. YAML, JSON, or properties. In\r\n                               properties dots are treated as key path\r\n                               separators. Type is inferred from the content\r\n                               type header, if it is present, or extension.\r\n                               Mounts shadow context entries.\r\n  -P, --parallelism=&lt;parallelism&gt;\r\n                             If the value greater than one then an executor\r\n                               service is created and injected into the context\r\n                               to allow concurrent execution.\r\n      --progress-console     Output progress to console\r\n      --progress-data        Output progress data\r\n      --progress-json        Output progress in JSON\r\n      --progress-output=&lt;progressOutput&gt;\r\n                             Output file for progress monitor\r\n  -r, --errors=&lt;pageErrors&gt;  Expected number of page errors\r\n                             -1 for any (not fail on errors)\r\n                             default is 0\r\n      --root-action-icon=&lt;rootActionIcon&gt;\r\n                             Root action icon\r\n      --root-action-location=&lt;rootActionLocation&gt;\r\n                             Root action location\r\n      --root-action-text=&lt;rootActionText&gt;\r\n                             Root action text\r\n  -t, --timeout=&lt;timeout&gt;    If parallelism is greater than one this option\r\n                               specifies timout in seconds awaiting completion\r\n                               of execution. Default value is 60.\r\n  -T, --page-template=&lt;pageTemplate&gt;\r\n                             Page template URI relative\r\n                             to the current directory\r\n  -V, --version              Print version information and exit.\r\n  -w, --work-dir=&lt;workDir&gt;   Working directory\r\nExit codes:\r\n  Non-negative number   Delegate result\r\n  -1                    Unhandled exception during execution\r\n  -2                    Invalid input\r\n  -3                    Diagnostic failed\r\n  -4                    Execution failed or was cancelled, successful rollback\r\n  -5                    Execution failed or was cancelled, rollback failed\r\n  -6                    Executor service termination timed out"},"core/index.html":{"action-uuid":"2d60f670-051e-4779-a872-3b196e91c2cd","title":"Core","content":"Sources"},"practices/generic/index.html":{"path":"Practices/Analysis, Visualization &amp; Generation","action-uuid":"90332a12-02ee-403e-8c1f-0712fe430df0","title":"Analysis, Visualization &amp; Generation","content":"This practice explains how to use Nasdanika products (specifically models) and related products. The above diagram shows the core idea - load input data into a model, modify the model or create a new model from it, and save the models to native (raw) formats. Loading to a model as opposed to working with raw formats gives the following benefits: Unified API Generated model documentation with visualizations Different models may extend classes from core models and be treated similarly Model classes may be subclassed and mixed Cross-reference model elements URI handlers allows to load models from diverse sources On-demand loading of resources and features of model elements Conversion of models to graphs and making them executable with graph processors E.g. want to read/write Excel files - take a look at the Excel metamodel and then use Ecore API to work with the model. Now want to work with PDF? A different metamodel, the same model API. You have Java sources stored in GitLab and want model elements to reflect both Java and GitLab natures of your sources? Create a GitLabRepositoryCompilationUnit class which extends both Compilation Unit and Repository File. Customize Loader to create this class for repository files with java extension. Want to load a PDF file directly from GitLab without having to clone the entire repository? Use GitLabURIHandler! The below diagram illustrates the above concepts: Models can be visualized using: ECharts using the ECharts model, ECharts-Java or by directly generating JavaScript/JSON. Example. PlantUML using DiagramGenerator, the diagram module or by directly generating PlantUML text and calling Plant UML API&rsquo;s. Example. Holistic model of an organization One use case for the modeling approach outlined above is creation of a holistic model of an organization/corporation as exemplified by the below diagram1 In a corporation different elements of the model are typically stored in different systems and documents like Excel spreadsheets. The modeling approach allows to load those elements in a single resource set and cross-reference them. Elements which are not stored in structured formats can be captured by modeling them in diagrams and mapping those diagrams to models, see Beyond Diagrams. One important reason why a holistic model might be beneficial for an organization is the ability of using it for AI insights. For example, using RAG/Chat on top of the organization model. Such chat can be made context-aware, chatting with the Operations will return result relevant to operations. The above diagram is very simple, a large organization may have many layers, thousands of applications, millions of lines of code. A model for such an organization would take some time to build, but it can be built incrementally - department by department, application by application. The value of building such a model will grow exponentially as more and more elements are added due to the network effect. While the resulting model might be &ldquo;large&rdquo;, &hellip; define large. Experiments show that a model element in a model like the above takes ~ 500 bytes of RAM. As such, 1 GB of RAM would hold about 2 million model elements. Also, model resources are loaded on demand, so only the model elements needed by some task would be loaded to complete that task. With DynamicDelegate it is possible to have model elements loading their data from multiple sources on demand. The organization model can be built on top of existing &ldquo;generic&rdquo; models such as Java, Maven, GitLab, Azure, &hellip; Resources TOGAF Enterprise Metamodel Corporate structure ↩ Output Model Transformation Input Model Raw Input Raw Output Cell Excel Resource Paragraph PDF Resource Resource Set GitLab URI Handler MS Excel Workbook GitLab Excel Resource Factory PDF Resource Factory PDF File File system Corporation Marketing Finance Uses Operations HR Builds IT Execution environments Binary packages Source Code Application"},"core/http/index.html":{"path":"Core/HTTP","action-uuid":"f2bdb835-f96e-42d7-a10b-4dc759b743e2","title":"HTTP","content":"Sources Javadoc"},"nsd-cli/nsd/model/ecore-html-app/site/index.html":{"path":"CLI/nsd/model/ecore-html-app/site","action-uuid":"7c411812-8ce4-44d3-9f40-abeeb9535e62","title":"site","content":"Version: org.nasdanika.cli \r\nUsage: nsd model ecore-html-app site [-hlV] [--progress-console]\r\n                                     [--progress-data] [--progress-json]\r\n                                     [-b=&lt;baseDir&gt;] [-F=&lt;pageTemplateFile&gt;]\r\n                                     [-m=&lt;domian&gt;] [-P=&lt;parallelism&gt;]\r\n                                     [--progress-output=&lt;progressOutput&gt;]\r\n                                     [-r=&lt;pageErrors&gt;] [-t=&lt;timeout&gt;]\r\n                                     [-T=&lt;pageTemplate&gt;] [-w=&lt;workDir&gt;]\r\n                                     [-c=&lt;String=String&gt;]... [-C=URL]...\r\n                                     [-M=&lt;String=String&gt;]... [-e\r\n                                     [=&lt;excludes&gt;...]]... [-i\r\n                                     [=&lt;includes&gt;...]]... &lt;output&gt;\r\nGenerates HTML site\r\n      &lt;output&gt;               Output directory relative to the base directory\r\n  -b, --base-dir=&lt;baseDir&gt;   Base directory\r\n  -c, --context-entry=&lt;String=String&gt;\r\n                             Context entries.\r\n                             Shadow entries in contexts and mounts.\r\n  -C, --context=URL          Context resource URL relative to the current\r\n                               directory. YAML, JSON, or properties. In\r\n                               properties dots are treated as key path\r\n                               separators. Type is inferred from the content\r\n                               type header, if it is present, or extension.\r\n                               Contexts are composed in the order of\r\n                               definition, later context entries shadowing the\r\n                               former\r\n  -e, --exclude[=&lt;excludes&gt;...]\r\n                             Output directory clean excludes\r\n                             Ant pattern\r\n  -F, --page-template-file=&lt;pageTemplateFile&gt;\r\n                             Page template file relative\r\n                             to the current directory\r\n  -h, --help                 Show this help message and exit.\r\n  -i, --include[=&lt;includes&gt;...]\r\n                             Output directory clean includes\r\n                             Ant pattern\r\n  -l, --[no-]clean           Clean working directory\r\n                             defaults to true\r\n  -m, --domain=&lt;domian&gt;      Sitemap domain\r\n  -M, --context-mount=&lt;String=String&gt;\r\n                             MappingContext resource URL relative to the\r\n                               current directory. YAML, JSON, or properties. In\r\n                               properties dots are treated as key path\r\n                               separators. Type is inferred from the content\r\n                               type header, if it is present, or extension.\r\n                               Mounts shadow context entries.\r\n  -P, --parallelism=&lt;parallelism&gt;\r\n                             If the value greater than one then an executor\r\n                               service is created and injected into the context\r\n                               to allow concurrent execution.\r\n      --progress-console     Output progress to console\r\n      --progress-data        Output progress data\r\n      --progress-json        Output progress in JSON\r\n      --progress-output=&lt;progressOutput&gt;\r\n                             Output file for progress monitor\r\n  -r, --errors=&lt;pageErrors&gt;  Expected number of page errors\r\n                             -1 for any (not fail on errors)\r\n                             default is 0\r\n  -t, --timeout=&lt;timeout&gt;    If parallelism is greater than one this option\r\n                               specifies timout in seconds awaiting completion\r\n                               of execution. Default value is 60.\r\n  -T, --page-template=&lt;pageTemplate&gt;\r\n                             Page template URI relative\r\n                             to the current directory\r\n  -V, --version              Print version information and exit.\r\n  -w, --work-dir=&lt;workDir&gt;   Working directory\r\nExit codes:\r\n  Non-negative number   Delegate result\r\n  -1                    Unhandled exception during execution\r\n  -2                    Invalid input\r\n  -3                    Diagnostic failed\r\n  -4                    Execution failed or was cancelled, successful rollback\r\n  -5                    Execution failed or was cancelled, rollback failed\r\n  -6                    Executor service termination timed out"},"nsd-cli/nsd/help/index.html":{"path":"CLI/nsd/help","action-uuid":"7f7766fd-554f-42fa-bcb8-49948df92fa8","title":"help","content":"Usage: nsd help [-ahHV] [-l=&lt;level&gt;] [-o=&lt;output&gt;] [COMMAND]\r\nOutputs usage for all registred commands\r\n  -a, --action-model      Output to action model\r\n  -h, --help              Show this help message and exit.\r\n  -H, --html              Output to HTML\r\n  -l, --header-level=&lt;level&gt;\r\n                          Starting level for HTML header tags in HTML output,\r\n                            the default value is 1.\r\n  -o, --output=&lt;output&gt;   Output file\r\n  -V, --version           Print version information and exit.\r\nCommands:\r\n  site  Generates help HTML site"}}