var searchDocuments = {"html/index.html":{"action-uuid":"d2e49885-aacd-4d04-aec8-fe457705b8ef","title":"HTML","content":"TODO"},"html/models/app/index.html":{"path":"HTML/Models/App","action-uuid":"37164d7c-e017-4356-b16e-95762e8e4d56","title":"App","content":"TODO"},"html/models/bootstrap/index.html":{"path":"HTML/Models/Bootstrap","action-uuid":"c6f9114c-ec26-4fac-819f-37ffdb5e0c4f","title":"Bootstrap","content":"TODO"},"core/maven/index.html":{"path":"Core/Maven","action-uuid":"5ca15890-d593-441b-9dc3-21a73f122a64","title":"Maven","content":"TODO"},"core/persistence/index.html":{"path":"Core/Persistence","action-uuid":"32ce63a6-ead7-4cce-a553-60aa11dbfa82","title":"Persistence","content":"TODO"},"core/diagram/index.html":{"path":"Core/Diagram","action-uuid":"877834a3-8232-492c-ba9e-9711bedef22f","title":"Diagram","content":"TODO"},"html/emf/index.html":{"path":"HTML/EMF","action-uuid":"b693e8ee-42cc-44b9-be88-05e2a8345a71","title":"EMF","content":"TODO"},"html/bootstrap/index.html":{"path":"HTML/Bootstrap","action-uuid":"8e0a3cb3-afdc-4717-9543-dad8a5f3493d","title":"Bootstrap","content":"TODO"},"core/resources/index.html":{"path":"Core/Resources","action-uuid":"8cf66436-c0bd-41cd-843e-bb512e81af8f","title":"Resources","content":"TODO"},"practices/index.html":{"action-uuid":"1e839b75-ce3e-43a0-8717-ee6098cf3a41","title":"Practices","content":"Practices explain how to use Nasdanika products to achieve specific goals and explain why particular design choices wer made. The enterprise model provides deeper insight on the WHY in general. The practices are organized into an enterprise continuum from the most generic on the left to the most specific on the right. However, the most specific on the right is still generic and needs to be specialized for a particular application (embodiment): Analysis, Visualization &amp; Generation - describes a general approach on using Nasdanika products. Java Analysis, Visualization &amp; Generation - application of the above to the Java model1 Loading and analyzing Java sources and bytecode, generation of non-Java artifacts such as HTML reports Generation of Java sources. JUnit test generation for low coverage methods - further specialization of the Java practice to identify methods with low test coverage using the Coverage Model and then generate JUnit tests for those methods using the Java model and OpenAI. You can think of the three practices above as progressive &ldquo;binding of decision&rdquo; as you move from the left to the right to reach &ldquo;executability&rdquo; - ability to deliver value. A java analogy for progressive specialization would be incremental binding of generic types as exemplified below: Map&lt;K,V&gt; - generic map. MyMap&lt;K extends Comparable&gt; extends Map&lt;&lt;K, MyValue&lt;K&gt;&gt; - the above map bound to a single generic parameter with an upper bound. It is a specialization of the above generic map which is also generic. Some decisions were bound, but there are still decisions to be bound. MyMap&lt;String&gt; theMap = ...; - fully bound map. Decisions are bound at variation point. For example, &ldquo;storage&rdquo; is a variation point, &ldquo;blob storage&rdquo; is one of alternatives, decision to use &ldquo;blob storage&rdquo; binds the variation point to a specific alternative. Decision binding forms a graph. Once you bind, say, &ldquo;storage&rdquo; variation point, some downstream alternatives may become unavailable because they are incompatible with that binding. Some might be available, but make no sense. For example, a decision to send data unencrypted over a public network is compatible with a decision to purchase some additional strong encryption hardware to use on-prem, but does it make business sense? Different alternatives feature different &ldquo;quality attributes&rdquo; - performance, reliability, cost. As the number of variation points and alternatives grows purely human-based decision making becomes inefficient. In this case variation points can be modeled as requirements and alternatives as capability providers or capabilities with quality attributes (seecapability). After this a list of &ldquo;designs&rdquo; (a.k.a. &ldquo;provisioning plans&rdquo;) can be created. A design/provisioning plan is a collection of compatible capabilities. If a list of designs is short enough it can be analyzed by humans directly. In the case of long lists or a large number of very similar designs decision analysis can be employed for making a selection of a design which is best fit for purpose. The page provides a general overview and the book goes into more details. â†©"},"core/emf/index.html":{"path":"Core/EMF","action-uuid":"604ea5aa-3879-4474-bc84-30a7c8ead489","title":"EMF","content":"TODO"},"html/models/html/index.html":{"path":"HTML/Models/HTML","action-uuid":"500853af-3472-4878-b876-34e387cab657","title":"HTML","content":"TODO"},"index.html":{"action-uuid":"3f1783f7-6d7c-42aa-82cb-50855313158b","title":"Nasdanika","content":" Common Resources Persistence Ncore Diagram Graph Drawio EMF Exec Maven Capability Core HTML HTML Bootstrap App Models JsTree Bootstrap EMF HTML GitLab Family Architecture Git Excel ECharts Nature Bank PDF Party Coverage Source Engineering Java Maven Enterprise Function Flow Rules Azure Decision Analysis Capability Flow Ecore Jira Models Data Sources Loader Store Key Extractor Query Engine Requestor Generator Responder Retrieval Augmented Generation (RAG) Analysis, Visualization &amp; Generation Java Analysis, Visualization &amp; Generation JUnit Tests Generation Practices Beyond Diagrams Java Analysis, Visualization, and Generation Books Common Resources Persistence Ncore Diagram Graph Drawio EMF Exec Maven Capability Core HTML HTML Bootstrap App Models JsTree Bootstrap EMF HTML GitLab Family Architecture Git Excel ECharts Nature Bank PDF Party Coverage Source Engineering Java Maven Enterprise Function Flow Rules Azure Decision Analysis Capability Flow Ecore Jira Models Data Sources Loader Store Key Extractor Query Engine Requestor Generator Responder Retrieval Augmented Generation (RAG) Analysis, Visualization &amp; Generation Java Analysis, Visualization &amp; Generation JUnit Tests Generation Practices Beyond Diagrams Java Analysis, Visualization, and Generation Books"},"html/jstree/index.html":{"path":"HTML/JsTree","action-uuid":"eee448e8-539b-403a-8dd3-834c6eeb0d71","title":"JsTree","content":"TODO"},"glossary.html":{"action-uuid":"6cc02e6f-7478-4543-bbb4-64b65f3dc548","title":"Glossary","content":"Clear Identifier(s) Hide UUID {{data.value.name}} {{data.value[0].value}} {{item.value}}"},"core/common/index.html":{"path":"Core/Common","action-uuid":"f055bace-5fc1-400a-ad6e-2a8fca6e0e68","title":"Common","content":"TODO"},"practices/junit/index.html":{"path":"Practices/JUnit Tests Generation","action-uuid":"fd9c6b9c-57f7-4666-bf35-7a64b92f9ecd","title":"JUnit Tests Generation","content":"This practice is a specialization of the Java Analysis, Visualization &amp; Generation Practice for generation of JUnit tests. In particular: Generation of tests for methods or classes with low test coverage Leveraging Gen AI such as OpenAI ChatGPT or Azure OpenAI Service for test generation The above diagram shows Java development activities and artifacts. Black arrows show the typical process, blue arrows show the test generation loop. The developer produces source artifacts which may include non-java artifacts used to generate Java code (e.g. Ecore models), &ldquo;main&rdquo; Java sources and test Java sources. Java sources are compiled into bytecode (class files). Here it is important to note that matching of bytecode classes and methods to source code classes and methods might be non-trivial because of: Lambdas Anonymous and method-scope classes Annotation processors like Lombok JUnit tests are compiled and executed. If code coverage, such as jacoco, is configured then test execution produces coverage data. Jacoco stores coverage data in jacoco.exec file. This file is used to generate a coverage report and upload coverage information to systems like SonarQube. In this practice it is also used to select which methods to generate tests for based on coverage data. This diagram provides an insight into the test generation activity: Coverage data and bytecode are used as input to load the Coverage model. Source files, the coverage model, and bytecode (optional) are used to load the Java model of source code. The generator traverses the model and generates unit tests for method with low coverage using a combination of programmatic (traditional) generation and Gen AI. Tests are generated as a Java model as well and then are delivered to the developer for review, modification, and inclusion into the unit test suite. The following section provides an overview of two &ldquo;local loop&rdquo; reference implementations (a.k.a. designs/embodiments) - all-in-one and componentized. There are many possible designs leveraging different alternatives at multiple variation points. The sections after the reference implementations section provide an overview of variation points, alternatives, and factors to take into consideration during alternative selection. Reference Implementations All-in-one Componentized Variation points and alternatives Stakeholders &amp; Activities Developer Build machine Test generator GenAI Messages Channels Developer -&gt; Build Machine/Test Generation : Source code Build Machine -&gt; Test Generator : Coverage results, possibly with bytecode Test Generation -&gt; Developer : Generated tests Test Generation - GenAI : Prompt Tests generator Delivery of generated tests Test generation execution Access to artifacts Parking lot Reference Implementations This section explains two reference implementations All-in-one All-in-one generations is implemented as a JUnit test is available in TestGenerator. An example of tests generated by this generator - PetControllerTests. As the name implies, all steps of source analysis and generation are implemented in a single class and are executed in one go. Componentized Componentized test generation which is also executed in one go is implemented in these classes: TestJavaAnalyzers - loads sources, coverage, and inspectors, passes the sources to the inspectors, aggregates and saves results. Coverage Inspector - generates tests for methods with low coverage leveraging TestGenerator capability provided by OpenAITestGenerator. Variation points and alternatives As you have seen above, you can have an AI-powered JUnit test generator in about 230 lines of code, and maybe it would all you need. However, there are many variation points (design dimensions), alternatives at each point and, as such, possible permutations of thereof (designs). This section provides a high level overview of variation points and alternatives. How to assemble a solution from those alternative is specific to your context and there might be different solutions for different contexts and multiple solutions complementing each other. As you proceed with assembling a solution, or a portfolio of solutions, you may identify more variation points and alternatives. To manage the complexity you may use: Enterprise Model for general guidance, Capability framework or Capability model to create a catalog of variation points and alternatives and compute solutions (designs) from them Decision Analysis to select from the computed list of designs Flow to map your development process AS-IS and then augment it with test generation activities at different points. In this section we&rsquo;ll use the below diagram and the concept of an Enterprise with Stakeholders performing activities and exchanging Messages over Channels. The mission of our enterprise is to deliver quality Java code. The loss function to minimize is loss function = cost * risk / business value. For our purposes we&rsquo;ll define risk as inversely proportional to tests coverage risk = missed lines / total lines - that&rsquo;s all we can measure in this simple model. The cost includes resources costs - salary, usage fees for OpenAI. Below is a summary of our enterprise: Stakeholders &amp; Activities: Developer - writes code Build machine - compiles code and executes tests Test generator - generates unit tests GenAI - leveraged by the Test Generator Messages: Source code Bytecode Coverage results Prompt to generate a test Generated tests Channels Developer -&gt; Build Machine : Source code Developer -&gt; Test Generation : Source code Build Machine -&gt; Test Generator : Coverage results, possibly with bytecode Test Generation -&gt; Developer : Generated tests Test Generation - GenAI : Prompt The below sections outline variation points and alternatives for the list items above Stakeholders &amp; Activities Developer A developer writes code - both &ldquo;business&rdquo; and test. They use some kind of an editor, likely an IDE - Eclipse, IntelliJ, VS Code. Different IDE&rsquo;s come with different sets of plug-ins, including AI assistants. Forcing a developer to switch from their IDE of preference to another IDE is likely to cause considerable productivity drop, at least for some period of time, even if the new IDE is considered superior to the old IDE. So, if you want to switch to another IDE just because it has some plug-in which you like - think twice. Build machine A build machine compiles code and executes tests. Technically, compilation and test execution may be separated in two individual activities. We are not doing it for this analysis because it doesn&rsquo;t carry much relevance to test generation. You can do it for yours. Test generator Test generator generates tests by &ldquo;looking&rdquo; at the source code, bytecode, and code coverage results. Because the source code is a model element representing piece of code (method, constructor, &hellip;), the generator may traverse the model to &ldquo;understand&rdquo; the context. E.g. it may take a look at the method&rsquo;s class, other classes in the module. If the sources are loaded from a version control system, it may take a look at the commits. And if the source model is part of an organization model, it may look at &ldquo;sibling&rdquo; modules and other resources. Using this information it may build a wide variety of prompts for GenAI. By analyzing source and bytecode the generator would know which methods a given method calls, which objects it creates, and also it would know methods calling the method. It will also &ldquo;know&rdquo; branch conditions, e.g. switch cases. Using this information the generator may: Generate comments to help the developer Generate mocks, including constructor and static methods mocks Generate tests for different branches GenAI There may GenAI models out there - cloud, self hosted. Which one to use heavily depends on the context. For example, if you have a large codebase with considerable amount of technical debt having an on-prem model may be a good choice because: You may fine-tune it. Even if you don&rsquo;t have tons of GPU power and your model is relatively slow you can crawl you code base, generate tests and deliver them to developers for review and inclusion into test suites. In this scenario your cost is on-prem infrastructure and power. Your savings are not having to pay for GenAI in the cloud and developer productivity if your fined tuned model turns out to be more efficient than a &ldquo;vanilla&rdquo; LLM. There are many other considerations, of course! Messages In this section we&rsquo;ll take a look just at bytecode and coverage results delivered to the test generator. The generator operates on models. As such, bytecode and coverage results can be delivered in a &ldquo;raw&rdquo; format to be loaded to a model by the generator, or pre-loaded to a model and saved to a file. The second option results in fewer files to pass to the test generator. The model file can be in XMI format or in compressed binary. The XMI format is human-readable, the binary format takes less space on disk. Channels Developer -&gt; Build Machine/Test Generation : Source code For local development the build machine is the same machine where developer creates sources. The test generator is also executed on the developer&rsquo;s workstation. As such, the delivery channels is the file system. In the case of CI/CD pipeline/build server such as Jenkins or GitHub Actions, a version control systems is the delivery channel. Build Machine -&gt; Test Generator : Coverage results, possibly with bytecode The test generator needs coverage results. If the coverage results are delivered in the raw form, it also needs bytecode (class files) to make sense of the results. Coverage results can be delivered to the test generator using the following channels: Filesystem Jenkins workspace made available to the test generator over HTTP(S) Binary repository. For example, coverage results might be published to the Maven repository as an assembly along with sources, jar file, and javadoc. They can be published in a raw format or as a model. In this modality the tests generator can get everything it needs from a Maven repository. TODO - artifact resolver. TODO - specialized repo for coverage info Test Generation -&gt; Developer : Generated tests Filtering, throttling, jira Test Generation - GenAI : Prompt Billing, throttling, caching, authentication, &hellip; Tests generator Delivery of generated tests Test generation execution Maven plugin, pipeline, crawling Access to artifacts Jenkins workspace, Maven repository, Maven classloader / artifacts loader - reference Maven model TODO: Diagram (site - activities, artifacts, variation points), manually created sources, generated source, bytecode, coverage report. Lombok, ecore. Sorting (by dependency, size, &hellip;), throttling, creation of work items Comparison, positioning, complementary - availability of IDE plug-ins/extensions in org. Not better, different. IDE plug-ins: select code, type a request, wait for generation, save to a file, add package declaration and some imports. dependency: top-down - downstream dependencies might be tested along the way bottom-up both have merits and might be applicable in diffent situations. bottom-up for new development, top-down for addressing technical debt. Parking lot Mention GitLab URI handler - get from, push to, create a merge reguest, link to sources Fine-tuned models (?) Llama 2? Massaging returned text - backticks, imports - explicit and implicit, use Java parser/model. Pet clinic demo - G/H fork, use GPT 4, specify SpringBoot and Mockito in prompt, tags - as is/disabled test methods Use with G/H copilot - complementary, different Unit tests delivery - branch, fork SonarQube - class level. jacoco.exec - Maven repository - evidence for other purposes. Coverage storage. Jenkins workspace Mention assembly of a solution from alternatives, use capability and decision analysis. Coverage - jacoco.exec + class files, sq api, JSON, DB/REST API (part of the enterprise model, mention the generic thing), XMI/Binary. Storage - local, Jenkins workspace, sq, maven binary repository Mock opportunities - we know methods being called, constructors etc. We can generate mock generation and try/catch for static methods and constructors. Branches, switch cases in particular and enums Generate review/explain @Mock, @InjectMocks Cost value for each acitivity, opportunities Sort by dependency, lower-level may be (partially) testes as part of higher level Prompt building - eContainer, resource, resource set (on-demand loading), mention enterprise model from the generic Massaging generated sources - peeling back-ticks, parsing, imports - in the snippet, implicit/assumed. All in one code snippet, rules - diagram and snippets Generation - lombok Recipe book Loops - local, pipeline, issues, scan repos, pull/merge request, sq TODO - sequence diagram for the componentized Re-generation: add @Generated annotation, source digest, generated source digest. Regenerate if source digest changed, but generated digest hasn&rsquo;t Assign different generated tests to different people by complexity/size and skill level. Build API delivery - throttling (rate limit), budgeting, billing Tech debt Prompt libraries/generators - context Java Sources Source Artifacts Bytecode Coverage Data Developer JUnit Tests Gen AI Code Generation Compilation Test Execution JUnit Test Generation Coverage Report Java Sources Bytecode Coverage Data Developer Gen AI Coverage Model Source Code Model Tests Model Generator JUnit Test Generation Writing Code Compilation Testing Test Generation Gen AI"},"core/drawio/index.html":{"path":"Core/Drawio","action-uuid":"b2905e8c-87ec-4038-8060-0ed38a4adbd7","title":"Drawio","content":"Nasdankia provides two Maven modules for working with Drawio diagrams - API and Model. The modules require Java 17 or above. API Drawio module provides Java API for reading and manipulating Drawio diagrams. It is built on top of Graph. The module provides the following interfaces representing elements of a diagram file: Document - the root object of the API representing a file/resource which contains one or more pages. Page - a page containing a diagram (Model). Model - a diagram model containing the diagram root. Root - the root of the model containing layers. Layer - a diagram may have one or more layers. Layers contain Nodes and Connections. Node - a node can be connected to other nodes with connections. A node may contain other nodes and connections. Connection - a connection between two nodes. The below diagram shows relationships between the above interfaces including their super-interfaces: Util provides utility methods such as layout() and methods to navigate and query documents and their elements. Model Drawio Model module provides an EMF Ecore model for diagrams. A model instance can be obtained from the API document by calling Document.toModelDocument() method. The model makes it more convenient to work with the diagram elements by: Making a reference between pages and model elements bi-directional. Introducing Tag class as opposed to a string in the API. Tag is contained by Page and has bi-directional reference with tagged elements. Document The root object of the API representing a file/resource which contains one or more pages Page A page containing a diagram (Model) Model A diagram model containing the diagram root Root The root of the model containing layers Layer A diagram may have one or more layers. Layers contain Nodes and Connections. Link [0..1] Layer Element Element Model Element Node A node can be connected to other nodes with connections. A node may contain other nodes and connections. Connection A connection between two nodes * source 0..1 outgoingConnections * 1 1 1..* * target 0..1 incomingConnections * Tag * * *"},"core/exec/index.html":{"path":"Core/Exec","action-uuid":"44ba72ef-443b-4ec5-8752-2310fbb23c2e","title":"Exec","content":"TODO"},"core/ncore/index.html":{"path":"Core/Ncore","action-uuid":"d26224e0-f6e7-4569-9639-d935fcf66f65","title":"Ncore","content":"TODO"},"html/html/index.html":{"path":"HTML/HTML","action-uuid":"ece83b60-4bee-4557-aac2-bdd1e6b0e433","title":"HTML","content":"TODO"},"practices/java/index.html":{"path":"Practices/Java Analysis, Visualization &amp; Generation","action-uuid":"fa193a46-0f1e-49bb-a11a-a0d03c9f997c","title":"Java Analysis, Visualization &amp; Generation","content":"sequence diagrams; method, class, package, module dependency graphs. Size and coverage - red border, green core. Logarithmic or scaled - min/max. Doc similar to model doc. GenAI explain and recommend - legacy code Mention the book - this is a high level overview, book is more detaied merging/ranges Sources linked to the org/architecture model - chat with them (RAG) Do not re-generate if: Nothing changed - if generation takes time or cost money, e.g. GenAI. Manual changes. Tracking - digests"},"core/capability/index.html":{"path":"Core/Capability","action-uuid":"aee78063-a71d-4f48-8895-03b0a884818b","title":"Capability","content":"Nasdanika Capability framework allows to discover/load capabilities which meet a requirement. Capabilities are provided by CapabilityFactory create() method. Capability factories may request other capabilities they need. As such, capabilities can be chained. Factories create CapabilityLoaders which provide Flux reactive streams of capabilities. It allows to have an infinite stream of capabilities which are consumed (and produced) as needed. Capability providers may furnish additional information about capabilities. This information can be used for filtering or sorting providers. A non-technical example of requirement/capability chain graph is a food chain/graph. Food is a requirement. Or &ldquo;I want to eat&rdquo; is a requirement. Bread and, say fried eggs are two capabilities meeting/addressing the requirement. Bread requires &ldquo;wheat&rdquo;, &ldquo;water&rdquo;, and &ldquo;bake&rdquo; capabilities. Fried eggs require &ldquo;egg&rdquo;, &ldquo;oil&rdquo;, and &ldquo;fry&rdquo; capabilities. Bread capability provider may implement Vegan marker interface which can be used for filtering. All food capabilities may implement NutritionalInformation interface - it can be used for filtering or sorting. A more technical example is Java ServiceLoader with service type being a requirement and an instance of the service class being a capability. Nasdanika capability framework can operate on top of ServiceLoader and may be thought of as a generalization of service loading. In essence, the capability framework is a backward chaining engine as shown in one of the example below. Client code - requesting a capability Capabilities are loaded by CapabilityLoader. Capability loader can take an iterable of capability factories in its constructor, or it can load them using ServiceLoader as shown in the below code snippet: CapabilityLoader capabilityLoader = new CapabilityLoader();\ncapabilityLoader.getFactories().add(new TestServiceFactory&lt;Object&gt;());\nProgressMonitor progressMonitor = new PrintStreamProgressMonitor();\n\t\t\nfor (CapabilityProvider&lt;?&gt; cp: capabilityLoader.load(new TestCapabilityFactory.Requirement(&quot;Hello World&quot;), progressMonitor)) {\n\tSystem.out.println(cp);\n\tFlux&lt;?&gt; publisher = cp.getPublisher();\n\t\t\t\n\tpublisher.subscribe(System.out::println);\n}\n Factories can also be added post-construction with getFactories().add(factory). Service capabilities Service requirements and capabilities provide functionality similar to ServiceLoader - requesting instances of specific type, but extend it with ability to provide additional service requirement. This functionality is provided by ServiceCapabilityFactory and ServiceCapabilityFactory.Requirement. CapabilityLoader capabilityLoader = new CapabilityLoader();\ncapabilityLoader.getFactories().add(new TestServiceFactory&lt;Object&gt;());\nProgressMonitor progressMonitor = new PrintStreamProgressMonitor();\n\t\t\n@SuppressWarnings({ &quot;unchecked&quot;, &quot;rawtypes&quot; })\nServiceCapabilityFactory.Requirement&lt;List&lt;Double&gt;, Double&gt; requirement = (ServiceCapabilityFactory.Requirement) ServiceCapabilityFactory.createRequirement(List.class, null,  33.0);\nfor (CapabilityProvider&lt;?&gt; cp: capabilityLoader.load(requirement, progressMonitor)) {\n\tSystem.out.println(cp);\n\tFlux&lt;?&gt; publisher = cp.getPublisher();\n\t\t\t\n\tpublisher.subscribe(System.out::println);\n}\n It is also possible to load services from ServiceLoader using subclasses of Service. You&rsquo;d need to subclass ServiceFactory in a module which uses a particular service and override stream(Class&lt;S&gt; service) method as shown below: @Override\nprotected Stream&lt;Provider&lt;S&gt;&gt; stream(Class&lt;S&gt; service) {\n\treturn ServiceLoader.load(service).stream();\n}\n Then you&rsquo;d need to add the factory to the loader: capabilityLoader.getFactories().add(new TestServiceFactory&lt;Object&gt;());\n Providing a capability As it was mentioned above, capability factories can be explicitly added to CapabilityLoader or loaded using ServiceLoader. Below is an example of a capability factory: public class TestCapabilityFactory implements CapabilityFactory&lt;TestCapabilityFactory.Requirement, Integer&gt; {\n\t\n\tpublic record Requirement(String value){};\n\t\n\t@Override\n\tpublic boolean canHandle(Object requirement) {\n\t\treturn requirement instanceof Requirement;\n\t}\n\n\t@Override\n\tpublic CompletionStage&lt;Iterable&lt;CapabilityProvider&lt;Integer&gt;&gt;&gt; create(\n\t\t\tRequirement requirement,\n\t\t\tBiFunction&lt;Object, ProgressMonitor, CompletionStage&lt;Iterable&lt;CapabilityProvider&lt;Object&gt;&gt;&gt;&gt; resolver,\n\t\t\tProgressMonitor progressMonitor) {\n\t\t\n\t\treturn resolver.apply(MyService.class, progressMonitor).thenApply(cp -&gt; {;\n\t\t\t@SuppressWarnings({ &quot;unchecked&quot;, &quot;rawtypes&quot; })\n\t\t\tFlux&lt;MyService&gt; myServiceCapabilityPublisher = (Flux) cp.iterator().next().getPublisher();\n\t\t\t\n\t\t\treturn Collections.singleton(new CapabilityProvider&lt;Integer&gt;() {\n\t\n\t\t\t\t@Override\n\t\t\t\tpublic Flux&lt;Integer&gt; getPublisher() {\n\t\t\t\t\tFunction&lt;MyService, Integer&gt; mapper = ms -&gt; ms.count(((Requirement) requirement).value());\n\t\t\t\t\treturn myServiceCapabilityPublisher.map(mapper);\n\t\t\t\t}\n\t\t\t\t\n\t\t\t});\n\t\t});\n\t}\n\n}\n Applications Services Service capabilities explained above a used by Graph and Function Flow for loading node processors and connection processors for a specific requirement using NodeProcessorFactory and ConnectionProcessorFactory respectively. For example, code generation, execution, simulation. Solutions for architectures One of future application of the capability framework is creation a list of solution alternatives for an architecture/pattern. For example, there might be multiple RAG embodiments with different key types, key extractors, stores, &hellip; Some of &ldquo;design dimensions&rdquo; are listed below: Key type: Bag of words. Multiple options - just words, words with frequency, tokenized words, word stems. Embedding vector - different embedding models, different dimensions. Store - multiple stores for multiple key types. Multiple indexing and retrieval methods. Chunk size, chunk overlap, chunking algorithm. Generator - multiple models and prompts As you can see a number of potential combinations can easily go into thousands or even be infinite. Reactive approach with filtering and sorting may be helpful in selecting a solution which is a good fit for a particular use case - number and type of data sources etc. For example, if the total size of data is under a few gigabytes an in-memory store may be a better choice than, say, an external (vector) database. Also an old good bag of words might be better than embeddings. E.g. it might be cheaper. Solution alternatives may include temporal aspect or monetary aspects. For example, version X of Y is available at time Z. Z might be absolute or relative. Say, Z days after project kick-off or license fee payment. Identified solutions meeting requirements can have different quality attributes - costs (to build, to run), timeline, etc. These quality attributes can be used for solution analysis. E.g. one solution can be selected as a transition architecture and another as the target architecture. Backward chaining Family reasoning demonstrates application of the capability framework as a backward chaining engine. Family relationships such as grandfather and cousin are constructed by requiring and combining relationships such as child and sibling. Stream processing This possible application is similar to backward reasoning. Imagine an algorithmic trading strategy which uses several technical indicators, such as moving averages, to make trading decisions. Such a strategy would submit requirements for technical indicators which would include symbol, indicator configuration, time frame size. Technical indicators in turn would submit a requirement for raw trading data. A technical indicator such as moving average would start publishing its events once it receives enough trading data frames to compute its average. A trading engine would submit a requirement for strategies. A strategy factory may produce multiple strategies with different configurations. The trading engine would perform &ldquo;paper&rdquo; trades, select well-performing strategies and discard ones which perform poorly. This can be an ongoing process - if a strategy deteriorates then it is discarded and a new strategy is requested from strategy publishers - this process can be infinite. AI model training/fine-tuning This application is similar to stream processing and may be combined with backward reasoning. Let&rsquo;s say we want to train a model to answer questions about family relationships for a specific family. For example, &ldquo;Who is Alan&rsquo;s great grandmother?&rdquo; A single relationship in the model can be expressed in multiple ways in natural language. And multiple relationships can be expressed in a single sentence. For example: Elias is a person Elias is a man Elias is a male Elias is a parent of Fiona Fiona is a child of Elias Elias is a father of Fiona Fiona is a daughter of Elias Paul and Isa are parents of Lea and Elias &hellip; So, on top of a model there might be a collection of text generators. Output of those generators can be fed to a model: Supervised - question and answer &ldquo;How many sisters does Bryan have?&rdquo; - &ldquo;Two&rdquo; &ldquo;Who are Bryan&rsquo;s sisters?&rdquo; - &ldquo;Clara and Fiona&rdquo; Unsupervised - factual statements A similar approach can be applied to other models - customer/accounts, organization or architecture model, etc. For example, from the Internet Banking System we can generate something like &ldquo;Accounts Summary Controller uses Mainframe Banking System Facade to make API calls to the Mainframe Banking System over XML/HTTPS&rdquo;. &ldquo;make API calls&rdquo; may also be generated as &ldquo;connect&rdquo; or &ldquo;make requests&rdquo;. In a similar fashion a number of questions/answers can be generated."},"core/graph/index.html":{"path":"Core/Graph","action-uuid":"acb57c5b-4d6e-423c-a486-d0f85c706ca0","title":"Graph","content":"TODO"},"core/index.html":{"action-uuid":"52fd3018-b56f-42c2-91ad-3a9f269c045f","title":"Core","content":"TODO"},"html/models/index.html":{"path":"HTML/Models","action-uuid":"5f6f8c44-a305-4952-bfe4-eaa1c61db231","title":"Models","content":"TODO"},"practices/generic/index.html":{"path":"Practices/Analysis, Visualization &amp; Generation","action-uuid":"14127a0f-1768-420d-9762-51824fd5f92a","title":"Analysis, Visualization &amp; Generation","content":"Decision binding, enterprise model, &hellip; Variation points, designs (provisioning plans), decision analysis - alternatives, quality attributes as criteria input -&gt; process -&gt; output raw data -&gt; model -&gt; process -&gt; model -&gt; output Cross-referencing, e.g. Excel cell referencing a PDF paragraph &hellip; Inheritance/specialization, e.g. Java source (comp unit) in GitLab. Org model. Loading/storing - GitLab URI converter. a brief overview of models, alphabetical conversion to graphs, processors, visualizations Evans, DDD, anti-corruption layer. Just processing - the what, Ecore &amp; NSD are how Inheritance - https://pubs.opengroup.org/togaf-standard/introduction/Figures/34_contentfwk8.png, https://pubs.opengroup.org/togaf-standard/applying-the-adm/Figures/40_partitioning5.png, https://pubs.opengroup.org/togaf-standard/applying-the-adm/chap04.html#tag_04, https://pubs.opengroup.org/togaf-standard/introduction/chap03.html#tag_03_12_03 Create a diagram, roll-up translationists, elaborationists, mdd book reference, lombock - post human, ecore - pre-human &amp; merge https://www.amazon.com/MDA-Explained-Architecture%C2%BF-Practice-Promise/dp/032119442X Source is essentially a model, bytecode is executed, not source Elaborationism options - subclassing (Java), merging (any structured text)"}}