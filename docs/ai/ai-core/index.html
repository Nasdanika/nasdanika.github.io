<!DOCTYPE html>
<html lang="EN">
  <head>
    <title>Core</title>
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootswatch/4.5.2/cerulean/bootstrap.min.css" id="nsd-bootstrap-theme-stylesheet"/>
    <meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/>
    <script src="https://code.jquery.com/jquery-3.3.1.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.1/dist/umd/popper.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.5.2/dist/js/bootstrap.min.js"></script>
    <meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Nasdanika-Models/html-app@master/gen/web-resources/css/app.css"/>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css"/>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jstree@3.3.11/dist/themes/default/style.min.css"/>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@5.7.0/github-markdown.min.css"/>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.9.0/build/styles/default.min.css"/>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-vue@2.23.0/dist/bootstrap-vue.css"/>
    <script src="https://cdn.jsdelivr.net/gh/Nasdanika-Models/html-app@master/gen/web-resources/js/common.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/Nasdanika-Models/html-app@master/gen/web-resources/js/dark-head.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/jstree@3.3.11/dist/jstree.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.9.0/build/highlight.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/vue@2.6.14/dist/vue.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap-vue@2.23.0/dist/bootstrap-vue.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/Nasdanika-Models/html-app@master/gen/web-resources/js/components/table.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/groovy.min.js"></script><!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-9BRJVLK8CC"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-9BRJVLK8CC');
</script>   

<!--  Start search configuration -->
<script src="../../search-documents.js"></script>

<script src="https://cdn.jsdelivr.net/gh/olivernn/lunr.js@v2.3.9/lunr.js"></script>

<script>
// Script for full-text search of JsTree

window.nsdJsTreeSearchCallback = function(str, node) { 
    var sf = new $.vakata.search(str, true, { caseSensitive : false, fuzzy : false }); 
    if (sf.search(node.text).isMatch) {
		return true;
	} 
    let searchResult = this.search(str); 
    for (const sr in searchResult) {
        if (searchResult[sr].ref === node.original['data-nsd-label-uuid']) {
            return true;
        } 
    } 
    return false; 
}.bind(lunr(function () {
			  this.ref('id');
			  this.field('title');
			  this.field('content');

			  for (const key in searchDocuments) {
				  let doc = searchDocuments[key];
				this.add({
					id: doc['link-uuid'],
					title: doc.title,
					path: doc.path,
					content: doc.content
				});  
			  }
			}));
</script>
<!-- End search configuration  -->
 
</head>
  <body>
    <div class="container-fluid nsd-app-container">
      <div class="row">
        <div class="col nsd-app-header">
          <a href="../../index.html" data-nsd-label-uuid="ed47e267-82b0-44bc-b514-46af92093e05" class="nsd-app-header-title">
            <img src="https://docs.nasdanika.org/images/nasdanika-logo.png" class="nsd-app-label-icon"/>Nasdanika</a>
          <ul class="nav nsd-app-header-navs">
            <li class="nav-item">
              <a href="../../search.html" data-nsd-label-uuid="b3143da8-4b55-4a97-907e-97f6867c8371" class="nav-link"><span class="fas fa-search nsd-app-label-icon"></span>Search</a>
            </li>
          </ul>
        </div>
      </div>
      <div class="row nsd-app-content-row">
        <div class="col nsd-app-navigation-panel">
          <div class="nsd-collapse-panel bg-light text-center"><span data-toggle="collapse" data-target="#nsd-nav-panel-baee7c73-07de-4f9c-890a-d7931bf5d2e6-collapsible" aria-expanded="true" aria-controls="nsd-nav-panel-baee7c73-07de-4f9c-890a-d7931bf5d2e6-collapsible" title="Toggle panel" id="nsd-nav-panel-baee7c73-07de-4f9c-890a-d7931bf5d2e6-collapsible-trigger" class="nsd-collapsible-trigger"><i aria-hidden="true" class="fa"></i></span>
          </div>
          <div id="nsd-nav-panel-baee7c73-07de-4f9c-890a-d7931bf5d2e6-collapsible" style="clear:right" class="nsd-collapsible collapse show">
            <input type="text" id="e1b391d0-4157-409f-8cc2-5fe850590a0d-navigation-panel_searchInput" title="Full-text search. You can use wildcards, e.g. 'foo*' or 'f*o'; title or content fields, e.g. 'title:foo* bar'; boosts, e.g. 'foo^10 bar'; fuzzy matches, e.g. 'foo~1'; and term presence, e.g. '+foo bar -baz'" class="form-control mt-1"/>
            <div id="e1b391d0-4157-409f-8cc2-5fe850590a0d-navigation-panel"></div>
            <script>$(document).ready( function() {
$('#e1b391d0-4157-409f-8cc2-5fe850590a0d-navigation-panel').jstree(function(tree) { tree.state.filter = function(state) { delete state.core.selected; return state; };  tree.search.search_callback = function(searchStr, node) { if (typeof window.nsdJsTreeSearchCallback === 'function') return window.nsdJsTreeSearchCallback(searchStr, node); var sf = new $.vakata.search(searchStr, true, { caseSensitive : false, fuzzy : false }); return sf.search(node.text).isMatch; }; return tree; }({"core":{"data":[{"a_attr":{"onclick":"window.location='https://github.com/Nasdanika-Knowledge';"},"children":[{"a_attr":{"onclick":"window.location='https://leanpub.com/beyond-diagrams';"},"icon":"fas fa-book","id":"nsd-app-nav-item-be1f4342-acc1-4da3-b12e-fbeff957347d","text":"Beyond Diagrams","type":"leaf"}],"icon":"/images/open-book.svg","id":"nsd-app-nav-item-b329c21d-c8b6-42fe-8d63-9aeb9c00283e","text":"Knowledge"},{"a_attr":{"onclick":"window.location='../../practices/index.html';"},"children":[{"a_attr":{"onclick":"window.location='../../practices/generic/index.html';"},"data-nsd-label-uuid":"42304545-f6fd-4d97-b333-6502f7a2aa9a","id":"nsd-app-nav-item-6eaf15a6-e5db-418c-85a0-c3114be4ddbf","text":"Analysis, Visualization & Generation","type":"leaf"},{"a_attr":{"onclick":"window.location='../../practices/java/index.html';"},"data-nsd-label-uuid":"15997dc8-3331-45cf-844f-ed177f881cfa","id":"nsd-app-nav-item-b3b486bf-3871-4ae5-8e49-baf6a2d73b5d","text":"Java Analysis, Visualization & Generation","type":"leaf"},{"a_attr":{"onclick":"window.location='../../practices/junit/index.html';"},"data-nsd-label-uuid":"e81e3e85-3505-4df9-9b7f-2463ab008356","id":"nsd-app-nav-item-c63d245f-0b6f-44e1-91b5-10b1d199450d","text":"JUnit Tests Generation","type":"leaf"}],"data-nsd-label-uuid":"c8c0c8c4-f2f9-4056-b567-3c4dfac2944f","id":"nsd-app-nav-item-799352b2-683f-4061-874a-2e22dee05bf2","text":"Practices"},{"a_attr":{"onclick":"window.location='../../nsd-cli/index.html';"},"children":[{"a_attr":{"onclick":"window.location='../../nsd-cli/nsd/index.html';"},"children":[{"a_attr":{"onclick":"window.location='../../nsd-cli/nsd/app/index.html';"},"children":[{"a_attr":{"onclick":"window.location='../../nsd-cli/nsd/app/site/index.html';"},"data-nsd-label-uuid":"66a39482-d05d-40d5-b916-5d69021a879b","id":"nsd-app-nav-item-07101e80-f3ff-448a-8b17-29c81ec9a174","text":"site","type":"leaf"}],"data-nsd-label-uuid":"b9d2c8a8-fb6c-4c8b-9608-348abb98f960","id":"nsd-app-nav-item-ce8e81fd-5e34-406f-aff4-eba6a5c70f5e","text":"app"},{"a_attr":{"onclick":"window.location='../../nsd-cli/nsd/drawio/index.html';"},"children":[{"a_attr":{"onclick":"window.location='../../nsd-cli/nsd/drawio/html-app/index.html';"},"children":[{"a_attr":{"onclick":"window.location='../../nsd-cli/nsd/drawio/html-app/crew-ai/index.html';"},"data-nsd-label-uuid":"0df35c7e-ff7b-4efd-9b53-eb41534a8355","icon":"https://crew-ai.models.nasdanika.org/images/crewai.svg","id":"nsd-app-nav-item-1ab78f86-1d60-47d5-9f42-6196cdfc7d3d","text":"crew-ai","type":"leaf"},{"a_attr":{"onclick":"window.location='../../nsd-cli/nsd/drawio/html-app/save/index.html';"},"data-nsd-label-uuid":"8b349766-6d53-447f-ba71-e5d30ef946cc","icon":"https://img.icons8.com/dusk/20/save--v1.png","id":"nsd-app-nav-item-05ae50ff-6b44-41b4-ada0-299279f71d7d","text":"save","type":"leaf"},{"a_attr":{"onclick":"window.location='../../nsd-cli/nsd/drawio/html-app/site/index.html';"},"data-nsd-label-uuid":"f8759e91-7d9f-4d70-ab39-a631987878ff","icon":"https://img.icons8.com/material-two-tone/20/web.png","id":"nsd-app-nav-item-66c7f57e-c95b-4fd2-8c5f-2285a5c56d98","text":"site","type":"leaf"}],"data-nsd-label-uuid":"2eca9ece-f4a3-4d33-90c9-67424348c895","icon":"https://docs.nasdanika.org/images/html-application.svg","id":"nsd-app-nav-item-3658eba9-2f71-42aa-8b5f-2b47c9479c4e","text":"html-app"},{"a_attr":{"onclick":"window.location='../../nsd-cli/nsd/drawio/http-server/index.html';"},"data-nsd-label-uuid":"749e814b-f457-4968-a28e-e041da3c11f0","icon":"https://docs.nasdanika.org/images/http.svg","id":"nsd-app-nav-item-b0182280-8991-4ae6-891a-fafa85fc6c9b","text":"http-server","type":"leaf"},{"a_attr":{"onclick":"window.location='../../nsd-cli/nsd/drawio/invoke/index.html';"},"data-nsd-label-uuid":"b29f7778-d077-4608-8814-f0537cb3c610","icon":"https://docs.nasdanika.org/images/automation.svg","id":"nsd-app-nav-item-530154e6-a6db-486b-8223-08b74e25e1be","text":"invoke","type":"leaf"}],"data-nsd-label-uuid":"a7b2f722-ea1e-45b9-b8b0-ddad4e905536","icon":"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAzMiAzMiI+PHJlY3QgeT0iMiIgeD0iMiIgd2lkdGg9IjI4IiByeD0iMS4xMiIgaGVpZ2h0PSIyOCIgZmlsbD0iI2YwODcwNSIvPjxwYXRoIGZpbGwtcnVsZT0iZXZlbm9kZCIgZmlsbD0iI2RmNmMwYyIgZD0ibTE2Ljg2MSA5LjE2OCAzLjAyLTMuMTg3IDEwLjExOSAxMC4xMTN2MTIuNzg2YTEuMTE5IDEuMTE5IDAgMCAxIC0xLjEyIDEuMTJoLTE3LjU2NGwtNS4zODUtNS40MDd6Ii8+PHBhdGggZmlsbD0iI2ZmZiIgZD0ibTI1LjI0IDE3Ljk2aC0zLjI5NGwtMy4wNzEtNS4zMmguMmExLjExOSAxLjExOSAwIDAgMCAxLjEyLTEuMTJ2LTQuNzZhMS4xMTkgMS4xMTkgMCAwIDAgLTEuMTItMS4xMmgtNi4xNTVhMS4xMTkgMS4xMTkgMCAwIDAgLTEuMTIgMS4xMnY0Ljc2YTEuMTE5IDEuMTE5IDAgMCAwIDEuMTIgMS4xMmguMjA1bC0zLjA3MSA1LjMyaC0zLjI5NGExLjExOSAxLjExOSAwIDAgMCAtMS4xMiAxLjEydjQuNzZhMS4xMTkgMS4xMTkgMCAwIDAgMS4xMiAxLjEyaDYuMTZhMS4xMTkgMS4xMTkgMCAwIDAgMS4xMi0xLjEydi00Ljc2YTEuMTE5IDEuMTE5IDAgMCAwIC0xLjEyLTEuMTJoLS45MjdsMy4wNzItNS4zMmgxLjg3bDMuMDcxIDUuMzJoLS45MjZhMS4xMTkgMS4xMTkgMCAwIDAgLTEuMTIgMS4xMnY0Ljc2YTEuMTE5IDEuMTE5IDAgMCAwIDEuMTIgMS4xMmg2LjE2YTEuMTE5IDEuMTE5IDAgMCAwIDEuMTItMS4xMnYtNC43NmExLjExOSAxLjExOSAwIDAgMCAtMS4xMi0xLjEyeiIvPjwvc3ZnPg==","id":"nsd-app-nav-item-bf485baa-c866-43cb-8db1-8e96509f0391","text":"drawio"},{"a_attr":{"onclick":"window.location='../../nsd-cli/nsd/gitlab/index.html';"},"children":[{"a_attr":{"onclick":"window.location='../../nsd-cli/nsd/gitlab/contribute/index.html';"},"children":[{"a_attr":{"onclick":"window.location='../../nsd-cli/nsd/gitlab/contribute/gsh/index.html';"},"data-nsd-label-uuid":"a843b2ca-43e8-4e2d-90e9-30a66d364d23","icon":"https://docs.nasdanika.org/images/command.svg","id":"nsd-app-nav-item-8a575f14-88b4-4049-a8bb-e7410a672d1c","text":"gsh","type":"leaf"},{"a_attr":{"onclick":"window.location='../../nsd-cli/nsd/gitlab/contribute/invoke/index.html';"},"data-nsd-label-uuid":"804a9544-7d72-4c08-8d9d-c12430cf0be9","icon":"https://docs.nasdanika.org/images/automation.svg","id":"nsd-app-nav-item-effa83f6-7053-4622-87f5-f322b20f52c4","text":"invoke","type":"leaf"},{"a_attr":{"onclick":"window.location='../../nsd-cli/nsd/gitlab/contribute/junit/index.html';"},"children":[{"a_attr":{"onclick":"window.location='../../nsd-cli/nsd/gitlab/contribute/junit/jacoco/index.html';"},"data-nsd-label-uuid":"88d17a6d-2210-42c7-82e4-b9e8cc2031f9","id":"nsd-app-nav-item-ed4adff7-2d1e-4e4d-aae4-904c91087037","text":"jacoco","type":"leaf"}],"data-nsd-label-uuid":"3b0029a1-9a24-459e-82e4-e5ca8b508119","icon":"https://docs.nasdanika.org/images/JUnit.svg","id":"nsd-app-nav-item-58e444ad-e250-4211-a790-d4d4ceb7a4ba","text":"junit"},{"a_attr":{"onclick":"window.location='../../nsd-cli/nsd/gitlab/contribute/retrospect/index.html';"},"children":[{"a_attr":{"onclick":"window.location='../../nsd-cli/nsd/gitlab/contribute/retrospect/gsh/index.html';"},"data-nsd-label-uuid":"4947c8b9-adaf-4f8e-b873-31313824c03c","icon":"https://docs.nasdanika.org/images/command.svg","id":"nsd-app-nav-item-c33ff77c-a978-40dc-a828-6d93a38effa4","text":"gsh","type":"leaf"},{"a_attr":{"onclick":"window.location='../../nsd-cli/nsd/gitlab/contribute/retrospect/invoke/index.html';"},"data-nsd-label-uuid":"c9110f2e-bffa-4e97-a079-e55448b82657","icon":"https://docs.nasdanika.org/images/automation.svg","id":"nsd-app-nav-item-ff2473f3-40e2-4d71-98a7-f9144f32d5cf","text":"invoke","type":"leaf"}],"data-nsd-label-uuid":"106d64d5-b281-48ed-96e6-450cb5993b34","icon":"https://docs.nasdanika.org/images/retrospective.svg","id":"nsd-app-nav-item-b9b97917-cab0-4748-8ea3-5d32eff59dfe","text":"retrospect"}],"data-nsd-label-uuid":"309bc611-ad0b-490a-94e1-f55f9f51830e","icon":"https://docs.nasdanika.org/images/jigsaw.svg","id":"nsd-app-nav-item-8a2cf952-9b69-4bfb-80a7-fcdaaf83bdb1","text":"contribute"},{"a_attr":{"onclick":"window.location='../../nsd-cli/nsd/gitlab/gsh/index.html';"},"data-nsd-label-uuid":"b07cb610-e16d-4f71-9f17-7dbf8f2608b0","icon":"https://docs.nasdanika.org/images/command.svg","id":"nsd-app-nav-item-cdc31f49-2ea8-4cd9-8d65-79b7f562fcae","text":"gsh","type":"leaf"},{"a_attr":{"onclick":"window.location='../../nsd-cli/nsd/gitlab/invoke/index.html';"},"data-nsd-label-uuid":"10d4baa2-408b-4d04-9290-774cab61d2e1","icon":"https://docs.nasdanika.org/images/automation.svg","id":"nsd-app-nav-item-26a4528c-4fdc-4caf-b928-f072eb155c2b","text":"invoke","type":"leaf"}],"data-nsd-label-uuid":"beb03fef-b113-490f-92cd-374949b87612","icon":"https://docs.nasdanika.org/images/GitLab.svg","id":"nsd-app-nav-item-35e281be-1132-4172-95a9-3de5db48947f","text":"gitlab"},{"a_attr":{"onclick":"window.location='../../nsd-cli/nsd/gsh/index.html';"},"data-nsd-label-uuid":"6d2ee526-eacc-4f44-b51d-2845603eabe3","icon":"https://docs.nasdanika.org/images/command.svg","id":"nsd-app-nav-item-7487b372-0e87-48e8-bc7f-21606263e43f","text":"gsh","type":"leaf"},{"a_attr":{"onclick":"window.location='../../nsd-cli/nsd/help/index.html';"},"children":[{"a_attr":{"onclick":"window.location='../../nsd-cli/nsd/help/site/index.html';"},"data-nsd-label-uuid":"367c0809-b28d-4fec-b6d1-d547caf233e5","icon":"https://img.icons8.com/material-two-tone/20/web.png","id":"nsd-app-nav-item-cf9c912f-e7c4-4aec-b678-1885bf6d5a02","text":"site","type":"leaf"}],"data-nsd-label-uuid":"e9e2dc4e-059a-4557-b908-2189244dbc25","icon":"far fa-question-circle","id":"nsd-app-nav-item-c87f1314-14bd-470a-a8f6-d671f4edd161","text":"help"},{"a_attr":{"onclick":"window.location='../../nsd-cli/nsd/http-server/index.html';"},"data-nsd-label-uuid":"7957477e-3166-49be-944b-76476232151f","icon":"https://docs.nasdanika.org/images/http.svg","id":"nsd-app-nav-item-f20e7921-3395-4898-b7d7-60bb737d9759","text":"http-server","type":"leaf"},{"a_attr":{"onclick":"window.location='../../nsd-cli/nsd/invoke/index.html';"},"data-nsd-label-uuid":"685c4f1d-b36f-4785-98ab-4710f67ed536","icon":"https://docs.nasdanika.org/images/automation.svg","id":"nsd-app-nav-item-4e07efda-f1c1-4705-a9a7-e26644ec5243","text":"invoke","type":"leaf"},{"a_attr":{"onclick":"window.location='../../nsd-cli/nsd/java/index.html';"},"children":[{"a_attr":{"onclick":"window.location='../../nsd-cli/nsd/java/junit/index.html';"},"children":[{"a_attr":{"onclick":"window.location='../../nsd-cli/nsd/java/junit/jacoco/index.html';"},"data-nsd-label-uuid":"15c7f76c-8b9b-4726-8227-1e34de1f1919","id":"nsd-app-nav-item-082ac55f-7cf2-4d80-bba9-8cefd5ebf87d","text":"jacoco","type":"leaf"}],"data-nsd-label-uuid":"a477df9d-b9ad-4a37-a98b-e039a5f82de9","icon":"https://docs.nasdanika.org/images/JUnit.svg","id":"nsd-app-nav-item-c89a332c-eb36-4f40-9ecd-d38ec2a7c998","text":"junit"}],"data-nsd-label-uuid":"e22834db-15ff-4aba-97bc-8b03179cc330","icon":"https://docs.nasdanika.org/images/java.svg","id":"nsd-app-nav-item-9be4990b-465f-4b53-8f6f-8110f55867fd","text":"java"},{"a_attr":{"onclick":"window.location='../../nsd-cli/nsd/launcher/index.html';"},"data-nsd-label-uuid":"8e262e33-5c4f-4830-b97e-3cf6bb19a7bb","id":"nsd-app-nav-item-ec1456bd-26b7-44de-ba08-b2cfcee4ab82","text":"launcher","type":"leaf"},{"a_attr":{"onclick":"window.location='../../nsd-cli/nsd/model/index.html';"},"children":[{"a_attr":{"onclick":"window.location='../../nsd-cli/nsd/model/crew-ai/index.html';"},"data-nsd-label-uuid":"81639bbd-3935-4ce3-aa0a-990c73493503","icon":"https://crew-ai.models.nasdanika.org/images/crewai.svg","id":"nsd-app-nav-item-9344f64d-48e4-4018-8000-fb2430269d50","text":"crew-ai","type":"leaf"},{"a_attr":{"onclick":"window.location='../../nsd-cli/nsd/model/html-app/index.html';"},"children":[{"a_attr":{"onclick":"window.location='../../nsd-cli/nsd/model/html-app/crew-ai/index.html';"},"data-nsd-label-uuid":"ccbfc467-1c67-4ca2-8f9d-38826f4dd463","icon":"https://crew-ai.models.nasdanika.org/images/crewai.svg","id":"nsd-app-nav-item-8c728783-7cd5-4c73-afd4-56fc6a1cec9f","text":"crew-ai","type":"leaf"},{"a_attr":{"onclick":"window.location='../../nsd-cli/nsd/model/html-app/save/index.html';"},"data-nsd-label-uuid":"2952af85-8e4f-4e78-a330-55c1c3df2ed7","icon":"https://img.icons8.com/dusk/20/save--v1.png","id":"nsd-app-nav-item-fba83d47-77b1-4303-831c-429facfc92d9","text":"save","type":"leaf"},{"a_attr":{"onclick":"window.location='../../nsd-cli/nsd/model/html-app/site/index.html';"},"data-nsd-label-uuid":"861e3a66-c9b6-4cc8-bd89-e20c68342804","icon":"https://img.icons8.com/material-two-tone/20/web.png","id":"nsd-app-nav-item-88fbcd34-34cd-418f-9fe7-b66671757453","text":"site","type":"leaf"}],"data-nsd-label-uuid":"b4588911-9c71-4389-a0b8-58bdbe780432","icon":"https://docs.nasdanika.org/images/html-application.svg","id":"nsd-app-nav-item-0cb11b9c-dbdb-4dc8-9c1e-bf4ece26b79a","text":"html-app"},{"a_attr":{"onclick":"window.location='../../nsd-cli/nsd/model/save/index.html';"},"data-nsd-label-uuid":"51821baf-2704-4001-9810-129c17173b77","icon":"https://img.icons8.com/dusk/20/save--v1.png","id":"nsd-app-nav-item-6335b884-7b9a-4c7a-b5c4-84190f6c2e2f","text":"save","type":"leaf"}],"data-nsd-label-uuid":"eec0f413-50da-41fe-a9a3-7264cbf69b3e","icon":"https://docs.nasdanika.org/images/model.svg","id":"nsd-app-nav-item-695d42d1-3a3a-4195-8d25-e94bd9a51f3b","text":"model"},{"a_attr":{"onclick":"window.location='../../nsd-cli/nsd/rules/index.html';"},"children":[{"a_attr":{"onclick":"window.location='../../nsd-cli/nsd/rules/action-model/index.html';"},"data-nsd-label-uuid":"ceb33ab3-5437-43c4-b54b-8317dba34c7f","id":"nsd-app-nav-item-1175c326-a717-45d6-8a22-a02189fdec58","text":"action-model","type":"leaf"},{"a_attr":{"onclick":"window.location='../../nsd-cli/nsd/rules/list/index.html';"},"data-nsd-label-uuid":"7edb8ea7-e915-416b-a65b-d1f594ea6b8e","id":"nsd-app-nav-item-ea54d0a7-ec32-459f-ba75-b14605df6656","text":"list","type":"leaf"},{"a_attr":{"onclick":"window.location='../../nsd-cli/nsd/rules/site/index.html';"},"data-nsd-label-uuid":"4c983069-3495-4351-ab3f-28a4bebc9868","id":"nsd-app-nav-item-91d2ae43-de35-4f6a-896d-c3736d0a6a2d","text":"site","type":"leaf"}],"data-nsd-label-uuid":"0ea49770-1cbf-4e0c-aaba-a06253e205c3","icon":"https://docs.nasdanika.org/images/rules.svg","id":"nsd-app-nav-item-08d3a53b-201e-466e-85d2-490cb8dd048a","text":"rules"},{"a_attr":{"onclick":"window.location='../../nsd-cli/nsd/shell/index.html';"},"data-nsd-label-uuid":"f7541e92-8bf1-4700-9ee9-cf0137bfa65c","icon":"https://img.icons8.com/nolan/20/console.png","id":"nsd-app-nav-item-5b6cd200-ab71-4918-9200-c74bef5e8cef","text":"shell","type":"leaf"}],"data-nsd-label-uuid":"73d3bd1d-45d1-43d9-8bb6-cda707773256","id":"nsd-app-nav-item-c4f5b6d0-55c3-4a9e-9e53-2ff4f15cb91c","text":"nsd"}],"data-nsd-label-uuid":"6be48711-4f91-49de-a397-97d55b820bfa","icon":"/images/command-line.svg","id":"nsd-app-nav-item-48a8a637-91a8-4d15-9905-60540d04940a","text":"CLI"},{"a_attr":{"onclick":"window.location='../index.html';"},"children":[{"a_attr":{"onclick":"window.location='../ai-cli/index.html';"},"data-nsd-label-uuid":"d318148a-8af9-4b4e-bd8d-731c20f03524","icon":"/images/command-line.svg","id":"nsd-app-nav-item-346cb1bd-274c-437a-bfc7-b55b399e932c","text":"CLI","type":"leaf"},{"data-nsd-label-uuid":"d0c079fc-b0ae-497a-a957-8e0145306b81","icon":"/images/geology.svg","state":{"selected":true},"id":"nsd_4gp","text":"Core","type":"leaf"},{"a_attr":{"onclick":"window.location='../ai-drawio/index.html';"},"data-nsd-label-uuid":"8812f932-ea21-4c11-81c7-8908bba30c34","icon":"/images/drawio.svg","id":"nsd-app-nav-item-e6e0f033-9b89-46e5-b84e-b2b5151f9080","text":"Drawio","type":"leaf"},{"a_attr":{"onclick":"window.location='../ai-emf/index.html';"},"data-nsd-label-uuid":"c749eb39-d664-432a-bc7a-f7d2f2611143","icon":"/images/diagram.svg","id":"nsd-app-nav-item-89a2fc66-b26e-4a27-a59a-69d2e1ffd6ed","text":"EMF","type":"leaf"},{"a_attr":{"onclick":"window.location='../mcp/index.html';"},"data-nsd-label-uuid":"a5d4c8c1-bc8e-4926-8bf5-ca8d7d3b8b28","icon":"/images/mcp.png","id":"nsd-app-nav-item-663e390e-d583-449d-b03a-d4d6accb0cc9","text":"MCP","type":"leaf"},{"a_attr":{"onclick":"window.location='../ollama/index.html';"},"data-nsd-label-uuid":"0034efb2-3a63-459e-9202-f3c962dded57","icon":"/images/ollama.png","id":"nsd-app-nav-item-82c04a14-4099-493f-8d6f-6a592bedb5a6","text":"Ollama","type":"leaf"},{"a_attr":{"onclick":"window.location='../open-ai/index.html';"},"data-nsd-label-uuid":"e2dec3f2-4201-4137-b041-7fb2bdc443d5","icon":"/images/chat-gpt.svg","id":"nsd-app-nav-item-4f2308e3-171c-402b-bc0b-e0a47ce258b5","text":"OpenAI","type":"leaf"}],"data-nsd-label-uuid":"df98f282-40c9-4841-95e0-30d28a1f0fee","icon":"/images/ai.svg","id":"nsd-app-nav-item-da22ea28-b4e3-4e78-9ebd-17d3633665b7","text":"AI"},{"a_attr":{"onclick":"window.location='../../models/index.html';"},"children":[{"a_attr":{"onclick":"window.location='https://a2a.models.nasdanika.org/index.html';"},"id":"nsd-app-nav-item-b7cddac4-3df5-47f4-9741-2be98424ebd6","text":"A2a","type":"leaf"},{"a_attr":{"onclick":"window.location='https://html-app.models.nasdanika.org/index.html';"},"id":"nsd-app-nav-item-1a93f21c-dffb-4fa0-8575-3c4d29f47047","text":"App","type":"leaf"},{"a_attr":{"onclick":"window.location='https://architecture.models.nasdanika.org/index.html';"},"id":"nsd-app-nav-item-11629e4c-8719-435a-aab0-bb21408d090e","text":"Architecture","type":"leaf"},{"a_attr":{"onclick":"window.location='https://azure.models.nasdanika.org';"},"id":"nsd-app-nav-item-8749ff82-fcb9-4417-aff2-8857b454945c","text":"Azure","type":"leaf"},{"a_attr":{"onclick":"window.location='https://bank.models.nasdanika.org';"},"id":"nsd-app-nav-item-9b69e409-2e9c-4985-b316-27bada46565f","text":"Bank","type":"leaf"},{"a_attr":{"onclick":"window.location='https://bootstrap.models.nasdanika.org';"},"id":"nsd-app-nav-item-28e69545-1664-44da-8e88-fe79f6ee9c81","text":"Bootstrap","type":"leaf"},{"a_attr":{"onclick":"window.location='https://capability.models.nasdanika.org';"},"id":"nsd-app-nav-item-19ff1f08-a456-4f4f-aa53-6080b5e4cb85","text":"Capability","type":"leaf"},{"a_attr":{"onclick":"window.location='https://coverage.models.nasdanika.org';"},"id":"nsd-app-nav-item-486e8c26-8f99-4c94-9592-96cb5f9a266d","text":"Coverage","type":"leaf"},{"a_attr":{"onclick":"window.location='https://crew-ai.models.nasdanika.org';"},"id":"nsd-app-nav-item-1030fec9-f103-479e-9e8d-d143c4b77158","text":"CrewAI","type":"leaf"},{"a_attr":{"onclick":"window.location='https://mcda.models.nasdanika.org';"},"id":"nsd-app-nav-item-08b5c63d-415e-499b-b817-1f129c7fc925","text":"Decision Analysis","type":"leaf"},{"a_attr":{"onclick":"window.location='https://echarts.models.nasdanika.org/graph';"},"id":"nsd-app-nav-item-9d25e6fc-6f15-4016-a3b7-e87734071114","text":"ECharts Graph","type":"leaf"},{"a_attr":{"onclick":"window.location='https://ecore.models.nasdanika.org';"},"id":"nsd-app-nav-item-a8eb3e80-c2c9-40c0-b3bc-aca988549a08","text":"Ecore","type":"leaf"},{"a_attr":{"onclick":"window.location='https://enterprise.models.nasdanika.org';"},"id":"nsd-app-nav-item-cbfc39a8-dd97-4a35-8342-6eb3d2ce8196","text":"Enterprise","type":"leaf"},{"a_attr":{"onclick":"window.location='https://excel.models.nasdanika.org';"},"id":"nsd-app-nav-item-b425c33b-506a-4809-a8ac-64c2c839a1d6","text":"Excel","type":"leaf"},{"a_attr":{"onclick":"window.location='https://family.models.nasdanika.org';"},"id":"nsd-app-nav-item-08009ba4-30ed-4b93-b093-67fe77e89f32","text":"Family","type":"leaf"},{"a_attr":{"onclick":"window.location='https://flow.models.nasdanika.org';"},"id":"nsd-app-nav-item-b1af32ed-5b0c-4775-9946-381206df1bdd","text":"Flow","type":"leaf"},{"a_attr":{"onclick":"window.location='https://function-flow.models.nasdanika.org';"},"id":"nsd-app-nav-item-6ac2ed70-3954-404d-bce7-3b667a8449bb","text":"Function Flow","type":"leaf"},{"a_attr":{"onclick":"window.location='https://git.models.nasdanika.org';"},"id":"nsd-app-nav-item-a936d99e-d1bc-4c1e-86bd-8b42055226ad","text":"Git","type":"leaf"},{"a_attr":{"onclick":"window.location='https://gitlab.models.nasdanika.org';"},"id":"nsd-app-nav-item-a94501d2-1d5a-48e1-acea-5e83cd18e549","text":"GitLab","type":"leaf"},{"a_attr":{"onclick":"window.location='https://graph.models.nasdanika.org';"},"id":"nsd-app-nav-item-9b77257f-e090-472b-bcee-f546a0f95f57","text":"Graph","type":"leaf"},{"a_attr":{"onclick":"window.location='https://html.models.nasdanika.org';"},"id":"nsd-app-nav-item-03b31aeb-834b-475b-8cbe-152a1b86a688","text":"HTML","type":"leaf"},{"a_attr":{"onclick":"window.location='https://java.models.nasdanika.org';"},"id":"nsd-app-nav-item-966b5dd0-35a5-40d4-867e-7d2c448d2a53","text":"Java","type":"leaf"},{"a_attr":{"onclick":"window.location='https://jira.models.nasdanika.org';"},"id":"nsd-app-nav-item-cc1151a5-e0e8-450f-8e60-2320929480fa","text":"Jira","type":"leaf"},{"a_attr":{"onclick":"window.location='https://maven.models.nasdanika.org';"},"id":"nsd-app-nav-item-a658dbdf-d4f1-49a6-8bc4-8cc77bdc9cfe","text":"Maven","type":"leaf"},{"a_attr":{"onclick":"window.location='https://nature.models.nasdanika.org';"},"id":"nsd-app-nav-item-d01fa786-88cf-47a9-a6d3-6b7d7bc7c403","text":"Nature","type":"leaf"},{"a_attr":{"onclick":"window.location='https://pdf.models.nasdanika.org';"},"id":"nsd-app-nav-item-993f76ba-8b23-4acd-b6ac-1dbf59f0e19a","text":"PDF","type":"leaf"},{"a_attr":{"onclick":"window.location='https://party.models.nasdanika.org';"},"id":"nsd-app-nav-item-3d48deb0-21d2-4e24-ad7c-ab260ef9e08a","text":"Party","type":"leaf"},{"a_attr":{"onclick":"window.location='https://python.models.nasdanika.org';"},"id":"nsd-app-nav-item-9ce2f209-481b-45d0-8e2a-5a032777c3c4","text":"Python","type":"leaf"},{"a_attr":{"onclick":"window.location='https://rules.models.nasdanika.org';"},"id":"nsd-app-nav-item-1cca0d66-5be4-4151-8ff4-2abc8e636462","text":"Rules","type":"leaf"},{"a_attr":{"onclick":"window.location='https://source-engineering.models.nasdanika.org';"},"id":"nsd-app-nav-item-be09e307-34e3-4963-a26d-e84e94ae1881","text":"Source Engineering","type":"leaf"}],"data-nsd-label-uuid":"20bc9746-0732-4b03-ac67-087b66458b1b","id":"nsd-app-nav-item-3037ed18-0929-451d-b973-c4918bf3faf6","text":"Models"},{"a_attr":{"onclick":"window.location='../../html/index.html';"},"children":[{"a_attr":{"onclick":"window.location='../../html/3d-force-graph/index.html';"},"data-nsd-label-uuid":"4d84e43b-9314-46b3-9445-579c2618ade6","id":"nsd-app-nav-item-cb26c6e9-da33-463c-bc8f-e552f8f95723","text":"3D Force Graph","type":"leaf"},{"a_attr":{"onclick":"window.location='../../html/alpine-js/index.html';"},"data-nsd-label-uuid":"1b5f9e7b-b8cb-4f2a-a4fb-3984f72a071d","id":"nsd-app-nav-item-dea999bd-6ae4-4b0b-b816-edf0dd45ba33","text":"AlpineJS","type":"leaf"},{"a_attr":{"onclick":"window.location='../../html/bootstrap/index.html';"},"data-nsd-label-uuid":"f03b73bc-c8d8-402e-b322-d75a392146e2","id":"nsd-app-nav-item-051a6e0d-f9d8-4558-bc6a-737db37768eb","text":"Bootstrap","type":"leaf"},{"a_attr":{"onclick":"window.location='../../html/html-graph/index.html';"},"data-nsd-label-uuid":"8d52d958-14ef-4a27-a736-f3c97aeef15b","id":"nsd-app-nav-item-f84f5bb4-f9f6-4a53-b841-32068ec0b57b","text":"Graph","type":"leaf"},{"a_attr":{"onclick":"window.location='../../html/html/index.html';"},"data-nsd-label-uuid":"4ed2b0d2-c0be-46bf-826b-34ad23513bd1","id":"nsd-app-nav-item-1e751c7a-0668-48bd-853d-7b94cfbb6811","text":"HTML","type":"leaf"},{"a_attr":{"onclick":"window.location='../../html/jstree/index.html';"},"data-nsd-label-uuid":"5045ab61-d679-4e19-aa30-eb291c537b47","id":"nsd-app-nav-item-2c59d7d1-337c-4125-801f-cf03008d722f","text":"JsTree","type":"leaf"}],"data-nsd-label-uuid":"fd56a99b-699b-49db-b81b-1367e80e11fe","icon":"/images/html.svg","id":"nsd-app-nav-item-30b5ca28-eeff-4f90-8dcc-32d067a88d96","text":"HTML"},{"a_attr":{"onclick":"window.location='../../core/index.html';"},"children":[{"a_attr":{"onclick":"window.location='../../core/cli/index.html';"},"data-nsd-label-uuid":"ca312265-7cf5-4492-9ea7-a5d3b694c026","icon":"/images/command-line.svg","id":"nsd-app-nav-item-f722ebbb-8930-4f38-9a89-df6dc1c203fa","text":"CLI","type":"leaf"},{"a_attr":{"onclick":"window.location='../../core/capability/index.html';"},"data-nsd-label-uuid":"45c85f73-4e82-4691-ae77-420876c4573b","id":"nsd-app-nav-item-30c3bf20-9fab-4d9c-8ef1-a1d631a234bd","text":"Capability","type":"leaf"},{"a_attr":{"onclick":"window.location='../../core/common/index.html';"},"data-nsd-label-uuid":"60647384-4a99-4697-886a-85e1483f3f43","id":"nsd-app-nav-item-4109a9e9-90df-4ab6-961c-bd1625feb1f3","text":"Common","type":"leaf"},{"a_attr":{"onclick":"window.location='../../core/diagram/index.html';"},"data-nsd-label-uuid":"7bc59b5f-37b1-4073-be5e-b0de0c4331ef","id":"nsd-app-nav-item-68d2e1f5-0cb6-4ca0-9580-6c919edb4782","text":"Diagram","type":"leaf"},{"a_attr":{"onclick":"window.location='../../core/drawio/index.html';"},"data-nsd-label-uuid":"1396b84f-2f4b-4973-baea-f0fe63f7faf9","id":"nsd-app-nav-item-1e91abdc-8353-4716-b5fb-fc779d9bf1c6","text":"Drawio","type":"leaf"},{"a_attr":{"onclick":"window.location='../../core/emf/index.html';"},"data-nsd-label-uuid":"9b02c068-f5e0-45cf-bd56-443659cabbf8","id":"nsd-app-nav-item-66cbcff9-0212-47cb-81fb-e2573a6df0f1","text":"EMF","type":"leaf"},{"a_attr":{"onclick":"window.location='../../core/exec/index.html';"},"data-nsd-label-uuid":"cecae1d4-4f6a-4b4e-818e-e7a7e34cda99","id":"nsd-app-nav-item-17fcfc8a-021a-46b2-869d-717954f654eb","text":"Exec","type":"leaf"},{"a_attr":{"onclick":"window.location='../../core/graph/index.html';"},"data-nsd-label-uuid":"af453f58-9488-4a10-b997-d66486454424","icon":"/images/data-flow.svg","id":"nsd-app-nav-item-48939814-0789-4c89-8bd5-3cf1b81395df","text":"Graph","type":"leaf"},{"a_attr":{"onclick":"window.location='../../core/http/index.html';"},"data-nsd-label-uuid":"131cede4-156d-4a60-adf3-3412fa3a01ec","icon":"/images/http.svg","id":"nsd-app-nav-item-7601d922-a07e-474a-9863-8dbaf6de0afa","text":"HTTP","type":"leaf"},{"a_attr":{"onclick":"window.location='../../core/mapping/index.html';"},"data-nsd-label-uuid":"4077d9a6-dbbe-4315-b103-369e350e7d28","icon":"/images/mapping.svg","id":"nsd-app-nav-item-eee574ae-1ab3-49ad-8859-c3fe3d467978","text":"Mapping","type":"leaf"},{"a_attr":{"onclick":"window.location='../../core/maven/index.html';"},"data-nsd-label-uuid":"d3c39546-450a-46a1-b69c-2c6b33fe42fe","id":"nsd-app-nav-item-bc0bcccc-4d09-4947-befc-ec6423c7e8d9","text":"Maven","type":"leaf"},{"a_attr":{"onclick":"window.location='https://ncore.models.nasdanika.org/';"},"id":"nsd-app-nav-item-b1f2a086-b9f0-4672-89cb-97b99f274f7e","text":"Ncore","type":"leaf"},{"a_attr":{"onclick":"window.location='../../core/persistence/index.html';"},"data-nsd-label-uuid":"e8246b61-8ea1-4151-94f3-120877ce38ca","id":"nsd-app-nav-item-6f0ed934-5221-442f-8de7-b52c8d769f4f","text":"Persistence","type":"leaf"},{"a_attr":{"onclick":"window.location='../../core/resources/index.html';"},"data-nsd-label-uuid":"857cae6d-495a-41b3-be19-47cb0461c4fc","id":"nsd-app-nav-item-fdfb2745-48f7-45c9-8846-9bfccd0dcb20","text":"Resources","type":"leaf"},{"a_attr":{"onclick":"window.location='../../core/telemetry/index.html';"},"data-nsd-label-uuid":"fafa8b99-f7fd-492b-86f2-0cba131271c8","icon":"/images/OpenTelemetry.svg","id":"nsd-app-nav-item-76ca338b-7565-4814-a6cb-84ee39bd9e6b","text":"Telemetry","type":"leaf"}],"data-nsd-label-uuid":"50216494-e9ba-4aab-9b30-fdf71823a581","icon":"/images/earth.svg","id":"nsd-app-nav-item-67ee6d76-3492-4d8b-a1ba-b555ea059fe1","text":"Core"}]},"search":{"show_only_matches":true,"show_only_matches_children":true},"types":{"leaf":{"icon":"jstree-file"}},"plugins":["state","type","search"],"state":{"key":"e1b391d0-4157-409f-8cc2-5fe850590a0d-navigation-panel"}}));
// Tokens: searchInputSelector, timer, treeSelector
$('#e1b391d0-4157-409f-8cc2-5fe850590a0d-navigation-panel_searchInput').keyup(function () {
    if (window['nsd_jstTreeSearchTimer_nsd_4ie']) { 
		clearTimeout(window['nsd_jstTreeSearchTimer_nsd_4ie']); 
	}
    window['nsd_jstTreeSearchTimer_nsd_4ie'] = setTimeout(function () {
      var v = $('#e1b391d0-4157-409f-8cc2-5fe850590a0d-navigation-panel_searchInput').val();
      $('#e1b391d0-4157-409f-8cc2-5fe850590a0d-navigation-panel').jstree(true).search(v);
    }, 250);
  });

});</script>
          </div>
        </div>
        <div data-nsd-label-uuid="d0c079fc-b0ae-497a-a957-8e0145306b81" data-nsd-action-uris="uuid:d0c079fc-b0ae-497a-a957-8e0145306b81" class="col nsd-app-content-panel">
          <div class="container-fluid">
            <div class="row nsd-app-content-panel-breadcrumb-row">
              <div class="col">
                <nav aria-label="breadcrumb" class="nsd-app-content-panel-breadcrumb">
                  <ol class="breadcrumb">
                    <li class="breadcrumb-item">
                      <a href="../index.html" data-nsd-label-uuid="df98f282-40c9-4841-95e0-30d28a1f0fee">
                        <img src="/images/ai.svg" class="nsd-app-label-icon"/>AI</a>
                    </li>
                    <li class="breadcrumb-item active"><span data-nsd-label-uuid="d0c079fc-b0ae-497a-a957-8e0145306b81"><img src="/images/geology.svg" class="nsd-app-label-icon"/>Core</span>
                    </li>
                  </ol>
                </nav>
              </div>
            </div>
            <div class="row nsd-app-content-panel-title-and-items-row">
              <div class="col-auto">
                <H1><span data-nsd-label-uuid="d0c079fc-b0ae-497a-a957-8e0145306b81" class="nsd-app-content-panel-title"><img src="/images/geology.svg" class="nsd-app-label-icon"/>Core</span>
                </H1>
              </div>
            </div>
            <div class="row nsd-app-content-panel-content-row">
              <div class="col">
                <div class="container-fluid">
                  <div class="row">
                    <div class="col"><div class="markdown-body"><p>This module provides AI interfaces implemented by provider modules such as <a href="../open-ai/index.html">OpenAI</a> and <a href="../ollama/index.html">Ollama</a>. It also provides classes and interfaces for building similarity search and RAG solutions.</p>
<ul>
<li><a href="https://github.com/Nasdanika/ai/tree/main/core">Sources</a></li>
<li><a href="https://javadoc.io/doc/org.nasdanika.ai/core">Javadoc</a></li>
</ul>
<p>See <a href="https://github.com/Nasdanika/ai/blob/main/tests/src/test/java/org/nasdanika/ai/openai/tests/tests/TestAI.java">test sources</a> for examples of using Nasdanika AI classes.</p>
<ul>
<li><a href="#embeddings">Embeddings</a>
<ul>
<li><a href="#text">Text</a>
<ul>
<li><a href="#generation">Generation</a>
<ul>
<li><a href="#synchronous">Synchronous</a>
<ul>
<li><a href="#with-telemetry">With telemetry</a></li>
<li><a href="#all-providers-and-models"># All providers and models</a></li>
<li><a href="#a-specific-provider"># A specific provider</a></li>
</ul>
</li>
<li><a href="#asynchronous">Asynchronous</a>
<ul>
<li><a href="#with-telemetry">With telemetry</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#chunking">Chunking</a></li>
<li><a href="#embeddings-resource">Embeddings resource</a></li>
</ul>
</li>
<li><a href="#images">Images</a>
<ul>
<li><a href="#narrate-describe-image">Narrate (describe) image</a></li>
</ul>
</li>
<li><a href="#caching">Caching</a>
<ul>
<li><a href="#cachingimagenarrator">CachingImageNarrator</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#similarity">Similarity</a>
<ul>
<li><a href="#computing">Computing</a></li>
<li><a href="#search">Search</a></li>
</ul>
</li>
<li><a href="#chat">Chat</a>
<ul>
<li><a href="#with-telemetery">With telemetery</a></li>
<li><a href="#retrieval-augmented-generation-rag">Retrieval-augmented generation (RAG)</a></li>
</ul>
</li>
</ul>
<h2><a href="#embeddings" id="embeddings">Embeddings</a></h2>
<p>In <a href="https://en.wikipedia.org/wiki/Machine_learning">machine learning</a> <a href="https://en.wikipedia.org/wiki/Embedding_(machine_learning)">embedding</a> is</p>
<blockquote>
<p>a <a href="https://en.wikipedia.org/wiki/Feature_learning">representation learning</a> technique that maps complex, high-dimensional data into a lower-dimensional <a href="https://en.wikipedia.org/wiki/Vector_space">vector space</a> of numerical vectors</p>
</blockquote>
<p>Here the word embedding is used in more <a href="https://en.wikipedia.org/wiki/Embedding">mathematical sense</a> - <a href="https://en.wikipedia.org/wiki/Dimensionality_reduction">dimensionality</a> with structure preservation.</p>
<p>Below are a few examples of embeddings:</p>
<ul>
<li>Vector embeddings of text or images</li>
<li>Textual description of an image, <a href="../ai-drawio/index.html">diagram</a>, or another complext structure such as a <a href="../../core/graph/index.html">graph</a> or <a href="../ai-emf/index.html">Ecore model</a>.</li>
<li>Text summary</li>
</ul>
<p>With extended definition embedding generation can be chained. Examples:</p>
<ul>
<li>image -&gt; text -&gt; vector</li>
<li>(PDF) document, diagram or other complex structure -&gt; text and images -&gt; combine text with image descriptions -&gt; vector</li>
</ul>
<p>In this module <code>EmbeddingGenerator&lt;S,E&gt;</code> is the base interface for generating embeddings. Is has multiple sub-interfaces and implementations. It has the following methods:</p>
<ul>
<li><code>Mono&lt;E&gt; generateAsync(S)</code> - generates an embedding of type <code>E</code> from source <code>S</code> asynchronously/reactively. This is the only method of the interface which has to be implemented - the other methods have default implementations.</li>
<li><code>E generate(S)</code> - generates an embedding synchronously.</li>
<li><code>Mono&lt;Map&lt;S,E&gt;&gt; generateAsync(List&lt;S&gt;)</code> - asynchronous batch generation. For example, generation of vectors for text chunks.</li>
<li><code>Map&lt;S,E&gt; generate(List&lt;S&gt;)</code> - synchronous batch generation. The default implementation calls generateAsync().block(), so actual processing is asynchronous.</li>
<li><code>&lt;F&gt; EmbeddingGenerator&lt;S,F&gt; then(EmbeddingGenerator&lt;E,F&gt; next)</code> - combines two generators. For example, image narrator with text vector generator.</li>
<li><code>&lt;V&gt; EmbeddingGenerator&lt;V,E&gt; adapt(Function&lt;V,Mono&lt;S&gt;&gt; mapper)</code> - adapts this generator to another source type using a mapper function. For example, image embedding generator can be adapted to input stream embedding generator.</li>
</ul>
<p><code>EmbeddingGenerator</code> interface also has a nested <code>Requirement</code> record for obtaining embedding generators using the <a href="../../core/capability/index.html">capability framework</a>.</p>
<p><code>EmbeddingModel</code> interface extends <code>EmbeddingGenerator</code> and <code>Coordinates</code> interfaces, so it has <code>provider</code>, <code>name</code>, and <code>version</code> attributes which can be used for requesting a specific model via the capability framework.</p>
<p><code>Narrator&lt;S&gt;</code> interface extends <code>EmbeddingGenerator&lt;S, String&gt;</code>. Specializations of this interface can be used for generating text from images, diagrams, graphs, models, &hellip; There might be implementations generating text from text. For example a summary or translation to another language.</p>
<h3><a href="#text" id="text">Text</a></h3>
<p>Implementations of <code>TextEmbeddingGenerator</code> can be used to generate text embeddings. <code>TextFloatVectorEmbeddingModel</code> is a specialization of <code>TextEmbeddingGenerator</code> for generating float vector embeddins. There are implementations of this interfaces for Ollama and OpenAI.</p>
<p><code>TextFloatVectorEmbeddingModel</code> generates a list of vectors from a piece of text, which is provided by concrete subclasses of <code>TextFloatVectorChunkingEmbeddingModel</code> - <code>TextFloatVectorCharChunkingEmbeddings</code> and <code>TextFloatVectorEncodingChunkingEmbeddingModel</code>.</p>
<h4><a href="#generation" id="generation">Generation</a></h4>
<h5><a href="#synchronous" id="synchronous">Synchronous</a></h5>
<pre><code class="language-java">CapabilityLoader capabilityLoader = new CapabilityLoader();
ProgressMonitor progressMonitor = new LoggerProgressMonitor(LOGGER);                
try {
    Requirement&lt;EmbeddingGenerator.Requirement, TextFloatVectorEmbeddingModel&gt; requirement = ServiceCapabilityFactory.createRequirement(TextFloatVectorEmbeddingModel.class);           
    Iterable&lt;CapabilityProvider&lt;TextFloatVectorEmbeddingModel&gt;&gt; embeddingsProviders = capabilityLoader.load(requirement, progressMonitor);
    List&lt;TextFloatVectorEmbeddingModel  &gt; allEmbeddings = new ArrayList&lt;&gt;();
    embeddingsProviders.forEach(ep -&gt; allEmbeddings.addAll(ep.getPublisher().collect(Collectors.toList()).block()));
    for (TextFloatVectorEmbeddingModel embeddings: allEmbeddings) {             
        for (List&lt;Float&gt; vector: embeddings.generate(&quot;Hello world!&quot;)) {     
            System.out.println(&quot;\t\t&quot; + vector.size());
        }
    }
} finally {
    capabilityLoader.close(progressMonitor);
}
</code></pre>
<h6><a href="#with-telemetry" id="with-telemetry">With telemetry</a></h6>
<h6><a href="#all-providers-and-models" id="all-providers-and-models"># All providers and models</a></h6>
<pre><code class="language-java">CapabilityLoader capabilityLoader = new CapabilityLoader();
ProgressMonitor progressMonitor = new LoggerProgressMonitor(LOGGER);new LoggerProgressMonitor(LOGGER);             
try {
    OpenTelemetry openTelemetry = capabilityLoader.loadOne(ServiceCapabilityFactory.createRequirement(OpenTelemetry.class), progressMonitor);
    
    Requirement&lt;EmbeddingGenerator.Requirement, TextFloatVectorEmbeddingModel&gt; requirement = ServiceCapabilityFactory.createRequirement(TextFloatVectorEmbeddingModel.class);           
    Iterable&lt;CapabilityProvider&lt;TextFloatVectorEmbeddingModel&gt;&gt; embeddingsProviders = capabilityLoader.load(requirement, progressMonitor);
    List&lt;TextFloatVectorEmbeddingModel  &gt; allEmbeddings = new ArrayList&lt;&gt;();
    embeddingsProviders.forEach(ep -&gt; allEmbeddings.addAll(ep.getPublisher().collect(Collectors.toList()).block()));
    Tracer tracer = openTelemetry.getTracer(&quot;test.ai&quot;);        
    Span span = tracer
        .spanBuilder(&quot;Embeddings&quot;)
        .startSpan();
    
    try (Scope scope = span.makeCurrent()) {
        for (TextFloatVectorEmbeddingModel embeddings: allEmbeddings) {             
            for (List&lt;Float&gt; vector: embeddings.generate(&quot;Hello world!&quot;)) {     
                System.out.println(&quot;\t\t&quot; + vector.size());
            }
        }
    } finally {
        span.end();
    }
} finally {
    capabilityLoader.close(progressMonitor);
}
</code></pre>
<h6><a href="#a-specific-provider" id="a-specific-provider"># A specific provider</a></h6>
<pre><code class="language-java">CapabilityLoader capabilityLoader = new CapabilityLoader();
ProgressMonitor progressMonitor = new LoggerProgressMonitor(LOGGER);             
try {
    OpenTelemetry openTelemetry = capabilityLoader.loadOne(ServiceCapabilityFactory.createRequirement(OpenTelemetry.class), progressMonitor);
    
    EmbeddingGenerator.Requirement eReq = TextFloatVectorEmbeddingModel.createRequirement(&quot;Ollama&quot;, null, null);
    Requirement&lt;EmbeddingGenerator.Requirement, TextFloatVectorEmbeddingModel&gt; requirement = ServiceCapabilityFactory.createRequirement(TextFloatVectorEmbeddingModel.class, null, eReq);           
    Iterable&lt;CapabilityProvider&lt;TextFloatVectorEmbeddingModel&gt;&gt; embeddingsProviders = capabilityLoader.load(requirement, progressMonitor);
    List&lt;TextFloatVectorEmbeddingModel&gt; allEmbeddings = new ArrayList&lt;&gt;();
    embeddingsProviders.forEach(ep -&gt; ep.getPublisher().subscribe(allEmbeddings::add));
    for (TextFloatVectorEmbeddingModel embeddings: allEmbeddings) {             
        Tracer tracer = openTelemetry.getTracer(&quot;test.ai&quot;);        
        Span span = tracer
            .spanBuilder(&quot;Embeddings&quot;)
            .startSpan();
        
        try (Scope scope = span.makeCurrent()) {
            Thread.sleep(200);
            for (Entry&lt;String, List&lt;List&lt;Float&gt;&gt;&gt; vectors: embeddings.generate(List.of(&quot;Hello world!&quot;, &quot;Hello universe!&quot;)).entrySet()) {        
                System.out.println(&quot;\t&quot; + vectors.getKey());
                for (List&lt;Float&gt; vector: vectors.getValue()) {
                    System.out.println(&quot;\t\t&quot; + vector.size());
                }
            }
            span.setStatus(StatusCode.OK);
        } finally {
            span.end();
        }
    }
} finally {
    capabilityLoader.close(progressMonitor);
}
</code></pre>
<h5><a href="#asynchronous" id="asynchronous">Asynchronous</a></h5>
<pre><code class="language-java">CapabilityLoader capabilityLoader = new CapabilityLoader();
ProgressMonitor progressMonitor = new LoggerProgressMonitor(LOGGER);
try {
    Requirement&lt;EmbeddingGenerator.Requirement, TextFloatVectorEmbeddingModel&gt; requirement = ServiceCapabilityFactory.createRequirement(TextFloatVectorEmbeddingModel.class);           
    TextFloatVectorEmbeddingModel embeddings = capabilityLoader.loadOne(requirement, progressMonitor);
    List&lt;List&lt;Float&gt;&gt; vectors = embeddings.generateAsync(&quot;Hello world!&quot;).block();
    for (List&lt;Float&gt; vector: vectors) {
        System.out.println(vector.size());
    }
} finally {
    capabilityLoader.close(progressMonitor);
}
</code></pre>
<h6><a href="#with-telemetry" id="with-telemetry">With telemetry</a></h6>
<pre><code class="language-java">CapabilityLoader capabilityLoader = new CapabilityLoader();
ProgressMonitor progressMonitor = new LoggerProgressMonitor(LOGGER);
try {
    Requirement&lt;EmbeddingGenerator.Requirement, TextFloatVectorEmbeddingModel&gt; requirement = ServiceCapabilityFactory.createRequirement(TextFloatVectorEmbeddingModel.class);           
    TextFloatVectorEmbeddingModel embeddings = capabilityLoader.loadOne(requirement, progressMonitor);
    
    OpenTelemetry openTelemetry = capabilityLoader.loadOne(ServiceCapabilityFactory.createRequirement(OpenTelemetry.class), progressMonitor);
    assertNotNull(openTelemetry);

    Tracer tracer = openTelemetry.getTracer(&quot;test.ai&quot;);        
    Span span = tracer
        .spanBuilder(&quot;Embeddings&quot;)
        .startSpan();
    
    List&lt;List&lt;Float&gt;&gt; vectors = embeddings
        .generateAsync(&quot;Hello world!&quot;)
        .contextWrite(reactor.util.context.Context.of(Context.class, Context.current().with(span)))
        .doFinally(signal -&gt; span.end())
        .block();

    for (List&lt;Float&gt; vector: vectors) {
        System.out.println(vector.size());
    }
} finally {
    capabilityLoader.close(progressMonitor);
}
</code></pre>
<h4><a href="#chunking" id="chunking">Chunking</a></h4>
<p>Chunking embeddings for <a href="https://platform.openai.com/docs/guides/embeddings#embedding-models"><code>text-embedding-ada-002</code></a> using <code>CL100K_BASE</code> encoding. <code>1000</code> tokens chunks with <code>20</code> tokens overlap.</p>
<pre><code class="language-java">TextFloatVectorEncodingChunkingEmbeddingModel chunkingEmbeddings = new TextFloatVectorEncodingChunkingEmbeddingModel(
        embeddings, 
        1000, 
        20, 
        EncodingType.CL100K_BASE);
</code></pre>
<h4><a href="#embeddings-resource" id="embeddings-resource">Embeddings resource</a></h4>
<p><code>TextFloatVectorEmbeddingResource</code> provides content with pre-computed embeddings. It is modeled after <a href="https://javadoc.io/doc/io.modelcontextprotocol.sdk/mcp/latest/io.modelcontextprotocol.sdk.mcp/io/modelcontextprotocol/spec/McpSchema.Resource.html">McpSchema.Resource</a> (see also <a href="https://modelcontextprotocol.io/docs/concepts/resources">MCP Resources</a>) to make it easy to wrap an embedding resources into an MCP resource and vice versa.</p>
<p>The idea is to publish text with embeddings and expose the data as an MCP resource and embeddings resource so it can be used by MCP clients, MCP tools, and there is no need to compute embeddings.</p>
<p>Example: <a href="https://docs.nasdanika.org/search-documents-embeddings.json">search-documents-embeddings.json</a> contains plain text for the pages of this site with pre-computed Ada embeddings of page chunks.</p>
<h3><a href="#images" id="images">Images</a></h3>
<p>This module provides the following classes and interfaces for working with images:</p>
<ul>
<li>Interfaces
<ul>
<li><code>ImageEmbeddingGenerator&lt;E&gt; extends EmbeddingGenerator&lt;BufferedImage, E&gt;</code></li>
<li><code>ImageNarrator extends ImageEmbeddingGenerator&lt;String&gt;, Narrator&lt;BufferedImage&gt;</code></li>
<li><code>ImageFloatVectorEmbeddingModel extends EmbeddingModel&lt;BufferedImage, List&lt;List&lt;Float&gt;&gt;&gt;, ImageEmbeddingGenerator&lt;List&lt;List&lt;Float&gt;&gt;&gt;, FloatVectorEmbeddingGenerator&lt;BufferedImage&gt;</code></li>
</ul>
</li>
<li>Classes
<ul>
<li><code>CachingImageEmbeddingGenerator&lt;E&gt; extends CachingEmbeddingGenerator&lt;BufferedImage, E, String&gt; implements ImageEmbeddingGenerator&lt;E&gt;</code>
<ul>
<li><code>CachingImageNarrator extends CachingImageEmbeddingGenerator&lt;String&gt; implements ImageNarrator</code></li>
</ul>
</li>
<li><code>ChatImageNarrator implements ImageNarrator</code> - uses multi-modal chat (see below) to generate image descriptions, extract text, &hellip;</li>
</ul>
</li>
</ul>
<h4><a href="#narrate-describe-image" id="narrate-describe-image">Narrate (describe) image</a></h4>
<pre><code class="language-java">CapabilityLoader capabilityLoader = new CapabilityLoader();
ProgressMonitor progressMonitor = new LoggerProgressMonitor(LOGGER);
OpenTelemetry openTelemetry = capabilityLoader.loadOne(ServiceCapabilityFactory.createRequirement(OpenTelemetry.class), progressMonitor);

List&lt;Chat&gt; chats = new ArrayList&lt;&gt;();       
try {
    Chat.Requirement cReq = new Chat.Requirement(&quot;OpenAI&quot;, &quot;gpt-4o&quot;, null);
    Requirement&lt;Chat.Requirement, Chat&gt; requirement = ServiceCapabilityFactory.createRequirement(Chat.class, null, cReq);           
    for (CapabilityProvider&lt;Chat&gt; chatProvider: capabilityLoader.&lt;Chat&gt;load(requirement, progressMonitor)) {
        chatProvider.getPublisher().subscribe(chats::add);
    }
    
    Tracer tracer = openTelemetry.getTracer(&quot;test.ai&quot;);        
    Span span = tracer
        .spanBuilder(&quot;Chat&quot;)
        .startSpan();
    try (Scope scope = span.makeCurrent()) {            
        for (Chat chat: chats) {
            ChatImageNarrator chatImageNarrator = new ChatImageNarrator(chat);
            String narration = chatImageNarrator.asFileEmbeddingGenerator().generate(new File(&quot;llama.png&quot;));
            System.out.println(narration);
        }
    } finally {
        span.end();
    }
} finally {
    capabilityLoader.close(progressMonitor);
}
</code></pre>
<h3><a href="#caching" id="caching">Caching</a></h3>
<p>Generation of embeddigns can be an expensive operation time and money wise (token cost). <code>CachingEmbeddingGenerator</code> and its subclasses can be used for caching and sharing embeddings.</p>
<p>One application of caching of image -&gt; textual description caching is manual modification of descriptions for images such as icons and logos where there is much more than meets the eye.<br />
For example, an architectural diagram may have an element with an image from an image library representing, say, a mainframe as on <a href="https://nasdanika-demos.github.io/internet-banking-system/index.html">this diagram</a>. Or it may represent a specific enterprise system such as a payment processing mainframe. Having a shared &ldquo;visual glossary&rdquo; would allow to generate higher quality diagram descriptions.</p>
<h4><a href="#cachingimagenarrator" id="cachingimagenarrator">CachingImageNarrator</a></h4>
<pre><code class="language-java">// Load cache here

ChatImageNarrator chatImageNarrator = new ChatImageNarrator(chat);
ImageNarrator cachingImageNarrator = new CachingImageNarrator(chatImageNarrator, cache);
String narration = cachingImageNarrator.asFileEmbeddingGenerator().generate(new File(&quot;llama.png&quot;));
System.out.println(narration);

// Save cache here
</code></pre>
<h2><a href="#similarity" id="similarity">Similarity</a></h2>
<p>One application of generating embeddings is to compute similarity between things such as text and images.</p>
<h3><a href="#computing" id="computing">Computing</a></h3>
<p><code>SimilarityComputer</code> interface and its extensions and implementation provide functionality for computing similarity for text and images.</p>
<p><code>SimilarityComputer</code> has the following methods:</p>
<ul>
<li><code>S compute(T, T)</code></li>
<li><code>Mono&lt;S&gt; computeAsync(T, T)</code></li>
<li><code>Mono&lt;S&gt; computeAsync(Mono&lt;T&gt;, Mono&lt;T&gt;)</code></li>
<li><code>&lt;V&gt; SimilarityComputer&lt;V,S&gt; adapt(Function&lt;V, Mono&lt;T&gt;&gt;)</code> - adapts to another input type using a mapper function</li>
</ul>
<p>Sub-interfaces:</p>
<ul>
<li><code>BufferedImageSimilarityComputer</code> - binds the input generic parameter to <code>BufferedImage</code> and provides adapter methods loading images from <code>InputStream</code>, <code>URL</code> or <code>File</code> and then computing similarity</li>
<li><code>TextSimilarityComputer</code> - binds the input generic parameter to <code>String</code></li>
<li><code>VectorSimilarityComputer&lt;E,S&gt; extends SimilarityComputer&lt;List&lt;E&gt;, S&gt;</code> - binds the input generic parameter to a list of vector elements
<ul>
<li><code>FloatVectorSimilarityComputer extends VectorSimilarityComputer&lt;Float, Float&gt;</code> - binds input element and similarity to <code>Float</code>. Provides <code>COSINE_SIMILARITY_COMPUTER</code> constant</li>
</ul>
</li>
</ul>
<p>Implementations:</p>
<ul>
<li><code>CompositeFloatSimilarityComputer&lt;T&gt; implements SimilarityComputer&lt;T,Float&gt;</code> - computes combined float similarity from several similarity computers. Computers are added using <code>addComputer(SimilarityComputer&lt;? super T, Float&gt; computer, float weight)</code> method. Possible application - compute image similarity using visual similarity methods, e.g. leveraging <a href="https://opencv.org/">OpenCV</a> or <a href="https://djl.ai/">Deep Java Library</a>. Then generate text descriptions and compute similarity between them. Finally, combine visual and textual similarity with weights.</li>
</ul>
<h3><a href="#search" id="search">Search</a></h3>
<p><a href="https://github.com/Nasdanika/ai/blob/main/core/src/main/java/org/nasdanika/ai/SimilaritySearch.java">SimilaritySearch</a> interface is intended to be used for finding items similar to a query using one of <code>find</code> methods:</p>
<ul>
<li><code>List&lt;SearchResult&lt;D&gt;&gt; find(U query, int numberOfItems)</code></li>
<li><code>Mono&lt;List&lt;SearchResult&lt;D&gt;&gt;&gt; findAsync(U query, int numberOfItems)</code></li>
</ul>
<p>Similarity search can work on any data type with a distance defined. The distance type must be <code>Comparable</code>. For example, for text distance can be computed using embeddings, a bag of words, a semantic graph, or a combination of thereof.</p>
<p>Semantic graphs may be useful with internal terminology. Let&rsquo;s say there is a <code>GBS</code> system which uses IBM MQ for communication with payload structure defined as <code>TVT</code> and encoded to bytes using <code>XLF</code>. The semantic/knowledge graph would &ldquo;know&rdquo; that <code>GBS</code> stands for &ldquo;Global Booking System&rdquo; and it is related to <code>TVT</code>, <code>MQ</code>, and <code>XLF</code><sup id="fnref-1"><a class="footnote-ref" href="#fn-1">1</a></sup>.</p>
<p>An instance of similarity search can be adapted to another type using <code>adapt(Function&lt;U,T&gt; mapper, Function&lt;U, Mono&lt;T&gt;&gt; asyncMapper)</code> method. One usage scenario is to adapt a structured type to text by &ldquo;narrating&rdquo; it. For example, there is a <a href="../../core/drawio/index.html">Drawio</a> diagram element or a <a href="https://architecture.models.nasdanika.org/references/eSubpackages/c4/index.html">C4 Model</a> element, say <a href="https://nasdanika-demos.github.io/internet-banking-system-c4/cerulean/references/elements/internet-banking-system/references/elements/api-application/index.html">API Application</a>.</p>
<p>In the case of a diagram element, it can be converted to text by explaining its label, tooltip, layer it belongs to, and other elements it connects to - this is different from computer vision because tooltips and layers are not visible. The narration may also include styling such as color, description of a shape image and geometry. E.g. &ldquo;above&rdquo;, &ldquo;to the right of&rdquo;.</p>
<p>In the case of a model element the narration would include element documentation, its references, and its type.</p>
<p>E.g.:</p>
<ul>
<li>The &ldquo;API Application&rdquo; is a <a href="https://architecture.models.nasdanika.org/references/eSubpackages/c4/references/eClassifiers/Container/index.html">Container</a>.</li>
<li><a href="https://nasdanika-demos.github.io/family-semantic-mapping/references/members/paul/index.html">Paul</a> is a <a href="https://family.models.nasdanika.org/references/eClassifiers/Man/index.html">Man</a>.</li>
</ul>
<p>Documentation may be in plain text or, for example, <a href="../../core/exec/index.html#markdown">Markdown</a>. In the latter case fenced blocks with diagrams can be narrated as explained above and images can be explained using vision models like ChatGPT. Image alternative text can be used as well.</p>
<p>Static <code>textFloatVectorEmbeddingSearch()</code> method adapts a float multi-vector search to string (text) search. There is a static method to adapt a single vector search to a multi-vector search.</p>
<p>The below code snippet shows how to create a vector search instance on top of <a href="https://github.com/jelmerk/hnswlib">Hnswlib</a>:</p>
<pre><code class="language-java">HnswIndex&lt;IndexId, float[], EmbeddingsItem, Float&gt; hnswIndex = HnswIndex
    .newBuilder(1536, DistanceFunctions.FLOAT_COSINE_DISTANCE, resources.size())
    .withM(16)
    .withEf(200)
    .withEfConstruction(200)
    .build();

Map&lt;String, String&gt; contentMap = new HashMap&lt;&gt;();

resourceSet.getResources().subscribe(er -&gt; {
    List&lt;List&lt;Float&gt;&gt; vectors = er.getEmbeddings();
    for (int i = 0; i &lt; vectors.size(); ++i) {
        List&lt;Float&gt; vector = vectors.get(i);
        float[] fVector = new float[vector.size()];
        for (int j = 0; j &lt; fVector.length; ++j) {
            fVector[j] = vector.get(j);
        }
        hnswIndex.add(new EmbeddingsItem(
                new IndexId(er.getUri(), i), 
                fVector, 
                er.getDimensions()));               
    }
    contentMap.put(er.getUri(), er.getContent());
});

hnswIndex.save(new File(&quot;test-data/hnsw-index.bin&quot;));

SimilaritySearch&lt;List&lt;Float&gt;, Float&gt; vectorSearch = new SimilaritySearch&lt;List&lt;Float&gt;, Float&gt;() {
    
    @Override
    public Mono&lt;List&lt;SearchResult&lt;Float&gt;&gt;&gt; findAsync(List&lt;Float&gt; query, int numberOfItems) {
        return Mono.just(find(query, numberOfItems));
    }
    
    @Override
    public List&lt;SearchResult&lt;Float&gt;&gt; find(List&lt;Float&gt; query, int numberOfItems) {
        float[] fVector = new float[query.size()];
        for (int j = 0; j &lt; fVector.length; ++j) {
            fVector[j] = query.get(j);
        }
        List&lt;SearchResult&lt;Float&gt;&gt; ret = new ArrayList&lt;&gt;();
        for (com.github.jelmerk.hnswlib.core.SearchResult&lt;EmbeddingsItem, Float&gt; nearest: hnswIndex.findNearest(fVector, numberOfItems)) {
            ret.add(new SearchResult&lt;Float&gt;() {
                
                @Override
                public String getUri() {
                    return nearest.item().id().uri();
                }
                
                @Override
                public int getIndex() {
                    return nearest.item().id().index();
                }
                
                @Override
                public Float getDistance() {
                    return nearest.distance();
                }
                
            });
        }
        return ret;
    }
    
};      

</code></pre>
<p>An instance of vector search can be adapted to a multi-vector search:</p>
<pre><code class="language-java">SimilaritySearch&lt;List&lt;List&lt;Float&gt;&gt;, Float&gt; multiVectorSearch = SimilaritySearch.adapt(vectorSearch);
</code></pre>
<p>and then to a text search:</p>
<pre><code class="language-java">TextFloatVectorChunkingEmbeddingModel chunkingEmbeddings = new TextFloatVectorChunkingEmbeddingModel(
        embeddings, 
        1000, 
        20, 
        EncodingType.CL100K_BASE);

SimilaritySearch&lt;String, Float&gt; textSearch = SimilaritySearch.textFloatVectorEmbeddingSearch(multiVectorSearch, chunkingEmbeddings);
</code></pre>
<h2><a href="#chat" id="chat">Chat</a></h2>
<pre><code class="language-java">CapabilityLoader capabilityLoader = new CapabilityLoader();
ProgressMonitor progressMonitor = new LoggerProgressMonitor(LOGGER);
try {
    Requirement&lt;Void, Chat&gt; requirement = ServiceCapabilityFactory.createRequirement(Chat.class);           
    org.nasdanika.ai.Chat chat = capabilityLoader.loadOne(requirement, progressMonitor);
    
    List&lt;ResponseMessage&gt; responses = chat.chat(
        Chat.Role.system.createMessage(&quot;You are a helpful assistant. You will talk like a pirate.&quot;),
        Chat.Role.user.createMessage(&quot;Can you help me?&quot;),
        Chat.Role.system.createMessage(&quot;Of course, me hearty! What can I do for ye?&quot;),
        Chat.Role.user.createMessage(&quot;What's the best way to train a parrot?&quot;)
    );
        
    for (ResponseMessage response: responses) {
        System.out.println(response.getContent());
    }
} finally {
    capabilityLoader.close(progressMonitor);
}
</code></pre>
<h3><a href="#with-telemetery" id="with-telemetery">With telemetery</a></h3>
<pre><code class="language-java">CapabilityLoader capabilityLoader = new CapabilityLoader();
ProgressMonitor progressMonitor = new LoggerProgressMonitor(LOGGER);
try {
    Requirement&lt;Void, Chat&gt; requirement = ServiceCapabilityFactory.createRequirement(Chat.class);           
    org.nasdanika.ai.Chat chat = capabilityLoader.loadOne(requirement, progressMonitor);
    
    OpenTelemetry openTelemetry = capabilityLoader.loadOne(ServiceCapabilityFactory.createRequirement(OpenTelemetry.class), progressMonitor);

    Tracer tracer = openTelemetry.getTracer(&quot;test.openai&quot;);        
    Span span = tracer
        .spanBuilder(&quot;Chat&quot;)
        .startSpan();
    
    try (Scope scope = span.makeCurrent()) {
        List&lt;ResponseMessage&gt; responses = chat.chat(
            Chat.Role.system.createMessage(&quot;You are a helpful assistant. You will talk like a pirate.&quot;),
            Chat.Role.user.createMessage(&quot;Can you help me?&quot;),
            Chat.Role.system.createMessage(&quot;Of course, me hearty! What can I do for ye?&quot;),
            Chat.Role.user.createMessage(&quot;What's the best way to train a parrot?&quot;)
        );
        
        for (ResponseMessage response: responses) {
            System.out.println(response.getContent());
        }
    } finally {
        span.end();
    }
} finally {
    capabilityLoader.close(progressMonitor);
}
</code></pre>
<h3><a href="#retrieval-augmented-generation-rag" id="retrieval-augmented-generation-rag">Retrieval-augmented generation (RAG)</a></h3>
<p>The below code snippet shows how chat can be used with the text search for <a href="https://en.wikipedia.org/wiki/Retrieval-augmented_generation">retrieval-augmented generation</a>:</p>
<pre><code class="language-java">String query = ...
List&lt;SearchResult&lt;Float&gt;&gt; searchResults = textSearch.find(query, 10);
  
// Chat
Chat.Requirement cReq = new Chat.Requirement(&quot;OpenAI&quot;, &quot;gpt-4o&quot;, null);
Requirement&lt;Chat.Requirement, Chat&gt; chatRequirement = ServiceCapabilityFactory.createRequirement(Chat.class, null, cReq);
Chat chat = capabilityLoader.loadOne(chatRequirement, progressMonitor);

List&lt;Chat.Message&gt; messages = new ArrayList&lt;&gt;();
messages.add(Chat.Role.system.createMessage(&quot;You are a helpful assistant. You will answer user question leveraging provided documents and provide references to the used documents. Output your answer in markdown&quot;));
messages.add(Chat.Role.user.createMessage(query));

Map&lt;String, List&lt;SearchResult&lt;Float&gt;&gt;&gt; groupedResults = org.nasdanika.common.Util.groupBy(searchResults, SearchResult::getUri);
for (Entry&lt;String, List&lt;SearchResult&lt;Float&gt;&gt;&gt; sre: groupedResults.entrySet()) {
    StringBuilder messageBuilder = new StringBuilder(&quot;Use this document with URL &quot; + sre.getKey() + &quot;:&quot; + System.lineSeparator());
    List&lt;String&gt; chunks = chunkingEmbeddings.chunk(contentMap.get(sre.getKey()));
    for (SearchResult&lt;Float&gt; chunkResult: sre.getValue()) {
        String chunk = chunks.get(chunkResult.getIndex());
        messageBuilder.append(System.lineSeparator() + System.lineSeparator() + chunk);
    }
    
    messages.add(Chat.Role.system.createMessage(messageBuilder.toString()));
}       

List&lt;ResponseMessage&gt; responses = chat.chat(messages);                              

for (ResponseMessage response: responses) {
    System.out.println(response.getContent());
}               
</code></pre>
<p>Please note that this is a very basic implementation:</p>
<ul>
<li>It doesn&rsquo;t take the size of the context window into account and doesn&rsquo;t count input tokens.</li>
<li>It uses all search results regardless of the distance. A more robust implementation would discard results with the distance greater than some threshold and perhaps would reply &ldquo;Not enough information&rdquo; if there are no good matches.</li>
</ul>
<p>Also the example above is a single-shot - ask a question, get an answer, it is not a dialog.</p>
<div class="footnotes">
<hr />
<ol>
<li id="fn-1">
<p>See <a href="https://medium.com/nasdanika/connecting-the-dots-94a733c61059">Connecting the dots</a> and <a href="https://medium.com/nasdanika/architecture-as-code-7c0eadfc0b2b">Architecture as code</a> stories for more details.</p>
<a href="#fnref-1" class="footnote-backref">&#8617;</a>
</li>
</ol>
</div>
</div></div>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
      <div class="row">
        <div class="col nsd-app-footer">
          <ul class="nav nsd-app-footer-navs">
            <li class="nav-item">
              <a href="https://github.com/Nasdanika/nasdanika.github.io/" data-nsd-label-uuid="b5c276ba-1f20-48d2-97cc-359c8ddcf5ba" class="nav-link"><span class="fab fa-github nsd-app-label-icon"></span>Source</a>
            </li>
          </ul>
        </div>
      </div>
    </div>
  </body>
</html>